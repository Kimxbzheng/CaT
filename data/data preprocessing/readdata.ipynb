{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC \n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_f = r\"../data/scp_gex_matrix.csv.gz\" \n",
    "label_f = r\"../data/scp_meta.txt\"\n",
    "\n",
    "def fprint(txtt):\n",
    "    f = open(r\"dp.txt\",\"a+\")\n",
    "    f.write(str(txtt))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "fprint(\"start123\") \n",
    "\n",
    "#read data\n",
    "samplesdf =  pd.read_csv(sample_f,compression =\"gzip\", header = 0)\n",
    "samplesdf = samplesdf.T\n",
    "samples_name = samplesdf.index.values\n",
    "samples_name = samples_name[1:]\n",
    "samples = samplesdf.values\n",
    "rna2 = samples[0]\n",
    "samples = samples[1:]\n",
    "fprint(\"First!\")\n",
    "labels_name = np.array([])\n",
    "labels_temp = np.array([])\n",
    "i = 0\n",
    "with open(label_f) as rawlabel:\n",
    "    label_reader = csv.reader(rawlabel, delimiter='\\t')\n",
    "    for labels in label_reader:\n",
    "        if i>=2:\n",
    "            labels_name = np.append(labels_name,[labels[0]])\n",
    "            labels_temp = np.append(labels_temp,[labels[3]])\n",
    "        i = i + 1\n",
    "fprint(\"Second!\")\n",
    "labels_text = np.array([])\n",
    "#find correct labels for each element in samples\n",
    "for lb in samples_name:\n",
    "    idx = np.where(labels_name == lb)\n",
    "    if len(idx[0]) > 1:\n",
    "        fprint(\"Warning! Have duplicate.\")\n",
    "    elif len(idx[0]) == 0:\n",
    "        fprint(\"Warning! No corresponding entry.\")\n",
    "    labels_text = np.append(labels_text, labels_temp[idx[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handed-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprint(\"Samples \")\n",
    "fprint(samples.shape)\n",
    "fprint(\"Labels \")\n",
    "fprint(labels_text.shape)\n",
    "fprint(\"RNA\")\n",
    "fprint(rna2.shape)\n",
    "fprint(labels_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "centered-donna",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/rna_names.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f40dc3ff1595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m# Save all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"data/rna_names.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_fdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"data/NEW_P_fdr.csv.gz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/dept2/xbzheng/miniconda3/envs/tf-cpu/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/dept2/xbzheng/miniconda3/envs/tf-cpu/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/dept2/xbzheng/miniconda3/envs/tf-cpu/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/research/dept2/xbzheng/miniconda3/envs/tf-cpu/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/rna_names.csv'"
     ]
    }
   ],
   "source": [
    "#convert labels_text into corresponding labels(0: non-sepsis, 1: sepsis)\n",
    "labels = np.array([])\n",
    "num1=0\n",
    "num0=0\n",
    "for lb in labels_text:\n",
    "    if lb == \"Int-URO\" or lb == \"URO\" or lb == \"Bac-SEP\" or lb == \"ICU-SEP\":\n",
    "        labels = np.append(labels,[1])\n",
    "        num1 = num1 + 1\n",
    "    else:\n",
    "        labels = np.append(labels,[0])\n",
    "        num0 = num0 + 1\n",
    "\n",
    "fprint(\"Converted to label in numbers\")\n",
    "fprint(labels.shape)\n",
    "fprint(num1)\n",
    "fprint(num0)\n",
    "\n",
    "\n",
    "#split training and testing sample (x = sample, y = label)\n",
    "x_train,x_test,y_train,y_test = train_test_split(samples,labels,test_size = 0.1, random_state = 5)\n",
    "fprint(\"Split succcessful\")\n",
    "\n",
    "#checking \n",
    "fprint(x_train.shape)\n",
    "fprint(x_test.shape)\n",
    "fprint(y_train.shape)\n",
    "fprint(y_test.shape)\n",
    "\n",
    "#separate control and case samples\n",
    "i = 0\n",
    "idx = []\n",
    "for lb in y_train:\n",
    "    if lb == 0:\n",
    "        idx.append(i)\n",
    "    i = i + 1\n",
    "\n",
    "fprint(\"Now mask.\")\n",
    "mask = np.ones(len(x_train), dtype=bool)\n",
    "mask[idx,] = False\n",
    "con_sample,case_sample = x_train[idx], x_train[mask]\n",
    "\n",
    "fprint(\"Separation succcessful\")\n",
    "fprint(con_sample.shape)\n",
    "fprint(case_sample.shape)\n",
    "\n",
    "#to avoid error, delete zero columns of case samples\n",
    "idx = np.argwhere(np.all(case_sample==0,axis = 0)) #find index of zero columns\n",
    "idx2 = np.argwhere(np.all(con_sample==0,axis = 0))\n",
    "idx = np.intersect1d(idx,idx2)\n",
    "case_sample = np.delete(case_sample,idx,axis = 1) \n",
    "con_sample = np.delete(con_sample,idx,axis = 1) \n",
    "x_train = np.delete(x_train,idx,axis = 1) \n",
    "x_test = np.delete(x_test,idx,axis = 1)  \n",
    "rna2 = np.delete(rna2,idx)\n",
    "\n",
    "fprint(\"After deletion\")\n",
    "fprint(x_train.shape)\n",
    "fprint(x_test.shape)\n",
    "\n",
    "fprint(con_sample.shape)\n",
    "fprint(case_sample.shape)\n",
    "\n",
    "con_sample = np.array(con_sample,dtype=np.float32)\n",
    "case_sample = np.array(case_sample,dtype=np.float32)\n",
    "\n",
    "# optain stat value\n",
    "t_stat,pvalue = stats.ttest_ind(con_sample, case_sample, axis = 0, equal_var=True, nan_policy='raise')\n",
    "rejected, P_fdr = fdrcorrection(pvalue, alpha=0.05, method='indep', is_sorted=False)\n",
    "\n",
    "fprint(\"Value computed!\")\n",
    "fprint(P_fdr.shape)\n",
    "\n",
    "\n",
    "# select RNAs with small P_fdr as the input\n",
    "i = 0\n",
    "idx = []\n",
    "for fdr in P_fdr:\n",
    "    if fdr > 0.005:\n",
    "        idx.append(i)\n",
    "    i = i + 1\n",
    "x_train = np.delete(x_train,idx,1)\n",
    "x_test = np.delete(x_test,idx,1)\n",
    "rna2 = np.delete(rna2,idx)\n",
    "\n",
    "\n",
    "fprint(\"Filter succcessful\")\n",
    "\n",
    "# Checking\n",
    "fprint(x_train.shape)\n",
    "fprint(x_test.shape)\n",
    "fprint(y_train.shape)\n",
    "fprint(y_test.shape)\n",
    "fprint(rna2.shape)\n",
    "\n",
    "\n",
    "#Delete sparse sample\n",
    "\n",
    "idx = []\n",
    "i = 0\n",
    "for samples in x_train :\n",
    "    num0 = 0\n",
    "    for col in samples:\n",
    "        if col == 0:\n",
    "            num0 = num0 + 1\n",
    "    if num0/len(samples)>0.9:\n",
    "        idx.append(i)\n",
    "    i = i + 1\n",
    "x_train = np.delete(x_train, idx,axis=0)\n",
    "y_train = np.delete(y_train,idx,axis=0)\n",
    "\n",
    "fprint(\"Deleted x_train sparse.\")\n",
    "fprint(x_train.shape)\n",
    "fprint(y_train.shape)\n",
    "\n",
    "# Delete sparse sample\n",
    "\n",
    "idx = []\n",
    "i = 0\n",
    "for samples in x_test :\n",
    "    num0 = 0\n",
    "    for col in samples:\n",
    "        if col == 0:\n",
    "            num0 = num0 + 1\n",
    "    if num0/len(samples)>0.9:\n",
    "        idx.append(i)\n",
    "    i = i + 1\n",
    "x_test = np.delete(x_test, idx,axis=0)\n",
    "y_test = np.delete(y_test, idx,axis=0)\n",
    "\n",
    "fprint(\"Deleted x_test sparse.\")\n",
    "fprint(x_test.shape)\n",
    "fprint(y_test.shape)\n",
    "\n",
    "#Take transpose of everything\n",
    "allsample = np.vstack((x_train,x_test))\n",
    "allsample = np.transpose(allsample)\n",
    "fprint(\"Taken transpose.\")\n",
    "fprint(allsample.shape)\n",
    "\n",
    "\n",
    "# Delete sparse sample\n",
    "\n",
    "idx = []\n",
    "i = 0\n",
    "for rna in allsample :\n",
    "    num0 = 0\n",
    "    for col in rna:\n",
    "        if col == 0:\n",
    "            num0 = num0 + 1\n",
    "    if num0/len(rna)>0.9:\n",
    "        idx.append(i)\n",
    "    i = i + 1\n",
    "fprint(\"Number of cols found\")\n",
    "fprint(len(idx))\n",
    "x_train = np.delete(x_train,idx,axis=1)\n",
    "x_test = np.delete(x_test,idx,axis=1)\n",
    "rna2 = np.delete(rna2,idx)\n",
    "\n",
    "\n",
    "fprint(\"Deleted col sparse.\")\n",
    "fprint(x_train.shape)\n",
    "fprint(x_test.shape)\n",
    "fprint(y_train.shape)\n",
    "fprint(y_test.shape)\n",
    "fprint(rna2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authentic-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all files\n",
    "df = pd.DataFrame(rna2)\n",
    "df.to_csv(r\"../data/rna_names.csv\",index=False,sep=\",\")\n",
    "df = pd.DataFrame(P_fdr)\n",
    "df.to_csv(r\"../data/NEW_P_fdr.csv.gz\",index=False,sep=\",\",compression=\"gzip\")\n",
    "df = pd.DataFrame(x_train)\n",
    "df.to_csv(r\"../data/NEW_training_sample.csv.gz\",index=False,sep=\",\",compression=\"gzip\")\n",
    "df = pd.DataFrame(x_test)\n",
    "df.to_csv(r\"../data/NEW_testing_sample.csv.gz\",index=False,sep=\",\",compression=\"gzip\")\n",
    "df = pd.DataFrame(y_train)\n",
    "df.to_csv(r\"../data/NEW_training_label.csv.gz\",index=False,sep=\",\",compression=\"gzip\")\n",
    "df = pd.DataFrame(y_test)\n",
    "df.to_csv(r\"../data/NEW_testing_label.csv.gz\",index=False,sep=\",\",compression=\"gzip\")\n",
    "\n",
    "\n",
    "# Checking\n",
    "\n",
    "fprint(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-norwegian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-cpu]",
   "language": "python",
   "name": "conda-env-tf-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
