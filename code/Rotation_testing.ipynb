{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46acef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:40:50.066118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras import callbacks\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9491e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(xtr,ytr,xval,yval,cw):\n",
    "    org_model = keras.models.load_model(\"../modelsave/weightmodel\")\n",
    "    org_model = models.Model(inputs=org_model.input, outputs=org_model.get_layer('dense_6').output) # do not include final classifier\n",
    "    org_model.summary()\n",
    "\n",
    "    org_model.trainable = False\n",
    "    inputs = keras.Input(shape=(2869,1))\n",
    "    x = org_model(inputs, training=False)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(xtr, ytr, batch_size=10, epochs=20,validation_data=(xval, yval),\n",
    "                   shuffle=True,class_weight=cw)\n",
    "\n",
    "    org_model.trainable = True\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "    \n",
    "    model.fit(xtr, ytr, batch_size=10, epochs=50,validation_data=(xval, yval),\n",
    "                   shuffle=True,class_weight=cw,callbacks =[earlystopping])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac46a278",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5.686 , 11.3806,  7.1689, ..., 10.6627,  9.3806,  5.5011],\n",
       "        [ 5.3899, 11.3008,  7.8225, ..., 10.7067,  9.8158,  4.895 ],\n",
       "        [ 5.2863,  8.4467,  7.775 , ..., 10.7362,  7.3991,  4.7524],\n",
       "        ...,\n",
       "        [ 5.9418,  7.851 ,  8.5398, ...,  9.8227,  7.0775,  4.8467],\n",
       "        [ 5.7863,  9.6025,  8.8713, ..., 10.5933,  7.2535,  5.5077],\n",
       "        [ 5.0932,  8.5812,  7.9627, ..., 11.3954,  6.7701,  4.8525]]),\n",
       " array([[ 4.1258,  8.4825,  7.375 , ...,  9.9011,  9.977 ,  4.5518],\n",
       "        [ 3.7253,  7.0136,  7.3436, ...,  9.974 , 10.9023,  4.3127],\n",
       "        [ 4.1171,  7.4553,  7.5396, ...,  9.8454, 10.3504,  4.6858],\n",
       "        ...,\n",
       "        [ 4.6867,  8.0777,  7.48  , ...,  9.57  , 10.7467,  4.8751],\n",
       "        [ 4.5665,  8.339 ,  6.8913, ...,  9.6997, 10.374 ,  4.1515],\n",
       "        [ 4.4886,  7.878 ,  7.3   , ...,  9.3813, 10.6168,  4.6568]]),\n",
       " array([[ 4.6275,  7.793 ,  4.8201, ...,  9.5678, 10.3472,  4.2763],\n",
       "        [ 4.3328,  6.8776,  4.857 , ..., 10.0162, 10.9576,  4.2889],\n",
       "        [ 4.4819,  6.4691,  5.1446, ...,  9.3187, 10.6998,  4.6467],\n",
       "        ...,\n",
       "        [ 4.3515,  8.3618,  4.9506, ..., 10.0109, 10.4098,  4.721 ],\n",
       "        [ 4.3024,  6.2064,  4.9689, ..., 10.1804, 10.0654,  4.4388],\n",
       "        [ 4.0834,  6.1256,  5.0791, ..., 10.3001, 10.8179,  4.515 ]]),\n",
       " array([[ 4.8699, 11.138 ,  7.9854, ...,  9.5333,  5.944 ,  4.3108],\n",
       "        [ 4.7673,  9.118 ,  7.9665, ...,  9.5745,  6.1626,  4.3971],\n",
       "        [ 4.8782, 10.0231,  7.8159, ...,  9.8404,  6.289 ,  4.2635],\n",
       "        ...,\n",
       "        [ 4.8031,  8.683 ,  8.1756, ...,  9.737 ,  6.3762,  4.1297],\n",
       "        [ 4.6296,  8.1717,  8.0561, ..., 10.3368,  6.1574,  4.1412],\n",
       "        [ 5.2687,  8.2238,  7.8848, ...,  9.479 ,  6.5385,  4.8391]]),\n",
       " array([[0.9595, 3.3447, 1.0367, ..., 1.1123, 0.8088, 0.8762],\n",
       "        [1.0471, 0.8364, 1.093 , ..., 1.1169, 1.1508, 0.8813],\n",
       "        [1.0353, 1.654 , 1.07  , ..., 1.3866, 1.5649, 1.0936],\n",
       "        ...,\n",
       "        [0.7833, 3.5272, 1.2436, ..., 0.8493, 0.8773, 1.1829],\n",
       "        [0.722 , 0.53  , 1.0948, ..., 1.5434, 1.7855, 1.0064],\n",
       "        [0.9088, 0.3062, 0.9472, ..., 1.0379, 2.3295, 1.0681]]),\n",
       " array([[1.045 , 0.3812, 0.6608, ..., 0.8732, 0.2927, 0.6373],\n",
       "        [1.0241, 0.305 , 1.4193, ..., 1.0898, 1.6128, 0.7768],\n",
       "        [0.9006, 0.3439, 1.1607, ..., 1.4101, 3.5541, 0.7845],\n",
       "        ...,\n",
       "        [0.9526, 0.8531, 1.1189, ..., 1.1026, 1.0744, 0.8627],\n",
       "        [0.8629, 2.9138, 1.0705, ..., 1.0295, 0.8002, 0.9985],\n",
       "        [0.7854, 0.2988, 0.6755, ..., 1.5033, 0.8524, 0.4698]]),\n",
       " array([[1.0523, 0.3833, 0.9838, ..., 0.7676, 0.7118, 0.7708],\n",
       "        [1.0402, 0.3291, 0.9351, ..., 0.6105, 0.6087, 0.6899],\n",
       "        [1.0412, 0.3994, 1.0394, ..., 1.247 , 1.1113, 0.5861],\n",
       "        ...,\n",
       "        [1.007 , 0.6694, 1.2827, ..., 1.7957, 2.6135, 1.4198],\n",
       "        [1.0988, 0.4271, 0.8659, ..., 1.055 , 0.838 , 0.6276],\n",
       "        [1.0936, 0.7807, 1.6094, ..., 1.3381, 1.0741, 0.5207]]),\n",
       " array([[ 6.3235, 11.3281,  8.5911, ..., 11.4771,  7.2169,  5.0226],\n",
       "        [ 6.2119,  9.3268,  8.5978, ..., 11.1739,  6.9289,  4.8747],\n",
       "        [ 6.0827,  9.0651,  8.8466, ..., 10.821 ,  7.2653,  5.0756],\n",
       "        ...,\n",
       "        [ 5.2202, 10.9254,  7.6861, ..., 11.0226,  8.6377,  4.863 ],\n",
       "        [ 5.8285,  8.0435,  8.8951, ..., 11.0371,  7.281 ,  4.7901],\n",
       "        [ 5.7913,  9.0184,  8.6441, ..., 11.1469,  6.7754,  4.8415]]),\n",
       " array([[ 5.5679,  7.7078,  8.3399, ...,  9.7995, 10.0076,  4.7722],\n",
       "        [ 5.4077,  8.0708,  8.4902, ..., 10.1738, 10.0719,  4.9263],\n",
       "        [ 4.6347,  9.018 ,  8.0825, ..., 10.6947, 10.4303,  5.0312],\n",
       "        ...,\n",
       "        [ 5.2123,  9.185 ,  8.3252, ...,  9.7987,  8.4861,  5.1439],\n",
       "        [ 5.2383,  9.2797,  8.2908, ..., 10.087 ,  9.4378,  5.0955],\n",
       "        [ 5.1241,  8.8112,  7.8747, ...,  9.6468,  9.7304,  4.962 ]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_idx=pd.read_csv(\"../data/dataBulk/common_rna.csv\",index_col=0).values.squeeze().tolist()\n",
    "\n",
    "# prepare training data\n",
    "files=[\"26440\",\"57065\",\"95233\",\"4607\",\"8121\",\"9692\",\"13904\",\"26378\",\"28750\"]\n",
    "\n",
    "datasets = []\n",
    "labels = []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    if file == \"13904\":\n",
    "        df=pd.read_csv(\"../data/dataBulk/exp.gene.mRNA.GSE\"+file+'.txt' , sep=\"\\t\").T\n",
    "        df_label=pd.read_csv(\"../data/dataBulk/label_GSE\"+file+'.txt' , sep=\"\\t\",header=None)\n",
    "        data=df[rna_idx].T\n",
    "        data=data[df_label[0]].T.values\n",
    "        label=df_label[2].values>0\n",
    "    else:\n",
    "        df=pd.read_csv(\"../data/dataBulk/exp.gene.mRNA.GSE\"+file+'.txt' , sep=\"\\t\").T\n",
    "        data=df[rna_idx].values\n",
    "        df_label=pd.read_csv(\"../data/dataBulk/label_GSE\"+file+'.txt' , sep=\"\\t\",header=None)[2].values\n",
    "        label=(df_label>0)\n",
    "    \n",
    "    datasets.append(data)\n",
    "    labels.append(label)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd051da-c267-461b-b64d-107ffdab8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据真实label导出来\n",
    "for label, file in zip(labels, files):\n",
    "    filename = f\"GSE{file}_truelabel.csv\"\n",
    "    df = pd.DataFrame({\"label\": label})\n",
    "    df.to_csv(f\"../data/dataBulk/bulk_truelabel/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd9adac1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_72 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 2s 61ms/step - loss: 1.3428 - accuracy: 0.2613 - val_loss: 1.2536 - val_accuracy: 0.1923\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.7996 - accuracy: 0.2473 - val_loss: 0.6447 - val_accuracy: 0.9231\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6777 - accuracy: 0.8051 - val_loss: 0.5515 - val_accuracy: 0.8077\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.7086 - accuracy: 0.7237 - val_loss: 0.6215 - val_accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6407 - accuracy: 0.8467 - val_loss: 0.6358 - val_accuracy: 0.9231\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6647 - accuracy: 0.8189 - val_loss: 0.6582 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.7484 - accuracy: 0.4730 - val_loss: 0.6847 - val_accuracy: 0.4615\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6342 - accuracy: 0.7780 - val_loss: 0.5900 - val_accuracy: 0.8077\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6152 - accuracy: 0.7794 - val_loss: 0.5905 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6217 - accuracy: 0.8463 - val_loss: 0.6306 - val_accuracy: 0.9231\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6800 - accuracy: 0.7700 - val_loss: 0.6486 - val_accuracy: 0.7692\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6347 - accuracy: 0.7784 - val_loss: 0.6197 - val_accuracy: 0.9231\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6495 - accuracy: 0.9032 - val_loss: 0.5969 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6069 - accuracy: 0.9470 - val_loss: 0.5870 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6683 - accuracy: 0.8782 - val_loss: 0.6411 - val_accuracy: 0.7692\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6141 - accuracy: 0.8114 - val_loss: 0.5943 - val_accuracy: 0.9231\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6092 - accuracy: 0.9207 - val_loss: 0.5680 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5925 - accuracy: 0.9570 - val_loss: 0.5956 - val_accuracy: 0.9231\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.6068 - accuracy: 0.9245 - val_loss: 0.5870 - val_accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5631 - accuracy: 0.9601 - val_loss: 0.5736 - val_accuracy: 0.9231\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 86ms/step - loss: 0.5807 - binary_accuracy: 0.9252 - val_loss: 0.5608 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.5610 - binary_accuracy: 0.9203 - val_loss: 0.5872 - val_binary_accuracy: 0.8462\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.5442 - binary_accuracy: 0.8697 - val_loss: 0.5591 - val_binary_accuracy: 0.8846\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.5498 - binary_accuracy: 0.8852 - val_loss: 0.5524 - val_binary_accuracy: 0.8846\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.5831 - binary_accuracy: 0.8525 - val_loss: 0.5601 - val_binary_accuracy: 0.8462\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.5040 - binary_accuracy: 0.8945 - val_loss: 0.4639 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.5052 - binary_accuracy: 0.9340 - val_loss: 0.5301 - val_binary_accuracy: 0.8846\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4936 - binary_accuracy: 0.9234 - val_loss: 0.5290 - val_binary_accuracy: 0.8462\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.5126 - binary_accuracy: 0.9306 - val_loss: 0.4601 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.4808 - binary_accuracy: 0.9479 - val_loss: 0.4480 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.4809 - binary_accuracy: 0.8714 - val_loss: 0.5420 - val_binary_accuracy: 0.7692\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4562 - binary_accuracy: 0.9154 - val_loss: 0.3977 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4478 - binary_accuracy: 0.9470 - val_loss: 0.5032 - val_binary_accuracy: 0.8077\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4289 - binary_accuracy: 0.9006 - val_loss: 0.4109 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4289 - binary_accuracy: 0.9404 - val_loss: 0.4195 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.4123 - binary_accuracy: 0.9360 - val_loss: 0.3911 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.3611 - binary_accuracy: 0.9282 - val_loss: 0.4125 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.3861 - binary_accuracy: 0.8787 - val_loss: 0.3646 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.3443 - binary_accuracy: 0.9656 - val_loss: 0.3341 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.3021 - binary_accuracy: 0.9239 - val_loss: 0.3547 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.3094 - binary_accuracy: 0.9096 - val_loss: 0.2933 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.2556 - binary_accuracy: 0.9169 - val_loss: 0.3344 - val_binary_accuracy: 0.8846\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.2881 - binary_accuracy: 0.8899 - val_loss: 0.2263 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.2166 - binary_accuracy: 0.9711 - val_loss: 0.3613 - val_binary_accuracy: 0.8462\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.2605 - binary_accuracy: 0.8745 - val_loss: 0.2056 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.2059 - binary_accuracy: 0.9306 - val_loss: 0.2736 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.2266 - binary_accuracy: 0.9263 - val_loss: 0.1847 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.1957 - binary_accuracy: 0.9484 - val_loss: 0.2057 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.1702 - binary_accuracy: 0.9616 - val_loss: 0.1751 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.1710 - binary_accuracy: 0.9307 - val_loss: 0.2002 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.1602 - binary_accuracy: 0.9140 - val_loss: 0.2184 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1860 - binary_accuracy: 0.8983 - val_loss: 0.1202 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1751 - binary_accuracy: 0.9723 - val_loss: 0.2743 - val_binary_accuracy: 0.8846\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1272 - binary_accuracy: 0.9586 - val_loss: 0.0984 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1543 - binary_accuracy: 0.9447 - val_loss: 0.1766 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1099 - binary_accuracy: 0.9533 - val_loss: 0.1540 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0971 - binary_accuracy: 0.9622 - val_loss: 0.0964 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1097 - binary_accuracy: 0.9773 - val_loss: 0.1466 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1046 - binary_accuracy: 0.9339 - val_loss: 0.1450 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0848 - binary_accuracy: 0.9668 - val_loss: 0.0851 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0906 - binary_accuracy: 0.9348 - val_loss: 0.0771 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0920 - binary_accuracy: 0.9976 - val_loss: 0.2139 - val_binary_accuracy: 0.9231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0886 - binary_accuracy: 0.9452 - val_loss: 0.1107 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1007 - binary_accuracy: 0.9233 - val_loss: 0.3840 - val_binary_accuracy: 0.8077\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.1300 - binary_accuracy: 0.9255 - val_loss: 0.0836 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0533 - binary_accuracy: 0.9690 - val_loss: 0.0916 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0459 - binary_accuracy: 0.9960 - val_loss: 0.1502 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0433 - binary_accuracy: 1.0000 - val_loss: 0.0786 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0374 - binary_accuracy: 0.9897 - val_loss: 0.1027 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0491 - binary_accuracy: 0.9893 - val_loss: 0.0644 - val_binary_accuracy: 0.9615\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 26440\n",
      "[[0.9914962 ]\n",
      " [0.7080482 ]\n",
      " [0.9927666 ]\n",
      " [0.9943757 ]\n",
      " [0.9662113 ]\n",
      " [0.98056227]\n",
      " [0.9951611 ]\n",
      " [0.91562456]\n",
      " [0.9951119 ]\n",
      " [0.99618185]\n",
      " [0.99670035]\n",
      " [0.9903454 ]\n",
      " [0.9913566 ]\n",
      " [0.9957599 ]\n",
      " [0.9967924 ]\n",
      " [0.9948606 ]\n",
      " [0.8061564 ]\n",
      " [0.99444854]\n",
      " [0.99455076]\n",
      " [0.99536884]\n",
      " [0.9950222 ]\n",
      " [0.764046  ]\n",
      " [0.9832962 ]\n",
      " [0.936669  ]\n",
      " [0.9903357 ]\n",
      " [0.98796636]\n",
      " [0.31531063]\n",
      " [0.98641545]\n",
      " [0.948347  ]\n",
      " [0.9928033 ]\n",
      " [0.9948572 ]\n",
      " [0.9766741 ]\n",
      " [0.99310666]\n",
      " [0.7960541 ]\n",
      " [0.99318075]\n",
      " [0.9900523 ]\n",
      " [0.97951496]\n",
      " [0.97806317]\n",
      " [0.9453137 ]\n",
      " [0.99571204]\n",
      " [0.00861203]\n",
      " [0.02310541]\n",
      " [0.02615459]\n",
      " [0.9940348 ]\n",
      " [0.9965874 ]\n",
      " [0.9963903 ]\n",
      " [0.994293  ]\n",
      " [0.06263388]\n",
      " [0.03622078]\n",
      " [0.01010397]\n",
      " [0.00718669]\n",
      " [0.09324296]\n",
      " [0.9834262 ]\n",
      " [0.99399865]\n",
      " [0.994666  ]\n",
      " [0.99413824]\n",
      " [0.99153495]\n",
      " [0.99328774]\n",
      " [0.99578273]\n",
      " [0.99507254]\n",
      " [0.99436635]\n",
      " [0.98660475]\n",
      " [0.9958525 ]\n",
      " [0.99404484]\n",
      " [0.9799667 ]\n",
      " [0.98105407]\n",
      " [0.9900823 ]\n",
      " [0.9931498 ]\n",
      " [0.99077016]\n",
      " [0.9485401 ]\n",
      " [0.9938465 ]\n",
      " [0.98394936]\n",
      " [0.99182266]\n",
      " [0.97009206]\n",
      " [0.9925599 ]\n",
      " [0.98709446]\n",
      " [0.983253  ]\n",
      " [0.9959794 ]\n",
      " [0.24767633]\n",
      " [0.00532206]\n",
      " [0.8622002 ]\n",
      " [0.00656979]\n",
      " [0.00818834]\n",
      " [0.00611787]\n",
      " [0.02397811]\n",
      " [0.9571362 ]\n",
      " [0.0254699 ]\n",
      " [0.13448544]\n",
      " [0.01207539]\n",
      " [0.00637819]\n",
      " [0.9957467 ]\n",
      " [0.28909075]\n",
      " [0.9879386 ]\n",
      " [0.9935476 ]\n",
      " [0.9947437 ]\n",
      " [0.9944614 ]\n",
      " [0.02013114]\n",
      " [0.03989851]\n",
      " [0.02068937]\n",
      " [0.0577687 ]\n",
      " [0.02104219]\n",
      " [0.00598422]\n",
      " [0.01331546]\n",
      " [0.02236373]\n",
      " [0.01050256]\n",
      " [0.9933343 ]\n",
      " [0.9959841 ]\n",
      " [0.99199003]\n",
      " [0.9906782 ]\n",
      " [0.02112016]\n",
      " [0.0581009 ]\n",
      " [0.01906963]\n",
      " [0.9950541 ]\n",
      " [0.02333103]\n",
      " [0.9724213 ]\n",
      " [0.9964921 ]\n",
      " [0.9937093 ]\n",
      " [0.7033907 ]\n",
      " [0.99486333]\n",
      " [0.981471  ]\n",
      " [0.9939721 ]\n",
      " [0.9924935 ]\n",
      " [0.9880135 ]\n",
      " [0.97790694]\n",
      " [0.99090964]\n",
      " [0.9959708 ]\n",
      " [0.965753  ]\n",
      " [0.9747098 ]\n",
      " [0.9923959 ]\n",
      " [0.9957488 ]]\n",
      "[[0.9976035 ]\n",
      " [0.9983858 ]\n",
      " [0.99441445]\n",
      " [0.9849349 ]\n",
      " [0.9850382 ]\n",
      " [0.9649434 ]\n",
      " [0.9962386 ]\n",
      " [0.99021447]\n",
      " [0.98920536]\n",
      " [0.9933066 ]\n",
      " [0.9915697 ]\n",
      " [0.99339926]\n",
      " [0.99711215]\n",
      " [0.99571395]\n",
      " [0.9950722 ]\n",
      " [0.9967535 ]\n",
      " [0.99648076]\n",
      " [0.99377936]\n",
      " [0.9895985 ]\n",
      " [0.9932775 ]\n",
      " [0.9916682 ]\n",
      " [0.996135  ]\n",
      " [0.99206114]\n",
      " [0.9930906 ]\n",
      " [0.9945732 ]\n",
      " [0.9923943 ]\n",
      " [0.9893197 ]\n",
      " [0.99686   ]\n",
      " [0.9961385 ]\n",
      " [0.9937232 ]\n",
      " [0.99329937]\n",
      " [0.9929676 ]\n",
      " [0.99395907]\n",
      " [0.92237717]\n",
      " [0.957927  ]\n",
      " [0.8255781 ]\n",
      " [0.9756781 ]\n",
      " [0.99282455]\n",
      " [0.9913555 ]\n",
      " [0.9964935 ]\n",
      " [0.9974215 ]\n",
      " [0.9963104 ]\n",
      " [0.9948279 ]\n",
      " [0.9857766 ]\n",
      " [0.9753253 ]\n",
      " [0.99594986]\n",
      " [0.9964939 ]\n",
      " [0.99419916]\n",
      " [0.9973189 ]\n",
      " [0.99587435]\n",
      " [0.9877412 ]\n",
      " [0.99671113]\n",
      " [0.99772674]\n",
      " [0.988378  ]\n",
      " [0.9865866 ]\n",
      " [0.92257315]\n",
      " [0.9715873 ]\n",
      " [0.97749037]\n",
      " [0.98948914]\n",
      " [0.9964947 ]\n",
      " [0.9934209 ]\n",
      " [0.99623555]\n",
      " [0.9958406 ]\n",
      " [0.989382  ]\n",
      " [0.9730949 ]\n",
      " [0.9947983 ]\n",
      " [0.97931606]\n",
      " [0.9929132 ]\n",
      " [0.9458355 ]\n",
      " [0.9912395 ]\n",
      " [0.99615556]\n",
      " [0.9968811 ]\n",
      " [0.99733365]\n",
      " [0.99600214]\n",
      " [0.99361414]\n",
      " [0.9902739 ]\n",
      " [0.9963993 ]\n",
      " [0.99139696]\n",
      " [0.99565095]\n",
      " [0.99704367]\n",
      " [0.9929877 ]\n",
      " [0.9964881 ]\n",
      " [0.09968144]\n",
      " [0.36514804]\n",
      " [0.15113963]\n",
      " [0.02227629]\n",
      " [0.22857878]\n",
      " [0.5760699 ]\n",
      " [0.16615406]\n",
      " [0.09701307]\n",
      " [0.5959931 ]\n",
      " [0.02009987]\n",
      " [0.19997771]\n",
      " [0.8952819 ]\n",
      " [0.7796129 ]\n",
      " [0.4052907 ]\n",
      " [0.02978972]\n",
      " [0.1273858 ]\n",
      " [0.02391166]\n",
      " [0.23499487]\n",
      " [0.7029679 ]\n",
      " [0.28529802]\n",
      " [0.04558184]\n",
      " [0.0229287 ]\n",
      " [0.02292109]\n",
      " [0.08924718]\n",
      " [0.5048805 ]]\n",
      "[[0.9408435 ]\n",
      " [0.865369  ]\n",
      " [0.52375674]\n",
      " [0.88915884]\n",
      " [0.76493174]\n",
      " [0.8089309 ]\n",
      " [0.53566897]\n",
      " [0.9288803 ]\n",
      " [0.8825529 ]\n",
      " [0.56410646]\n",
      " [0.9777699 ]\n",
      " [0.9564347 ]\n",
      " [0.8106937 ]\n",
      " [0.97957844]\n",
      " [0.843054  ]\n",
      " [0.917724  ]\n",
      " [0.7849923 ]\n",
      " [0.8695873 ]\n",
      " [0.839994  ]\n",
      " [0.7285935 ]\n",
      " [0.7674106 ]\n",
      " [0.8543694 ]\n",
      " [0.9968129 ]\n",
      " [0.99601597]\n",
      " [0.99768376]\n",
      " [0.99702734]\n",
      " [0.99709404]\n",
      " [0.9965197 ]\n",
      " [0.98715264]\n",
      " [0.99682164]\n",
      " [0.9968798 ]\n",
      " [0.988509  ]\n",
      " [0.9970294 ]\n",
      " [0.99299026]\n",
      " [0.9965467 ]\n",
      " [0.9935935 ]\n",
      " [0.99677163]\n",
      " [0.99489033]\n",
      " [0.9972287 ]\n",
      " [0.9955739 ]\n",
      " [0.99740964]\n",
      " [0.99579394]\n",
      " [0.9959074 ]\n",
      " [0.98127973]\n",
      " [0.9967679 ]\n",
      " [0.99471396]\n",
      " [0.9969253 ]\n",
      " [0.9969193 ]\n",
      " [0.9961939 ]\n",
      " [0.9939084 ]\n",
      " [0.9968509 ]\n",
      " [0.9969375 ]\n",
      " [0.9915103 ]\n",
      " [0.9953172 ]\n",
      " [0.997265  ]\n",
      " [0.99564856]\n",
      " [0.99732816]\n",
      " [0.995471  ]\n",
      " [0.9953414 ]\n",
      " [0.9953127 ]\n",
      " [0.99653447]\n",
      " [0.99706155]\n",
      " [0.99233425]\n",
      " [0.9933334 ]\n",
      " [0.99638796]\n",
      " [0.9957212 ]\n",
      " [0.9857956 ]\n",
      " [0.98704135]\n",
      " [0.9953849 ]\n",
      " [0.99084187]\n",
      " [0.9976896 ]\n",
      " [0.995475  ]\n",
      " [0.9973953 ]\n",
      " [0.9934041 ]\n",
      " [0.9962012 ]\n",
      " [0.9939857 ]\n",
      " [0.9952225 ]\n",
      " [0.9953601 ]\n",
      " [0.9964713 ]\n",
      " [0.99531096]\n",
      " [0.99738985]\n",
      " [0.9961545 ]\n",
      " [0.99667966]\n",
      " [0.9952619 ]\n",
      " [0.99723095]\n",
      " [0.9967872 ]\n",
      " [0.9958978 ]\n",
      " [0.98959035]\n",
      " [0.9961584 ]\n",
      " [0.99180025]\n",
      " [0.9854455 ]\n",
      " [0.99396485]\n",
      " [0.9940872 ]\n",
      " [0.9960103 ]\n",
      " [0.996983  ]\n",
      " [0.99784935]\n",
      " [0.99678123]\n",
      " [0.9965628 ]\n",
      " [0.99547404]\n",
      " [0.99618995]\n",
      " [0.9962058 ]\n",
      " [0.9969382 ]\n",
      " [0.9959857 ]\n",
      " [0.99522275]\n",
      " [0.9966388 ]\n",
      " [0.9965849 ]\n",
      " [0.99398005]\n",
      " [0.99359655]\n",
      " [0.99691653]\n",
      " [0.99634784]\n",
      " [0.99150145]\n",
      " [0.9769579 ]\n",
      " [0.99491525]\n",
      " [0.99594206]\n",
      " [0.9980525 ]\n",
      " [0.9982797 ]\n",
      " [0.9973182 ]\n",
      " [0.99547994]\n",
      " [0.9965867 ]\n",
      " [0.99751604]\n",
      " [0.994426  ]\n",
      " [0.9942252 ]\n",
      " [0.99515766]\n",
      " [0.99740857]]\n",
      "[[0.02368893]\n",
      " [0.01119364]\n",
      " [0.01540183]\n",
      " [0.01228396]\n",
      " [0.3577324 ]\n",
      " [0.00831072]\n",
      " [0.0146746 ]\n",
      " [0.07376591]\n",
      " [0.01317374]\n",
      " [0.02060159]\n",
      " [0.00521424]\n",
      " [0.00953273]\n",
      " [0.00569437]\n",
      " [0.00504795]\n",
      " [0.15009125]\n",
      " [0.9936559 ]\n",
      " [0.996442  ]\n",
      " [0.9825764 ]\n",
      " [0.9964162 ]\n",
      " [0.944573  ]\n",
      " [0.99379444]\n",
      " [0.91285324]\n",
      " [0.99410397]\n",
      " [0.9911225 ]\n",
      " [0.9959869 ]\n",
      " [0.99711955]\n",
      " [0.98491746]\n",
      " [0.99433666]\n",
      " [0.99075526]\n",
      " [0.99561936]\n",
      " [0.99307126]\n",
      " [0.73814327]\n",
      " [0.9940475 ]\n",
      " [0.97524387]\n",
      " [0.9363541 ]\n",
      " [0.9914961 ]\n",
      " [0.41551894]\n",
      " [0.9705702 ]\n",
      " [0.993975  ]\n",
      " [0.99584705]\n",
      " [0.9954136 ]\n",
      " [0.8689188 ]\n",
      " [0.99589396]\n",
      " [0.9962287 ]\n",
      " [0.987745  ]\n",
      " [0.9939203 ]\n",
      " [0.991169  ]\n",
      " [0.96205425]\n",
      " [0.9961117 ]\n",
      " [0.9939224 ]\n",
      " [0.99458104]\n",
      " [0.9956311 ]\n",
      " [0.9896153 ]\n",
      " [0.99586535]\n",
      " [0.9918635 ]\n",
      " [0.9661439 ]\n",
      " [0.95915866]\n",
      " [0.95263106]\n",
      " [0.9963599 ]\n",
      " [0.92506665]\n",
      " [0.91003686]\n",
      " [0.9905352 ]\n",
      " [0.99394894]\n",
      " [0.99456394]\n",
      " [0.9935469 ]\n",
      " [0.98064923]\n",
      " [0.989056  ]\n",
      " [0.9952024 ]\n",
      " [0.99527353]\n",
      " [0.9958545 ]\n",
      " [0.9696814 ]\n",
      " [0.95869327]\n",
      " [0.04548588]\n",
      " [0.9521625 ]\n",
      " [0.9820425 ]\n",
      " [0.9867677 ]\n",
      " [0.9361028 ]\n",
      " [0.97494966]\n",
      " [0.98629737]\n",
      " [0.79444015]\n",
      " [0.9884692 ]\n",
      " [0.9649871 ]\n",
      " [0.95551234]\n",
      " [0.9767904 ]\n",
      " [0.00553531]\n",
      " [0.9926602 ]\n",
      " [0.99540174]\n",
      " [0.984831  ]\n",
      " [0.99500763]\n",
      " [0.98821694]\n",
      " [0.98847544]\n",
      " [0.99538666]\n",
      " [0.96110475]\n",
      " [0.9613539 ]\n",
      " [0.98550284]\n",
      " [0.97484493]\n",
      " [0.9262871 ]\n",
      " [0.9936655 ]\n",
      " [0.99385464]\n",
      " [0.05245775]\n",
      " [0.95869654]\n",
      " [0.9949915 ]\n",
      " [0.9789612 ]\n",
      " [0.9837569 ]\n",
      " [0.65277296]\n",
      " [0.9684418 ]\n",
      " [0.9930218 ]\n",
      " [0.83618665]\n",
      " [0.9950428 ]\n",
      " [0.995577  ]\n",
      " [0.98309386]\n",
      " [0.990236  ]\n",
      " [0.99047583]\n",
      " [0.9942654 ]\n",
      " [0.9897503 ]\n",
      " [0.98550874]\n",
      " [0.4798999 ]\n",
      " [0.36578652]\n",
      " [0.9956878 ]\n",
      " [0.9428606 ]\n",
      " [0.95941013]\n",
      " [0.9938945 ]\n",
      " [0.99355936]]\n",
      "[[0.05561702]\n",
      " [0.05070572]\n",
      " [0.05083846]\n",
      " [0.04972505]\n",
      " [0.07699868]\n",
      " [0.05002455]\n",
      " [0.05601512]\n",
      " [0.05198259]\n",
      " [0.05113637]\n",
      " [0.05177169]\n",
      " [0.05187984]\n",
      " [0.05197267]\n",
      " [0.04640348]\n",
      " [0.0455243 ]\n",
      " [0.05017241]\n",
      " [0.99841225]\n",
      " [0.9985049 ]\n",
      " [0.64402497]\n",
      " [0.99217355]\n",
      " [0.05481317]\n",
      " [0.9899629 ]\n",
      " [0.99808216]\n",
      " [0.26889503]\n",
      " [0.84871805]\n",
      " [0.98524666]\n",
      " [0.09498926]\n",
      " [0.9780256 ]\n",
      " [0.1511642 ]\n",
      " [0.05493537]\n",
      " [0.28626963]\n",
      " [0.9984646 ]\n",
      " [0.9067195 ]\n",
      " [0.4384425 ]\n",
      " [0.99696285]\n",
      " [0.8553076 ]\n",
      " [0.987479  ]\n",
      " [0.05854533]\n",
      " [0.15073228]\n",
      " [0.9900517 ]\n",
      " [0.96969205]\n",
      " [0.07786497]\n",
      " [0.07924629]\n",
      " [0.21303363]\n",
      " [0.282927  ]\n",
      " [0.23141356]\n",
      " [0.9887701 ]\n",
      " [0.99363625]\n",
      " [0.18604313]\n",
      " [0.9906115 ]\n",
      " [0.05330046]\n",
      " [0.9915548 ]\n",
      " [0.9979645 ]\n",
      " [0.7634839 ]\n",
      " [0.07898837]\n",
      " [0.92323434]\n",
      " [0.27596852]\n",
      " [0.8796266 ]\n",
      " [0.05342093]\n",
      " [0.9954543 ]\n",
      " [0.12328415]\n",
      " [0.8527556 ]\n",
      " [0.8769757 ]\n",
      " [0.9965744 ]\n",
      " [0.9892    ]\n",
      " [0.26914144]\n",
      " [0.9943473 ]\n",
      " [0.06082756]\n",
      " [0.28941205]\n",
      " [0.9832023 ]\n",
      " [0.06029928]\n",
      " [0.0858215 ]\n",
      " [0.07119081]\n",
      " [0.05992804]\n",
      " [0.5441005 ]\n",
      " [0.07841987]]\n",
      "[[0.06818142]\n",
      " [0.0713983 ]\n",
      " [0.99747497]\n",
      " [0.74736494]\n",
      " [0.8517067 ]\n",
      " [0.20682964]\n",
      " [0.99520564]\n",
      " [0.07498138]\n",
      " [0.21777236]\n",
      " [0.18765719]\n",
      " [0.99291795]\n",
      " [0.9827602 ]\n",
      " [0.97780776]\n",
      " [0.7206414 ]\n",
      " [0.8757712 ]\n",
      " [0.99100775]\n",
      " [0.99782217]\n",
      " [0.7317934 ]\n",
      " [0.9994306 ]\n",
      " [0.7461252 ]\n",
      " [0.9664649 ]\n",
      " [0.04911759]\n",
      " [0.04492309]\n",
      " [0.04597589]\n",
      " [0.05143599]\n",
      " [0.05189593]\n",
      " [0.05314447]\n",
      " [0.05146074]\n",
      " [0.05176859]\n",
      " [0.05661298]\n",
      " [0.0511425 ]\n",
      " [0.08788364]\n",
      " [0.06662061]\n",
      " [0.9679698 ]\n",
      " [0.09844605]\n",
      " [0.7200151 ]\n",
      " [0.9937344 ]\n",
      " [0.11911519]\n",
      " [0.08587483]\n",
      " [0.55244786]\n",
      " [0.04957316]\n",
      " [0.05138944]\n",
      " [0.05163907]\n",
      " [0.05553412]\n",
      " [0.08369161]]\n",
      "[[0.05186308]\n",
      " [0.05277998]\n",
      " [0.04605448]\n",
      " [0.04840845]\n",
      " [0.04383234]\n",
      " [0.0446393 ]\n",
      " [0.05212166]\n",
      " [0.05252736]\n",
      " [0.05109936]\n",
      " [0.04906449]\n",
      " [0.05145731]\n",
      " [0.05561747]\n",
      " [0.05119997]\n",
      " [0.08951502]\n",
      " [0.04980175]\n",
      " [0.05154505]\n",
      " [0.05048909]\n",
      " [0.05612021]\n",
      " [0.19128276]\n",
      " [0.9976451 ]\n",
      " [0.8327482 ]\n",
      " [0.9398077 ]\n",
      " [0.06164093]\n",
      " [0.9916692 ]\n",
      " [0.24601011]\n",
      " [0.98250985]\n",
      " [0.98216796]\n",
      " [0.19237368]\n",
      " [0.19890344]\n",
      " [0.08774411]\n",
      " [0.08539592]\n",
      " [0.84570867]\n",
      " [0.60854846]\n",
      " [0.42743644]\n",
      " [0.8321306 ]\n",
      " [0.71287924]\n",
      " [0.35283166]\n",
      " [0.9582811 ]\n",
      " [0.06214684]\n",
      " [0.05744388]\n",
      " [0.4304884 ]\n",
      " [0.96070343]\n",
      " [0.35373962]\n",
      " [0.06823403]\n",
      " [0.86154115]\n",
      " [0.9982895 ]\n",
      " [0.10186123]\n",
      " [0.76430905]\n",
      " [0.05800073]\n",
      " [0.99879694]\n",
      " [0.07377582]\n",
      " [0.05670776]\n",
      " [0.6726122 ]\n",
      " [0.07369061]\n",
      " [0.45850518]\n",
      " [0.36253974]\n",
      " [0.19684497]\n",
      " [0.05269917]\n",
      " [0.9265653 ]\n",
      " [0.9527677 ]\n",
      " [0.9807536 ]\n",
      " [0.10625561]\n",
      " [0.0505281 ]\n",
      " [0.9413545 ]\n",
      " [0.06697412]\n",
      " [0.05755751]\n",
      " [0.23050678]\n",
      " [0.8626979 ]\n",
      " [0.04836065]\n",
      " [0.04753172]]\n",
      "[[0.99439913]\n",
      " [0.9871294 ]\n",
      " [0.9965578 ]\n",
      " [0.9805951 ]\n",
      " [0.9961953 ]\n",
      " [0.9869654 ]\n",
      " [0.8947041 ]\n",
      " [0.9923717 ]\n",
      " [0.35408446]\n",
      " [0.9975017 ]\n",
      " [0.9962521 ]\n",
      " [0.95260704]\n",
      " [0.9957242 ]\n",
      " [0.01659886]\n",
      " [0.0428472 ]\n",
      " [0.00619192]\n",
      " [0.02475248]\n",
      " [0.06883808]\n",
      " [0.99605834]\n",
      " [0.9705575 ]\n",
      " [0.9898713 ]\n",
      " [0.98458016]\n",
      " [0.9890505 ]\n",
      " [0.9855203 ]\n",
      " [0.9892051 ]\n",
      " [0.97381645]\n",
      " [0.9804354 ]\n",
      " [0.99179196]\n",
      " [0.9947437 ]\n",
      " [0.99453074]\n",
      " [0.03403777]\n",
      " [0.00899599]\n",
      " [0.02303346]\n",
      " [0.00550743]\n",
      " [0.01910555]\n",
      " [0.18922707]\n",
      " [0.9955403 ]\n",
      " [0.98457944]\n",
      " [0.99549305]\n",
      " [0.99473757]\n",
      " [0.9897686 ]\n",
      " [0.5917708 ]\n",
      " [0.9932921 ]\n",
      " [0.99376005]\n",
      " [0.9665436 ]\n",
      " [0.9785582 ]\n",
      " [0.9923603 ]\n",
      " [0.9938998 ]\n",
      " [0.993741  ]\n",
      " [0.99335206]\n",
      " [0.9831284 ]\n",
      " [0.9906917 ]\n",
      " [0.95241016]\n",
      " [0.8311007 ]\n",
      " [0.02050629]\n",
      " [0.92752546]\n",
      " [0.98942566]\n",
      " [0.9902262 ]\n",
      " [0.99308044]\n",
      " [0.9908568 ]\n",
      " [0.93496025]\n",
      " [0.22009751]\n",
      " [0.54323953]\n",
      " [0.03152148]\n",
      " [0.9928484 ]\n",
      " [0.9894237 ]\n",
      " [0.9896834 ]\n",
      " [0.99412835]\n",
      " [0.9223224 ]\n",
      " [0.9677789 ]\n",
      " [0.9935262 ]\n",
      " [0.9880911 ]\n",
      " [0.99746084]\n",
      " [0.877365  ]\n",
      " [0.9962263 ]\n",
      " [0.99345183]\n",
      " [0.9846333 ]\n",
      " [0.01173122]\n",
      " [0.01489492]\n",
      " [0.99588794]\n",
      " [0.9957105 ]\n",
      " [0.21000314]\n",
      " [0.709831  ]\n",
      " [0.95702136]\n",
      " [0.1140812 ]\n",
      " [0.01000727]\n",
      " [0.7870228 ]\n",
      " [0.9951691 ]\n",
      " [0.01668873]\n",
      " [0.01256636]\n",
      " [0.01860622]\n",
      " [0.09176885]\n",
      " [0.9963671 ]\n",
      " [0.99552935]\n",
      " [0.9925948 ]\n",
      " [0.9951074 ]\n",
      " [0.9504699 ]\n",
      " [0.9949831 ]\n",
      " [0.98323935]\n",
      " [0.37077972]\n",
      " [0.24002668]\n",
      " [0.9918424 ]\n",
      " [0.9821655 ]]\n",
      "[[0.97863626]\n",
      " [0.9715057 ]\n",
      " [0.995972  ]\n",
      " [0.9980738 ]\n",
      " [0.9970595 ]\n",
      " [0.99664056]\n",
      " [0.99753237]\n",
      " [0.9908669 ]\n",
      " [0.98940533]\n",
      " [0.9581594 ]\n",
      " [0.05094984]\n",
      " [0.37399027]\n",
      " [0.12975697]\n",
      " [0.03197476]\n",
      " [0.6279354 ]\n",
      " [0.04227326]\n",
      " [0.02147604]\n",
      " [0.9291135 ]\n",
      " [0.50484324]\n",
      " [0.42962822]\n",
      " [0.10850587]\n",
      " [0.0573804 ]\n",
      " [0.04851469]\n",
      " [0.22449721]\n",
      " [0.15127057]\n",
      " [0.06324621]\n",
      " [0.07702407]\n",
      " [0.46170118]\n",
      " [0.33935457]\n",
      " [0.4074328 ]]\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_74 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 2s 72ms/step - loss: 1.3909 - accuracy: 0.7254 - val_loss: 0.3928 - val_accuracy: 0.8636\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.9947 - accuracy: 0.6907 - val_loss: 0.5589 - val_accuracy: 0.8636\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6523 - accuracy: 0.7835 - val_loss: 0.7364 - val_accuracy: 0.1364\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6705 - accuracy: 0.2817 - val_loss: 0.7930 - val_accuracy: 0.1364\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6644 - accuracy: 0.2509 - val_loss: 0.6895 - val_accuracy: 0.5455\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6525 - accuracy: 0.6326 - val_loss: 0.6146 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6860 - accuracy: 0.7637 - val_loss: 0.6557 - val_accuracy: 0.9545\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7091 - accuracy: 0.6783 - val_loss: 0.6884 - val_accuracy: 0.5455\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6348 - accuracy: 0.7036 - val_loss: 0.6153 - val_accuracy: 0.9091\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6607 - accuracy: 0.8533 - val_loss: 0.6084 - val_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6647 - accuracy: 0.8666 - val_loss: 0.6305 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6765 - accuracy: 0.8327 - val_loss: 0.6564 - val_accuracy: 0.8182\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5911 - accuracy: 0.8792 - val_loss: 0.5978 - val_accuracy: 0.9091\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6724 - accuracy: 0.8447 - val_loss: 0.6670 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6030 - accuracy: 0.7165 - val_loss: 0.6130 - val_accuracy: 0.9091\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6069 - accuracy: 0.8648 - val_loss: 0.6274 - val_accuracy: 0.9545\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6127 - accuracy: 0.9045 - val_loss: 0.5984 - val_accuracy: 0.8636\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.6193 - accuracy: 0.8947 - val_loss: 0.6326 - val_accuracy: 0.8636\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6088 - accuracy: 0.8835 - val_loss: 0.5995 - val_accuracy: 0.9091\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6332 - accuracy: 0.8632 - val_loss: 0.5961 - val_accuracy: 0.9091\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 2s 97ms/step - loss: 0.6137 - binary_accuracy: 0.8639 - val_loss: 0.6143 - val_binary_accuracy: 0.8636\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5655 - binary_accuracy: 0.8896 - val_loss: 0.5903 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5644 - binary_accuracy: 0.8889 - val_loss: 0.5756 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5518 - binary_accuracy: 0.8779 - val_loss: 0.5760 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5811 - binary_accuracy: 0.8572 - val_loss: 0.5278 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6136 - binary_accuracy: 0.8866 - val_loss: 0.5307 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5120 - binary_accuracy: 0.9409 - val_loss: 0.4997 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5017 - binary_accuracy: 0.8819 - val_loss: 0.5623 - val_binary_accuracy: 0.8636\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4839 - binary_accuracy: 0.8677 - val_loss: 0.5366 - val_binary_accuracy: 0.8636\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4677 - binary_accuracy: 0.9288 - val_loss: 0.4759 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4903 - binary_accuracy: 0.9651 - val_loss: 0.4750 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4684 - binary_accuracy: 0.9724 - val_loss: 0.4708 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4441 - binary_accuracy: 0.9526 - val_loss: 0.4337 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3880 - binary_accuracy: 0.9950 - val_loss: 0.4379 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.3971 - binary_accuracy: 0.9434 - val_loss: 0.4735 - val_binary_accuracy: 0.8636\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4213 - binary_accuracy: 0.9181 - val_loss: 0.3839 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3836 - binary_accuracy: 0.9855 - val_loss: 0.3549 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.3618 - binary_accuracy: 0.9744 - val_loss: 0.4223 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3656 - binary_accuracy: 0.9335 - val_loss: 0.3284 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3503 - binary_accuracy: 0.9738 - val_loss: 0.3207 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3472 - binary_accuracy: 0.9384 - val_loss: 0.3063 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.2931 - binary_accuracy: 1.0000 - val_loss: 0.2690 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2614 - binary_accuracy: 0.9673 - val_loss: 0.3108 - val_binary_accuracy: 0.9091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.2603 - binary_accuracy: 0.9078 - val_loss: 0.2334 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2138 - binary_accuracy: 0.9897 - val_loss: 0.2408 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1986 - binary_accuracy: 0.9819 - val_loss: 0.2003 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1784 - binary_accuracy: 0.9805 - val_loss: 0.1713 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.1750 - binary_accuracy: 0.9216 - val_loss: 0.1630 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1460 - binary_accuracy: 0.9976 - val_loss: 0.1268 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1113 - binary_accuracy: 0.9964 - val_loss: 0.1281 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1150 - binary_accuracy: 0.9855 - val_loss: 0.1099 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1094 - binary_accuracy: 0.9888 - val_loss: 0.0854 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0835 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.1132 - binary_accuracy: 0.9705 - val_loss: 0.0969 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0701 - binary_accuracy: 0.9913 - val_loss: 0.0662 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0712 - binary_accuracy: 1.0000 - val_loss: 0.0821 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0656 - binary_accuracy: 0.9964 - val_loss: 0.0594 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0595 - binary_accuracy: 1.0000 - val_loss: 0.0833 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0689 - binary_accuracy: 0.9671 - val_loss: 0.0512 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.0521 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0503 - binary_accuracy: 1.0000 - val_loss: 0.0572 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0475 - binary_accuracy: 1.0000 - val_loss: 0.0392 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0365 - binary_accuracy: 1.0000 - val_loss: 0.0453 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0413 - binary_accuracy: 1.0000 - val_loss: 0.0458 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0392 - binary_accuracy: 0.9933 - val_loss: 0.0393 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0266 - binary_accuracy: 1.0000 - val_loss: 0.0357 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0571 - binary_accuracy: 0.9749 - val_loss: 0.0409 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0491 - binary_accuracy: 1.0000 - val_loss: 0.0456 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0590 - binary_accuracy: 0.9753 - val_loss: 0.0618 - val_binary_accuracy: 0.9545\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0407 - binary_accuracy: 1.0000 - val_loss: 0.0266 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 57065\n",
      "[[0.9933113 ]\n",
      " [0.4873388 ]\n",
      " [0.9488327 ]\n",
      " [0.983295  ]\n",
      " [0.6304096 ]\n",
      " [0.756442  ]\n",
      " [0.99458826]\n",
      " [0.40365523]\n",
      " [0.99367875]\n",
      " [0.9942859 ]\n",
      " [0.9956269 ]\n",
      " [0.8607373 ]\n",
      " [0.93917584]\n",
      " [0.98660266]\n",
      " [0.9954699 ]\n",
      " [0.9808394 ]\n",
      " [0.29975   ]\n",
      " [0.9821447 ]\n",
      " [0.98786163]\n",
      " [0.99124545]\n",
      " [0.9904765 ]\n",
      " [0.23583393]\n",
      " [0.5967752 ]\n",
      " [0.44341832]\n",
      " [0.9272301 ]\n",
      " [0.8612365 ]\n",
      " [0.1043927 ]\n",
      " [0.7512897 ]\n",
      " [0.6333235 ]\n",
      " [0.96698785]\n",
      " [0.986226  ]\n",
      " [0.5265447 ]\n",
      " [0.9789667 ]\n",
      " [0.12936574]\n",
      " [0.97491235]\n",
      " [0.9128795 ]\n",
      " [0.6550934 ]\n",
      " [0.6612419 ]\n",
      " [0.66456485]\n",
      " [0.9921101 ]\n",
      " [0.0110356 ]\n",
      " [0.02017538]\n",
      " [0.01653363]\n",
      " [0.9742785 ]\n",
      " [0.995533  ]\n",
      " [0.99416167]\n",
      " [0.98902017]\n",
      " [0.10209868]\n",
      " [0.11575039]\n",
      " [0.02580432]\n",
      " [0.04514264]\n",
      " [0.0597786 ]\n",
      " [0.8545306 ]\n",
      " [0.9947136 ]\n",
      " [0.9769046 ]\n",
      " [0.98617274]\n",
      " [0.968544  ]\n",
      " [0.98726916]\n",
      " [0.99072814]\n",
      " [0.976647  ]\n",
      " [0.9807066 ]\n",
      " [0.7721969 ]\n",
      " [0.99047756]\n",
      " [0.98309636]\n",
      " [0.78605604]\n",
      " [0.77997446]\n",
      " [0.9259944 ]\n",
      " [0.9601964 ]\n",
      " [0.9459506 ]\n",
      " [0.6361462 ]\n",
      " [0.98779476]\n",
      " [0.8040703 ]\n",
      " [0.92844003]\n",
      " [0.6281781 ]\n",
      " [0.9779871 ]\n",
      " [0.91944   ]\n",
      " [0.7692283 ]\n",
      " [0.9934609 ]\n",
      " [0.06888703]\n",
      " [0.01115434]\n",
      " [0.42887744]\n",
      " [0.01614913]\n",
      " [0.03619497]\n",
      " [0.03154229]\n",
      " [0.06074719]\n",
      " [0.81253284]\n",
      " [0.02907551]\n",
      " [0.11744916]\n",
      " [0.08093059]\n",
      " [0.02139479]\n",
      " [0.99262094]\n",
      " [0.17663747]\n",
      " [0.9699163 ]\n",
      " [0.97255206]\n",
      " [0.98691285]\n",
      " [0.99144346]\n",
      " [0.07180179]\n",
      " [0.02203926]\n",
      " [0.0818468 ]\n",
      " [0.04595917]\n",
      " [0.0351771 ]\n",
      " [0.00983529]\n",
      " [0.01944768]\n",
      " [0.01799708]\n",
      " [0.01214845]\n",
      " [0.9795775 ]\n",
      " [0.9959416 ]\n",
      " [0.9747483 ]\n",
      " [0.9338384 ]\n",
      " [0.04391155]\n",
      " [0.0632731 ]\n",
      " [0.04351404]\n",
      " [0.99100155]\n",
      " [0.04334456]\n",
      " [0.92012393]\n",
      " [0.99394035]\n",
      " [0.98487574]\n",
      " [0.47400004]\n",
      " [0.98125386]\n",
      " [0.7540154 ]\n",
      " [0.9718741 ]\n",
      " [0.9535103 ]\n",
      " [0.804513  ]\n",
      " [0.5757787 ]\n",
      " [0.91653496]\n",
      " [0.9918052 ]\n",
      " [0.4538506 ]\n",
      " [0.3783988 ]\n",
      " [0.96185416]\n",
      " [0.99261004]]\n",
      "[[0.998887  ]\n",
      " [0.99931204]\n",
      " [0.99751943]\n",
      " [0.99180084]\n",
      " [0.9890458 ]\n",
      " [0.9738602 ]\n",
      " [0.99692184]\n",
      " [0.98739946]\n",
      " [0.9806311 ]\n",
      " [0.995522  ]\n",
      " [0.9927114 ]\n",
      " [0.9896666 ]\n",
      " [0.997867  ]\n",
      " [0.997317  ]\n",
      " [0.9959727 ]\n",
      " [0.99779737]\n",
      " [0.9976891 ]\n",
      " [0.9930161 ]\n",
      " [0.9834727 ]\n",
      " [0.9961743 ]\n",
      " [0.98318326]\n",
      " [0.9950808 ]\n",
      " [0.99049497]\n",
      " [0.9903654 ]\n",
      " [0.9948874 ]\n",
      " [0.99471694]\n",
      " [0.9828583 ]\n",
      " [0.99741566]\n",
      " [0.99753237]\n",
      " [0.99440575]\n",
      " [0.9946233 ]\n",
      " [0.9894014 ]\n",
      " [0.99291587]\n",
      " [0.8757835 ]\n",
      " [0.9299581 ]\n",
      " [0.7833242 ]\n",
      " [0.9288925 ]\n",
      " [0.992851  ]\n",
      " [0.9878302 ]\n",
      " [0.9969886 ]\n",
      " [0.998594  ]\n",
      " [0.99705136]\n",
      " [0.9965501 ]\n",
      " [0.98674715]\n",
      " [0.9597439 ]\n",
      " [0.9965857 ]\n",
      " [0.99816424]\n",
      " [0.99603564]\n",
      " [0.99820006]\n",
      " [0.996635  ]\n",
      " [0.8951042 ]\n",
      " [0.99718165]\n",
      " [0.99923646]\n",
      " [0.9925264 ]\n",
      " [0.9901445 ]\n",
      " [0.8019175 ]\n",
      " [0.9479927 ]\n",
      " [0.9666758 ]\n",
      " [0.9888754 ]\n",
      " [0.9975526 ]\n",
      " [0.9938048 ]\n",
      " [0.994712  ]\n",
      " [0.99558663]\n",
      " [0.97653824]\n",
      " [0.8554789 ]\n",
      " [0.9958703 ]\n",
      " [0.9666781 ]\n",
      " [0.9954014 ]\n",
      " [0.9363953 ]\n",
      " [0.98145604]\n",
      " [0.9974239 ]\n",
      " [0.99777263]\n",
      " [0.99793756]\n",
      " [0.9963741 ]\n",
      " [0.99485505]\n",
      " [0.9922192 ]\n",
      " [0.9977598 ]\n",
      " [0.9942326 ]\n",
      " [0.99608684]\n",
      " [0.998338  ]\n",
      " [0.99576867]\n",
      " [0.99701333]\n",
      " [0.06090872]\n",
      " [0.04281784]\n",
      " [0.04475931]\n",
      " [0.01287771]\n",
      " [0.07474305]\n",
      " [0.05063762]\n",
      " [0.02268066]\n",
      " [0.01773969]\n",
      " [0.05592869]\n",
      " [0.00594408]\n",
      " [0.03213777]\n",
      " [0.14425689]\n",
      " [0.08856607]\n",
      " [0.2163279 ]\n",
      " [0.02409787]\n",
      " [0.04119409]\n",
      " [0.0115586 ]\n",
      " [0.03400121]\n",
      " [0.07817911]\n",
      " [0.08598599]\n",
      " [0.02125985]\n",
      " [0.01889544]\n",
      " [0.01502997]\n",
      " [0.04398112]\n",
      " [0.11122511]]\n",
      "[[0.5389168 ]\n",
      " [0.43461326]\n",
      " [0.22523738]\n",
      " [0.39906007]\n",
      " [0.32037535]\n",
      " [0.2217708 ]\n",
      " [0.18947805]\n",
      " [0.4861827 ]\n",
      " [0.3792717 ]\n",
      " [0.18706115]\n",
      " [0.7818679 ]\n",
      " [0.5650154 ]\n",
      " [0.29273593]\n",
      " [0.7957359 ]\n",
      " [0.3655994 ]\n",
      " [0.62301594]\n",
      " [0.3689359 ]\n",
      " [0.35893738]\n",
      " [0.29742557]\n",
      " [0.19865394]\n",
      " [0.28807828]\n",
      " [0.37688547]\n",
      " [0.99626714]\n",
      " [0.99620557]\n",
      " [0.99837947]\n",
      " [0.9979943 ]\n",
      " [0.9974905 ]\n",
      " [0.99642485]\n",
      " [0.9878902 ]\n",
      " [0.9974463 ]\n",
      " [0.9978515 ]\n",
      " [0.9675154 ]\n",
      " [0.99786633]\n",
      " [0.9881671 ]\n",
      " [0.9966264 ]\n",
      " [0.9924591 ]\n",
      " [0.99758446]\n",
      " [0.990724  ]\n",
      " [0.99762183]\n",
      " [0.9932848 ]\n",
      " [0.99769586]\n",
      " [0.9946673 ]\n",
      " [0.99458367]\n",
      " [0.91494954]\n",
      " [0.9971239 ]\n",
      " [0.99448746]\n",
      " [0.9969971 ]\n",
      " [0.9964444 ]\n",
      " [0.99607027]\n",
      " [0.9939057 ]\n",
      " [0.99672616]\n",
      " [0.9971207 ]\n",
      " [0.9895523 ]\n",
      " [0.9917162 ]\n",
      " [0.9979473 ]\n",
      " [0.99650276]\n",
      " [0.9982468 ]\n",
      " [0.99516284]\n",
      " [0.99479634]\n",
      " [0.99604464]\n",
      " [0.9967069 ]\n",
      " [0.99746764]\n",
      " [0.98312896]\n",
      " [0.9888798 ]\n",
      " [0.9967327 ]\n",
      " [0.99541795]\n",
      " [0.974815  ]\n",
      " [0.92768013]\n",
      " [0.99497694]\n",
      " [0.98357403]\n",
      " [0.99848276]\n",
      " [0.9958098 ]\n",
      " [0.99790925]\n",
      " [0.98930055]\n",
      " [0.99690163]\n",
      " [0.9919292 ]\n",
      " [0.9945833 ]\n",
      " [0.9920034 ]\n",
      " [0.9976755 ]\n",
      " [0.99651825]\n",
      " [0.99790394]\n",
      " [0.99477863]\n",
      " [0.9968965 ]\n",
      " [0.99443084]\n",
      " [0.9973295 ]\n",
      " [0.9970745 ]\n",
      " [0.9948368 ]\n",
      " [0.94918174]\n",
      " [0.99682707]\n",
      " [0.9793097 ]\n",
      " [0.97403276]\n",
      " [0.9898233 ]\n",
      " [0.99292374]\n",
      " [0.99421763]\n",
      " [0.99674207]\n",
      " [0.9987809 ]\n",
      " [0.99742633]\n",
      " [0.9970892 ]\n",
      " [0.9953949 ]\n",
      " [0.9971718 ]\n",
      " [0.99618727]\n",
      " [0.9969602 ]\n",
      " [0.996407  ]\n",
      " [0.99407035]\n",
      " [0.99615246]\n",
      " [0.99650675]\n",
      " [0.99293846]\n",
      " [0.99215925]\n",
      " [0.99780506]\n",
      " [0.99634534]\n",
      " [0.98351514]\n",
      " [0.95248264]\n",
      " [0.9954177 ]\n",
      " [0.995684  ]\n",
      " [0.9988834 ]\n",
      " [0.9985537 ]\n",
      " [0.99630797]\n",
      " [0.9951047 ]\n",
      " [0.9961063 ]\n",
      " [0.9977604 ]\n",
      " [0.9914076 ]\n",
      " [0.98827887]\n",
      " [0.9932313 ]\n",
      " [0.9982368 ]]\n",
      "[[0.02737489]\n",
      " [0.02426681]\n",
      " [0.03457173]\n",
      " [0.02737013]\n",
      " [0.24165113]\n",
      " [0.01399262]\n",
      " [0.07244207]\n",
      " [0.07325758]\n",
      " [0.01679739]\n",
      " [0.04739311]\n",
      " [0.01940632]\n",
      " [0.02463598]\n",
      " [0.00922984]\n",
      " [0.00629471]\n",
      " [0.04630604]\n",
      " [0.9929715 ]\n",
      " [0.99661225]\n",
      " [0.99440056]\n",
      " [0.9958591 ]\n",
      " [0.863288  ]\n",
      " [0.9919103 ]\n",
      " [0.646963  ]\n",
      " [0.9814416 ]\n",
      " [0.9908818 ]\n",
      " [0.995501  ]\n",
      " [0.99830925]\n",
      " [0.9615125 ]\n",
      " [0.994626  ]\n",
      " [0.9408165 ]\n",
      " [0.99228823]\n",
      " [0.9807767 ]\n",
      " [0.39474502]\n",
      " [0.995915  ]\n",
      " [0.8572402 ]\n",
      " [0.7299574 ]\n",
      " [0.9875378 ]\n",
      " [0.50766665]\n",
      " [0.9412828 ]\n",
      " [0.9934349 ]\n",
      " [0.9911089 ]\n",
      " [0.9944845 ]\n",
      " [0.514646  ]\n",
      " [0.9960759 ]\n",
      " [0.9949238 ]\n",
      " [0.9515933 ]\n",
      " [0.97291946]\n",
      " [0.9697187 ]\n",
      " [0.8386367 ]\n",
      " [0.9937297 ]\n",
      " [0.99001324]\n",
      " [0.98371094]\n",
      " [0.9935309 ]\n",
      " [0.991147  ]\n",
      " [0.9838779 ]\n",
      " [0.9956463 ]\n",
      " [0.91004914]\n",
      " [0.94672644]\n",
      " [0.58631945]\n",
      " [0.9941684 ]\n",
      " [0.38531944]\n",
      " [0.952819  ]\n",
      " [0.988472  ]\n",
      " [0.95979047]\n",
      " [0.98675925]\n",
      " [0.98759615]\n",
      " [0.97789747]\n",
      " [0.9813634 ]\n",
      " [0.9892385 ]\n",
      " [0.9909609 ]\n",
      " [0.99197114]\n",
      " [0.9294314 ]\n",
      " [0.8265476 ]\n",
      " [0.11757425]\n",
      " [0.85310733]\n",
      " [0.7496362 ]\n",
      " [0.6406296 ]\n",
      " [0.8399227 ]\n",
      " [0.62347525]\n",
      " [0.9535634 ]\n",
      " [0.63353026]\n",
      " [0.8436988 ]\n",
      " [0.9460453 ]\n",
      " [0.80549794]\n",
      " [0.91224676]\n",
      " [0.01449949]\n",
      " [0.99407035]\n",
      " [0.99480397]\n",
      " [0.99419385]\n",
      " [0.9950789 ]\n",
      " [0.93445873]\n",
      " [0.9593185 ]\n",
      " [0.99219346]\n",
      " [0.8467257 ]\n",
      " [0.9358993 ]\n",
      " [0.95688564]\n",
      " [0.8913364 ]\n",
      " [0.61592096]\n",
      " [0.9753576 ]\n",
      " [0.9865161 ]\n",
      " [0.05282201]\n",
      " [0.8121577 ]\n",
      " [0.99493057]\n",
      " [0.9073214 ]\n",
      " [0.9220471 ]\n",
      " [0.2877897 ]\n",
      " [0.897069  ]\n",
      " [0.9852378 ]\n",
      " [0.7886766 ]\n",
      " [0.989301  ]\n",
      " [0.99403507]\n",
      " [0.8769012 ]\n",
      " [0.993686  ]\n",
      " [0.9740844 ]\n",
      " [0.9899978 ]\n",
      " [0.97135925]\n",
      " [0.91979575]\n",
      " [0.18704924]\n",
      " [0.47326463]\n",
      " [0.993371  ]\n",
      " [0.8559321 ]\n",
      " [0.69624555]\n",
      " [0.96965605]\n",
      " [0.99366105]]\n",
      "[[0.06676275]\n",
      " [0.06808703]\n",
      " [0.06913675]\n",
      " [0.07937146]\n",
      " [0.1574032 ]\n",
      " [0.08210436]\n",
      " [0.09141248]\n",
      " [0.08817337]\n",
      " [0.06446557]\n",
      " [0.08356257]\n",
      " [0.07466939]\n",
      " [0.08256451]\n",
      " [0.0845447 ]\n",
      " [0.06969891]\n",
      " [0.08743388]\n",
      " [0.9999367 ]\n",
      " [0.99993646]\n",
      " [0.5540773 ]\n",
      " [0.99968874]\n",
      " [0.08815102]\n",
      " [0.99960726]\n",
      " [0.9999026 ]\n",
      " [0.12799734]\n",
      " [0.96593976]\n",
      " [0.99901164]\n",
      " [0.17734678]\n",
      " [0.98895776]\n",
      " [0.21007544]\n",
      " [0.10558128]\n",
      " [0.3169664 ]\n",
      " [0.9999465 ]\n",
      " [0.99518496]\n",
      " [0.6015801 ]\n",
      " [0.9997758 ]\n",
      " [0.9417651 ]\n",
      " [0.99789524]\n",
      " [0.09939233]\n",
      " [0.216017  ]\n",
      " [0.9989748 ]\n",
      " [0.99525815]\n",
      " [0.14454503]\n",
      " [0.15225898]\n",
      " [0.19576226]\n",
      " [0.6037539 ]\n",
      " [0.6042055 ]\n",
      " [0.9988663 ]\n",
      " [0.9986304 ]\n",
      " [0.18126963]\n",
      " [0.99904746]\n",
      " [0.08940192]\n",
      " [0.9997787 ]\n",
      " [0.99985206]\n",
      " [0.67598987]\n",
      " [0.14075851]\n",
      " [0.9853873 ]\n",
      " [0.2350003 ]\n",
      " [0.86635315]\n",
      " [0.09311721]\n",
      " [0.99971706]\n",
      " [0.2140069 ]\n",
      " [0.9751429 ]\n",
      " [0.97013974]\n",
      " [0.9994635 ]\n",
      " [0.998447  ]\n",
      " [0.21650909]\n",
      " [0.99915636]\n",
      " [0.12979764]\n",
      " [0.2555118 ]\n",
      " [0.99836797]\n",
      " [0.11403613]\n",
      " [0.11978863]\n",
      " [0.11750403]\n",
      " [0.08737517]\n",
      " [0.5768881 ]\n",
      " [0.24348795]]\n",
      "[[0.20644552]\n",
      " [0.22504254]\n",
      " [0.99978584]\n",
      " [0.78984433]\n",
      " [0.88718486]\n",
      " [0.21545546]\n",
      " [0.9996834 ]\n",
      " [0.22500052]\n",
      " [0.2308136 ]\n",
      " [0.36326385]\n",
      " [0.99951756]\n",
      " [0.9972235 ]\n",
      " [0.99624866]\n",
      " [0.86130506]\n",
      " [0.93420565]\n",
      " [0.99887186]\n",
      " [0.9999149 ]\n",
      " [0.7770194 ]\n",
      " [0.9999838 ]\n",
      " [0.75292796]\n",
      " [0.9961423 ]\n",
      " [0.08602779]\n",
      " [0.06876634]\n",
      " [0.0871694 ]\n",
      " [0.08242491]\n",
      " [0.07518686]\n",
      " [0.082878  ]\n",
      " [0.06230784]\n",
      " [0.08742867]\n",
      " [0.09296322]\n",
      " [0.08436808]\n",
      " [0.17047785]\n",
      " [0.1238337 ]\n",
      " [0.99789494]\n",
      " [0.22165215]\n",
      " [0.5011904 ]\n",
      " [0.9996321 ]\n",
      " [0.24291745]\n",
      " [0.28889933]\n",
      " [0.8414476 ]\n",
      " [0.07777597]\n",
      " [0.06947572]\n",
      " [0.06928112]\n",
      " [0.06579305]\n",
      " [0.20007418]]\n",
      "[[0.07805508]\n",
      " [0.08330417]\n",
      " [0.08692656]\n",
      " [0.08475861]\n",
      " [0.07096331]\n",
      " [0.08156597]\n",
      " [0.08298261]\n",
      " [0.07399314]\n",
      " [0.08950262]\n",
      " [0.06752971]\n",
      " [0.08714937]\n",
      " [0.08823075]\n",
      " [0.08247808]\n",
      " [0.18730517]\n",
      " [0.07833605]\n",
      " [0.07282525]\n",
      " [0.07193318]\n",
      " [0.06779096]\n",
      " [0.17997397]\n",
      " [0.9998229 ]\n",
      " [0.8454474 ]\n",
      " [0.94349504]\n",
      " [0.1328458 ]\n",
      " [0.9990846 ]\n",
      " [0.19215676]\n",
      " [0.99795026]\n",
      " [0.9973091 ]\n",
      " [0.27505544]\n",
      " [0.20865382]\n",
      " [0.15945728]\n",
      " [0.16379261]\n",
      " [0.95047754]\n",
      " [0.4376082 ]\n",
      " [0.35602975]\n",
      " [0.7687462 ]\n",
      " [0.9144691 ]\n",
      " [0.33967298]\n",
      " [0.99611855]\n",
      " [0.11879779]\n",
      " [0.11069331]\n",
      " [0.6367284 ]\n",
      " [0.9923962 ]\n",
      " [0.16732635]\n",
      " [0.11109262]\n",
      " [0.97193277]\n",
      " [0.9998932 ]\n",
      " [0.1127525 ]\n",
      " [0.8184018 ]\n",
      " [0.22276455]\n",
      " [0.99992096]\n",
      " [0.10622986]\n",
      " [0.0789466 ]\n",
      " [0.52484506]\n",
      " [0.2017389 ]\n",
      " [0.3595317 ]\n",
      " [0.63600576]\n",
      " [0.31470364]\n",
      " [0.09392972]\n",
      " [0.97999394]\n",
      " [0.961138  ]\n",
      " [0.99716693]\n",
      " [0.19532722]\n",
      " [0.17222664]\n",
      " [0.9686313 ]\n",
      " [0.10462049]\n",
      " [0.08672191]\n",
      " [0.30379248]\n",
      " [0.9156684 ]\n",
      " [0.07092909]\n",
      " [0.18931496]]\n",
      "[[0.9815545 ]\n",
      " [0.94053435]\n",
      " [0.9950121 ]\n",
      " [0.79248166]\n",
      " [0.99285394]\n",
      " [0.959559  ]\n",
      " [0.7199502 ]\n",
      " [0.96315855]\n",
      " [0.32131916]\n",
      " [0.9981019 ]\n",
      " [0.99423075]\n",
      " [0.74321556]\n",
      " [0.9948002 ]\n",
      " [0.06060107]\n",
      " [0.11118408]\n",
      " [0.02408216]\n",
      " [0.05738827]\n",
      " [0.07022812]\n",
      " [0.9928276 ]\n",
      " [0.85943323]\n",
      " [0.9533146 ]\n",
      " [0.9739491 ]\n",
      " [0.96817726]\n",
      " [0.9540915 ]\n",
      " [0.9734928 ]\n",
      " [0.88084984]\n",
      " [0.91363597]\n",
      " [0.9534125 ]\n",
      " [0.9883385 ]\n",
      " [0.9860298 ]\n",
      " [0.11557852]\n",
      " [0.05514256]\n",
      " [0.06214667]\n",
      " [0.02487004]\n",
      " [0.09715281]\n",
      " [0.16009945]\n",
      " [0.9913762 ]\n",
      " [0.97470236]\n",
      " [0.98603827]\n",
      " [0.993903  ]\n",
      " [0.9799248 ]\n",
      " [0.40976903]\n",
      " [0.969533  ]\n",
      " [0.98506606]\n",
      " [0.4452367 ]\n",
      " [0.93322307]\n",
      " [0.9603467 ]\n",
      " [0.98093   ]\n",
      " [0.9903025 ]\n",
      " [0.98626256]\n",
      " [0.91582566]\n",
      " [0.9671967 ]\n",
      " [0.6905869 ]\n",
      " [0.50608075]\n",
      " [0.03146651]\n",
      " [0.51244617]\n",
      " [0.9605466 ]\n",
      " [0.9783547 ]\n",
      " [0.9842933 ]\n",
      " [0.98665744]\n",
      " [0.7423475 ]\n",
      " [0.30031306]\n",
      " [0.7583715 ]\n",
      " [0.09942044]\n",
      " [0.9494414 ]\n",
      " [0.9724209 ]\n",
      " [0.90674645]\n",
      " [0.98702824]\n",
      " [0.6940049 ]\n",
      " [0.7817693 ]\n",
      " [0.9903398 ]\n",
      " [0.9468798 ]\n",
      " [0.99764913]\n",
      " [0.4562997 ]\n",
      " [0.99520725]\n",
      " [0.9857904 ]\n",
      " [0.7559347 ]\n",
      " [0.03650673]\n",
      " [0.06149812]\n",
      " [0.9945656 ]\n",
      " [0.9940117 ]\n",
      " [0.3043085 ]\n",
      " [0.28959993]\n",
      " [0.7750213 ]\n",
      " [0.22118665]\n",
      " [0.03377358]\n",
      " [0.1892889 ]\n",
      " [0.9870516 ]\n",
      " [0.08190516]\n",
      " [0.07753727]\n",
      " [0.03695305]\n",
      " [0.0928873 ]\n",
      " [0.99344593]\n",
      " [0.989581  ]\n",
      " [0.9741236 ]\n",
      " [0.9910942 ]\n",
      " [0.78551555]\n",
      " [0.9900377 ]\n",
      " [0.95688576]\n",
      " [0.5633886 ]\n",
      " [0.37735596]\n",
      " [0.9463123 ]\n",
      " [0.89076674]]\n",
      "[[0.972306  ]\n",
      " [0.9201527 ]\n",
      " [0.99670863]\n",
      " [0.9988207 ]\n",
      " [0.9978338 ]\n",
      " [0.9979304 ]\n",
      " [0.9982674 ]\n",
      " [0.97788674]\n",
      " [0.99313015]\n",
      " [0.9070511 ]\n",
      " [0.13479298]\n",
      " [0.24217999]\n",
      " [0.13671818]\n",
      " [0.07258625]\n",
      " [0.20583948]\n",
      " [0.0928572 ]\n",
      " [0.02649757]\n",
      " [0.35330474]\n",
      " [0.1960927 ]\n",
      " [0.2402885 ]\n",
      " [0.16339456]\n",
      " [0.0750331 ]\n",
      " [0.04564923]\n",
      " [0.15037932]\n",
      " [0.12175331]\n",
      " [0.11843933]\n",
      " [0.24694706]\n",
      " [0.30823752]\n",
      " [0.3247951 ]\n",
      " [0.3516555 ]]\n",
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_76 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 2s 65ms/step - loss: 1.7218 - accuracy: 0.1673 - val_loss: 1.7566 - val_accuracy: 0.2400\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.0062 - accuracy: 0.2120 - val_loss: 0.9243 - val_accuracy: 0.2400\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7244 - accuracy: 0.2488 - val_loss: 0.6117 - val_accuracy: 0.7600\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7845 - accuracy: 0.8129 - val_loss: 0.6009 - val_accuracy: 0.7600\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.8517 - accuracy: 0.7863 - val_loss: 0.6439 - val_accuracy: 0.7600\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7460 - accuracy: 0.7812 - val_loss: 0.6922 - val_accuracy: 0.4800\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7704 - accuracy: 0.2561 - val_loss: 0.7073 - val_accuracy: 0.3600\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.7274 - accuracy: 0.3201 - val_loss: 0.6706 - val_accuracy: 0.7600\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6670 - accuracy: 0.8011 - val_loss: 0.6204 - val_accuracy: 0.7600\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.7779 - accuracy: 0.7946 - val_loss: 0.6552 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7214 - accuracy: 0.7347 - val_loss: 0.6767 - val_accuracy: 0.7200\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7398 - accuracy: 0.5236 - val_loss: 0.6834 - val_accuracy: 0.4800\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6224 - accuracy: 0.6346 - val_loss: 0.6178 - val_accuracy: 0.7600\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7238 - accuracy: 0.8695 - val_loss: 0.6449 - val_accuracy: 0.8800\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6504 - accuracy: 0.8711 - val_loss: 0.6456 - val_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6792 - accuracy: 0.8401 - val_loss: 0.6679 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6581 - accuracy: 0.7384 - val_loss: 0.6405 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7375 - accuracy: 0.7862 - val_loss: 0.6598 - val_accuracy: 0.8400\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6007 - accuracy: 0.8426 - val_loss: 0.5898 - val_accuracy: 0.7600\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6251 - accuracy: 0.8692 - val_loss: 0.6230 - val_accuracy: 0.9200\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 2s 91ms/step - loss: 0.5754 - binary_accuracy: 0.8911 - val_loss: 0.6108 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6199 - binary_accuracy: 0.5683 - val_loss: 0.6977 - val_binary_accuracy: 0.3200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6111 - binary_accuracy: 0.3967 - val_loss: 0.5902 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.6420 - binary_accuracy: 0.8821 - val_loss: 0.5918 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6046 - binary_accuracy: 0.9324 - val_loss: 0.5519 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5162 - binary_accuracy: 0.9907 - val_loss: 0.5527 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5062 - binary_accuracy: 0.9472 - val_loss: 0.5594 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5221 - binary_accuracy: 0.9154 - val_loss: 0.5609 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5942 - binary_accuracy: 0.8284 - val_loss: 0.5394 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5070 - binary_accuracy: 0.9815 - val_loss: 0.4840 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5441 - binary_accuracy: 0.9777 - val_loss: 0.5309 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5074 - binary_accuracy: 0.9510 - val_loss: 0.4872 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4860 - binary_accuracy: 0.9932 - val_loss: 0.4531 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4792 - binary_accuracy: 0.9730 - val_loss: 0.4968 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4706 - binary_accuracy: 0.9676 - val_loss: 0.4253 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5063 - binary_accuracy: 0.9827 - val_loss: 0.4463 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.4175 - binary_accuracy: 1.0000 - val_loss: 0.4224 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.4395 - binary_accuracy: 0.9482 - val_loss: 0.4153 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.4277 - binary_accuracy: 0.9808 - val_loss: 0.3747 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.3598 - binary_accuracy: 1.0000 - val_loss: 0.3667 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.3189 - binary_accuracy: 0.9972 - val_loss: 0.4170 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3458 - binary_accuracy: 0.9431 - val_loss: 0.3436 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.3958 - binary_accuracy: 0.9804 - val_loss: 0.3278 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3272 - binary_accuracy: 0.9724 - val_loss: 0.2963 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2868 - binary_accuracy: 0.9914 - val_loss: 0.3147 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2746 - binary_accuracy: 0.9982 - val_loss: 0.2731 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2534 - binary_accuracy: 0.9929 - val_loss: 0.2576 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2267 - binary_accuracy: 1.0000 - val_loss: 0.2222 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2843 - binary_accuracy: 0.9569 - val_loss: 0.1925 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2047 - binary_accuracy: 1.0000 - val_loss: 0.1786 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1553 - binary_accuracy: 0.9805 - val_loss: 0.1474 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1419 - binary_accuracy: 0.9960 - val_loss: 0.1489 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1074 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0911 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0931 - binary_accuracy: 1.0000 - val_loss: 0.0857 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0917 - binary_accuracy: 0.9947 - val_loss: 0.0759 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1054 - binary_accuracy: 0.9895 - val_loss: 0.0959 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0712 - binary_accuracy: 1.0000 - val_loss: 0.0667 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0678 - binary_accuracy: 1.0000 - val_loss: 0.0799 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0508 - binary_accuracy: 1.0000 - val_loss: 0.0625 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0717 - binary_accuracy: 0.9873 - val_loss: 0.1457 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0904 - binary_accuracy: 0.9676 - val_loss: 0.0640 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0630 - binary_accuracy: 0.9972 - val_loss: 0.0947 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0420 - binary_accuracy: 1.0000 - val_loss: 0.0517 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0342 - binary_accuracy: 1.0000 - val_loss: 0.0731 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0577 - binary_accuracy: 0.9628 - val_loss: 0.0448 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0506 - binary_accuracy: 1.0000 - val_loss: 0.0442 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0312 - binary_accuracy: 1.0000 - val_loss: 0.0446 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0276 - binary_accuracy: 1.0000 - val_loss: 0.0641 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0334 - binary_accuracy: 1.0000 - val_loss: 0.0360 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 95233\n",
      "[[0.98663574]\n",
      " [0.75536   ]\n",
      " [0.7848912 ]\n",
      " [0.9710075 ]\n",
      " [0.69482034]\n",
      " [0.3066618 ]\n",
      " [0.953942  ]\n",
      " [0.12830421]\n",
      " [0.9504608 ]\n",
      " [0.9767031 ]\n",
      " [0.9806662 ]\n",
      " [0.5293999 ]\n",
      " [0.7679039 ]\n",
      " [0.91674185]\n",
      " [0.9740658 ]\n",
      " [0.9694763 ]\n",
      " [0.26543516]\n",
      " [0.90046835]\n",
      " [0.9235345 ]\n",
      " [0.96646905]\n",
      " [0.91871774]\n",
      " [0.23725367]\n",
      " [0.25403887]\n",
      " [0.69268966]\n",
      " [0.8751536 ]\n",
      " [0.90743953]\n",
      " [0.08241169]\n",
      " [0.31126222]\n",
      " [0.73768365]\n",
      " [0.771279  ]\n",
      " [0.9204436 ]\n",
      " [0.40228465]\n",
      " [0.7845284 ]\n",
      " [0.07083426]\n",
      " [0.8858896 ]\n",
      " [0.56332606]\n",
      " [0.5115687 ]\n",
      " [0.80996567]\n",
      " [0.7555492 ]\n",
      " [0.9469679 ]\n",
      " [0.03195408]\n",
      " [0.04445174]\n",
      " [0.03303089]\n",
      " [0.5849474 ]\n",
      " [0.9747069 ]\n",
      " [0.96121866]\n",
      " [0.9863397 ]\n",
      " [0.04898421]\n",
      " [0.5700347 ]\n",
      " [0.03199407]\n",
      " [0.1050667 ]\n",
      " [0.11201021]\n",
      " [0.9415227 ]\n",
      " [0.95772314]\n",
      " [0.81497955]\n",
      " [0.9737752 ]\n",
      " [0.9695478 ]\n",
      " [0.98461145]\n",
      " [0.970296  ]\n",
      " [0.88018227]\n",
      " [0.9299256 ]\n",
      " [0.41966158]\n",
      " [0.88935375]\n",
      " [0.820035  ]\n",
      " [0.87064683]\n",
      " [0.77537495]\n",
      " [0.93386513]\n",
      " [0.7008331 ]\n",
      " [0.8940286 ]\n",
      " [0.86139965]\n",
      " [0.9278712 ]\n",
      " [0.678164  ]\n",
      " [0.71765244]\n",
      " [0.86334884]\n",
      " [0.9643978 ]\n",
      " [0.6888436 ]\n",
      " [0.4750846 ]\n",
      " [0.9676386 ]\n",
      " [0.04756426]\n",
      " [0.01737533]\n",
      " [0.5890206 ]\n",
      " [0.03884384]\n",
      " [0.08476623]\n",
      " [0.12193169]\n",
      " [0.1119944 ]\n",
      " [0.92312086]\n",
      " [0.09923999]\n",
      " [0.16483371]\n",
      " [0.5266578 ]\n",
      " [0.01925837]\n",
      " [0.9477559 ]\n",
      " [0.14509165]\n",
      " [0.92476153]\n",
      " [0.9313617 ]\n",
      " [0.9205227 ]\n",
      " [0.97553045]\n",
      " [0.3463066 ]\n",
      " [0.04029991]\n",
      " [0.18879236]\n",
      " [0.09046258]\n",
      " [0.18326986]\n",
      " [0.02646321]\n",
      " [0.04086325]\n",
      " [0.03277184]\n",
      " [0.02091954]\n",
      " [0.90351456]\n",
      " [0.98268855]\n",
      " [0.96568686]\n",
      " [0.92205346]\n",
      " [0.24198382]\n",
      " [0.2661647 ]\n",
      " [0.2067681 ]\n",
      " [0.9607785 ]\n",
      " [0.14807525]\n",
      " [0.93975466]\n",
      " [0.9474031 ]\n",
      " [0.967498  ]\n",
      " [0.599952  ]\n",
      " [0.9313204 ]\n",
      " [0.49549866]\n",
      " [0.8328945 ]\n",
      " [0.78997165]\n",
      " [0.56735176]\n",
      " [0.18981652]\n",
      " [0.9624685 ]\n",
      " [0.97934306]\n",
      " [0.27753526]\n",
      " [0.16795278]\n",
      " [0.9327732 ]\n",
      " [0.9006968 ]]\n",
      "[[0.9926812 ]\n",
      " [0.9941801 ]\n",
      " [0.9911069 ]\n",
      " [0.97374016]\n",
      " [0.97409207]\n",
      " [0.94341856]\n",
      " [0.98308414]\n",
      " [0.8320072 ]\n",
      " [0.5849877 ]\n",
      " [0.9866768 ]\n",
      " [0.960215  ]\n",
      " [0.9558306 ]\n",
      " [0.99178   ]\n",
      " [0.9880895 ]\n",
      " [0.9832479 ]\n",
      " [0.98918855]\n",
      " [0.9863653 ]\n",
      " [0.92733383]\n",
      " [0.86682653]\n",
      " [0.9828997 ]\n",
      " [0.7391272 ]\n",
      " [0.9837917 ]\n",
      " [0.93946004]\n",
      " [0.8920016 ]\n",
      " [0.96704525]\n",
      " [0.93978846]\n",
      " [0.734562  ]\n",
      " [0.9767577 ]\n",
      " [0.98985016]\n",
      " [0.974361  ]\n",
      " [0.9594854 ]\n",
      " [0.9529319 ]\n",
      " [0.9694298 ]\n",
      " [0.630521  ]\n",
      " [0.5602905 ]\n",
      " [0.4142708 ]\n",
      " [0.82052535]\n",
      " [0.96292394]\n",
      " [0.9483432 ]\n",
      " [0.9819614 ]\n",
      " [0.9868815 ]\n",
      " [0.96957356]\n",
      " [0.98949206]\n",
      " [0.9592315 ]\n",
      " [0.8124345 ]\n",
      " [0.98736423]\n",
      " [0.9885173 ]\n",
      " [0.9834958 ]\n",
      " [0.9800403 ]\n",
      " [0.95074254]\n",
      " [0.18209957]\n",
      " [0.99050915]\n",
      " [0.9957437 ]\n",
      " [0.93739843]\n",
      " [0.94982916]\n",
      " [0.16785643]\n",
      " [0.5372397 ]\n",
      " [0.8917889 ]\n",
      " [0.9289786 ]\n",
      " [0.9878483 ]\n",
      " [0.9597    ]\n",
      " [0.9535725 ]\n",
      " [0.98002315]\n",
      " [0.3661121 ]\n",
      " [0.16569689]\n",
      " [0.9867405 ]\n",
      " [0.72720563]\n",
      " [0.9898705 ]\n",
      " [0.6797923 ]\n",
      " [0.7072659 ]\n",
      " [0.9941597 ]\n",
      " [0.9931248 ]\n",
      " [0.99175876]\n",
      " [0.94234   ]\n",
      " [0.96855587]\n",
      " [0.94542134]\n",
      " [0.99112684]\n",
      " [0.9669611 ]\n",
      " [0.97240937]\n",
      " [0.99387085]\n",
      " [0.9853872 ]\n",
      " [0.9905601 ]\n",
      " [0.08022612]\n",
      " [0.02049525]\n",
      " [0.02904749]\n",
      " [0.03612662]\n",
      " [0.05635817]\n",
      " [0.02099659]\n",
      " [0.0151908 ]\n",
      " [0.0102001 ]\n",
      " [0.0263414 ]\n",
      " [0.0154454 ]\n",
      " [0.0185538 ]\n",
      " [0.03144611]\n",
      " [0.02226743]\n",
      " [0.13166131]\n",
      " [0.06067559]\n",
      " [0.06053091]\n",
      " [0.01667432]\n",
      " [0.04653054]\n",
      " [0.01820401]\n",
      " [0.04714185]\n",
      " [0.0464754 ]\n",
      " [0.02150853]\n",
      " [0.04521632]\n",
      " [0.05183064]\n",
      " [0.14556819]]\n",
      "[[0.02033086]\n",
      " [0.04209056]\n",
      " [0.01104076]\n",
      " [0.02718921]\n",
      " [0.02034875]\n",
      " [0.01052884]\n",
      " [0.01207406]\n",
      " [0.02201981]\n",
      " [0.02954836]\n",
      " [0.01372165]\n",
      " [0.09272995]\n",
      " [0.03699785]\n",
      " [0.01228768]\n",
      " [0.09530982]\n",
      " [0.0219103 ]\n",
      " [0.04549986]\n",
      " [0.01339334]\n",
      " [0.01626962]\n",
      " [0.01314957]\n",
      " [0.01008745]\n",
      " [0.01563565]\n",
      " [0.04397063]\n",
      " [0.99153745]\n",
      " [0.98956037]\n",
      " [0.99633753]\n",
      " [0.9964594 ]\n",
      " [0.99560225]\n",
      " [0.9943117 ]\n",
      " [0.97942185]\n",
      " [0.99401784]\n",
      " [0.99594337]\n",
      " [0.60778856]\n",
      " [0.9942374 ]\n",
      " [0.9496022 ]\n",
      " [0.9935777 ]\n",
      " [0.9199384 ]\n",
      " [0.99373996]\n",
      " [0.9784434 ]\n",
      " [0.9947002 ]\n",
      " [0.9765306 ]\n",
      " [0.9947685 ]\n",
      " [0.99006957]\n",
      " [0.991646  ]\n",
      " [0.8369659 ]\n",
      " [0.99378306]\n",
      " [0.9831377 ]\n",
      " [0.99527526]\n",
      " [0.9937295 ]\n",
      " [0.99442273]\n",
      " [0.9751143 ]\n",
      " [0.9941089 ]\n",
      " [0.99256164]\n",
      " [0.9733777 ]\n",
      " [0.98446816]\n",
      " [0.9955011 ]\n",
      " [0.9924843 ]\n",
      " [0.9954163 ]\n",
      " [0.98633295]\n",
      " [0.98900795]\n",
      " [0.9884211 ]\n",
      " [0.9940637 ]\n",
      " [0.9934708 ]\n",
      " [0.9801491 ]\n",
      " [0.9880271 ]\n",
      " [0.9942642 ]\n",
      " [0.9823638 ]\n",
      " [0.96188766]\n",
      " [0.9386062 ]\n",
      " [0.9927666 ]\n",
      " [0.974361  ]\n",
      " [0.9964477 ]\n",
      " [0.98791957]\n",
      " [0.995155  ]\n",
      " [0.959229  ]\n",
      " [0.98911625]\n",
      " [0.9694238 ]\n",
      " [0.9831671 ]\n",
      " [0.97694093]\n",
      " [0.99495345]\n",
      " [0.98934096]\n",
      " [0.9955135 ]\n",
      " [0.989643  ]\n",
      " [0.9948242 ]\n",
      " [0.9845552 ]\n",
      " [0.99360657]\n",
      " [0.9941618 ]\n",
      " [0.9906386 ]\n",
      " [0.87919605]\n",
      " [0.9929911 ]\n",
      " [0.8864307 ]\n",
      " [0.9511373 ]\n",
      " [0.9814657 ]\n",
      " [0.9918882 ]\n",
      " [0.9933796 ]\n",
      " [0.9910761 ]\n",
      " [0.99671435]\n",
      " [0.99194676]\n",
      " [0.990285  ]\n",
      " [0.98098814]\n",
      " [0.98890966]\n",
      " [0.99462223]\n",
      " [0.9954835 ]\n",
      " [0.9833514 ]\n",
      " [0.9885473 ]\n",
      " [0.9935922 ]\n",
      " [0.99468464]\n",
      " [0.9829342 ]\n",
      " [0.969942  ]\n",
      " [0.9945016 ]\n",
      " [0.9914635 ]\n",
      " [0.9850294 ]\n",
      " [0.95097303]\n",
      " [0.98690563]\n",
      " [0.989198  ]\n",
      " [0.99657804]\n",
      " [0.9949366 ]\n",
      " [0.9818211 ]\n",
      " [0.9939023 ]\n",
      " [0.99533135]\n",
      " [0.99549735]\n",
      " [0.98556167]\n",
      " [0.9803611 ]\n",
      " [0.9937791 ]\n",
      " [0.9965869 ]]\n",
      "[[0.08643693]\n",
      " [0.11418764]\n",
      " [0.11764009]\n",
      " [0.12252755]\n",
      " [0.14055249]\n",
      " [0.01707643]\n",
      " [0.39056975]\n",
      " [0.08511846]\n",
      " [0.05591868]\n",
      " [0.06373058]\n",
      " [0.07858215]\n",
      " [0.0579253 ]\n",
      " [0.0299592 ]\n",
      " [0.01295206]\n",
      " [0.02933626]\n",
      " [0.98801255]\n",
      " [0.97161496]\n",
      " [0.98839694]\n",
      " [0.9435129 ]\n",
      " [0.93126976]\n",
      " [0.90349233]\n",
      " [0.58416134]\n",
      " [0.9441473 ]\n",
      " [0.97091025]\n",
      " [0.96147686]\n",
      " [0.9493869 ]\n",
      " [0.95336306]\n",
      " [0.57139707]\n",
      " [0.6787878 ]\n",
      " [0.91459495]\n",
      " [0.46565908]\n",
      " [0.09828942]\n",
      " [0.9291958 ]\n",
      " [0.20800239]\n",
      " [0.42989886]\n",
      " [0.9621838 ]\n",
      " [0.65685123]\n",
      " [0.9323325 ]\n",
      " [0.944872  ]\n",
      " [0.9727074 ]\n",
      " [0.9492613 ]\n",
      " [0.518556  ]\n",
      " [0.9700529 ]\n",
      " [0.8733892 ]\n",
      " [0.7938013 ]\n",
      " [0.60534024]\n",
      " [0.94765896]\n",
      " [0.53920954]\n",
      " [0.85953397]\n",
      " [0.92141914]\n",
      " [0.84433436]\n",
      " [0.97165203]\n",
      " [0.9866895 ]\n",
      " [0.809525  ]\n",
      " [0.9646873 ]\n",
      " [0.932369  ]\n",
      " [0.8891816 ]\n",
      " [0.12943983]\n",
      " [0.87104684]\n",
      " [0.29635394]\n",
      " [0.9274879 ]\n",
      " [0.8787523 ]\n",
      " [0.8853413 ]\n",
      " [0.58754706]\n",
      " [0.75571275]\n",
      " [0.8470092 ]\n",
      " [0.5104191 ]\n",
      " [0.74714965]\n",
      " [0.9260603 ]\n",
      " [0.76304686]\n",
      " [0.24641809]\n",
      " [0.2845781 ]\n",
      " [0.26913908]\n",
      " [0.7094469 ]\n",
      " [0.21695554]\n",
      " [0.21397091]\n",
      " [0.3678961 ]\n",
      " [0.5420793 ]\n",
      " [0.2857792 ]\n",
      " [0.4742441 ]\n",
      " [0.40584397]\n",
      " [0.8981126 ]\n",
      " [0.11644554]\n",
      " [0.8193901 ]\n",
      " [0.02445565]\n",
      " [0.9442089 ]\n",
      " [0.97630715]\n",
      " [0.97033185]\n",
      " [0.95268124]\n",
      " [0.28294376]\n",
      " [0.6822209 ]\n",
      " [0.9442925 ]\n",
      " [0.257064  ]\n",
      " [0.5777774 ]\n",
      " [0.5140006 ]\n",
      " [0.29179475]\n",
      " [0.41197765]\n",
      " [0.89631784]\n",
      " [0.93381274]\n",
      " [0.08606032]\n",
      " [0.48053542]\n",
      " [0.9529426 ]\n",
      " [0.6826679 ]\n",
      " [0.17463067]\n",
      " [0.2054961 ]\n",
      " [0.53351784]\n",
      " [0.60876316]\n",
      " [0.2500235 ]\n",
      " [0.8134873 ]\n",
      " [0.9567379 ]\n",
      " [0.17133835]\n",
      " [0.90138113]\n",
      " [0.8072337 ]\n",
      " [0.89696157]\n",
      " [0.9426369 ]\n",
      " [0.7783005 ]\n",
      " [0.04943096]\n",
      " [0.39028826]\n",
      " [0.84382856]\n",
      " [0.8961026 ]\n",
      " [0.642722  ]\n",
      " [0.6893724 ]\n",
      " [0.95459676]]\n",
      "[[0.0928621 ]\n",
      " [0.08832629]\n",
      " [0.08188067]\n",
      " [0.08722202]\n",
      " [0.12734146]\n",
      " [0.08758956]\n",
      " [0.09540652]\n",
      " [0.09275962]\n",
      " [0.08497585]\n",
      " [0.08916805]\n",
      " [0.09209266]\n",
      " [0.09164064]\n",
      " [0.08054997]\n",
      " [0.08014397]\n",
      " [0.08634518]\n",
      " [0.99833006]\n",
      " [0.9966628 ]\n",
      " [0.80307096]\n",
      " [0.99624443]\n",
      " [0.08430588]\n",
      " [0.99454814]\n",
      " [0.99736303]\n",
      " [0.1872283 ]\n",
      " [0.94178575]\n",
      " [0.9951611 ]\n",
      " [0.21009178]\n",
      " [0.93139714]\n",
      " [0.21250613]\n",
      " [0.10130854]\n",
      " [0.37125027]\n",
      " [0.9960096 ]\n",
      " [0.98497635]\n",
      " [0.6123502 ]\n",
      " [0.99767226]\n",
      " [0.97833073]\n",
      " [0.9743755 ]\n",
      " [0.09768452]\n",
      " [0.29844323]\n",
      " [0.99703336]\n",
      " [0.9401035 ]\n",
      " [0.13902785]\n",
      " [0.12018311]\n",
      " [0.22535342]\n",
      " [0.49374738]\n",
      " [0.42276365]\n",
      " [0.99461174]\n",
      " [0.9904608 ]\n",
      " [0.33589545]\n",
      " [0.95737326]\n",
      " [0.08754835]\n",
      " [0.993786  ]\n",
      " [0.97592056]\n",
      " [0.632274  ]\n",
      " [0.14727363]\n",
      " [0.9517475 ]\n",
      " [0.34320155]\n",
      " [0.8335712 ]\n",
      " [0.09189029]\n",
      " [0.995398  ]\n",
      " [0.2831654 ]\n",
      " [0.86176974]\n",
      " [0.9237741 ]\n",
      " [0.96563184]\n",
      " [0.99614245]\n",
      " [0.58268297]\n",
      " [0.97070307]\n",
      " [0.09949903]\n",
      " [0.45772496]\n",
      " [0.9959046 ]\n",
      " [0.09842896]\n",
      " [0.11847752]\n",
      " [0.11799867]\n",
      " [0.09538626]\n",
      " [0.78993255]\n",
      " [0.12352985]]\n",
      "[[0.16936538]\n",
      " [0.11034477]\n",
      " [0.97380054]\n",
      " [0.8168086 ]\n",
      " [0.93492615]\n",
      " [0.26568484]\n",
      " [0.9971205 ]\n",
      " [0.12191021]\n",
      " [0.28572565]\n",
      " [0.36254063]\n",
      " [0.9957476 ]\n",
      " [0.9928631 ]\n",
      " [0.9881874 ]\n",
      " [0.73949564]\n",
      " [0.9409399 ]\n",
      " [0.99249625]\n",
      " [0.99735826]\n",
      " [0.70061696]\n",
      " [0.9978173 ]\n",
      " [0.8939344 ]\n",
      " [0.9886591 ]\n",
      " [0.08525813]\n",
      " [0.07965037]\n",
      " [0.07975518]\n",
      " [0.0911641 ]\n",
      " [0.09188323]\n",
      " [0.0901007 ]\n",
      " [0.08603699]\n",
      " [0.09285564]\n",
      " [0.09595388]\n",
      " [0.08837742]\n",
      " [0.15090011]\n",
      " [0.11288881]\n",
      " [0.97298515]\n",
      " [0.19280428]\n",
      " [0.70587224]\n",
      " [0.9960437 ]\n",
      " [0.22396177]\n",
      " [0.15788126]\n",
      " [0.826306  ]\n",
      " [0.08734096]\n",
      " [0.08263898]\n",
      " [0.08914758]\n",
      " [0.09332696]\n",
      " [0.1436752 ]]\n",
      "[[0.08908281]\n",
      " [0.0926173 ]\n",
      " [0.08194328]\n",
      " [0.0841198 ]\n",
      " [0.07825131]\n",
      " [0.07898062]\n",
      " [0.09167525]\n",
      " [0.09233252]\n",
      " [0.08927013]\n",
      " [0.08233858]\n",
      " [0.09266462]\n",
      " [0.09514546]\n",
      " [0.08870981]\n",
      " [0.15428226]\n",
      " [0.08775183]\n",
      " [0.08085798]\n",
      " [0.08657641]\n",
      " [0.0927406 ]\n",
      " [0.3025387 ]\n",
      " [0.98132366]\n",
      " [0.7929896 ]\n",
      " [0.95577914]\n",
      " [0.1017314 ]\n",
      " [0.9935948 ]\n",
      " [0.31779745]\n",
      " [0.99477154]\n",
      " [0.9949151 ]\n",
      " [0.34884882]\n",
      " [0.29013088]\n",
      " [0.14867702]\n",
      " [0.11960143]\n",
      " [0.66177374]\n",
      " [0.63007355]\n",
      " [0.23914659]\n",
      " [0.8542814 ]\n",
      " [0.9620773 ]\n",
      " [0.3403569 ]\n",
      " [0.9846884 ]\n",
      " [0.10725089]\n",
      " [0.08763594]\n",
      " [0.75311303]\n",
      " [0.9719643 ]\n",
      " [0.3913804 ]\n",
      " [0.11744703]\n",
      " [0.8295586 ]\n",
      " [0.99560475]\n",
      " [0.14352581]\n",
      " [0.91023654]\n",
      " [0.09393138]\n",
      " [0.99731535]\n",
      " [0.10332908]\n",
      " [0.09726296]\n",
      " [0.66502595]\n",
      " [0.15139525]\n",
      " [0.79369813]\n",
      " [0.6633067 ]\n",
      " [0.36451662]\n",
      " [0.09282169]\n",
      " [0.9870184 ]\n",
      " [0.92043096]\n",
      " [0.99356043]\n",
      " [0.17924163]\n",
      " [0.15573354]\n",
      " [0.97520113]\n",
      " [0.10834986]\n",
      " [0.09435093]\n",
      " [0.31668898]\n",
      " [0.8094956 ]\n",
      " [0.09511782]\n",
      " [0.11458288]]\n",
      "[[0.9717101 ]\n",
      " [0.92511714]\n",
      " [0.9806831 ]\n",
      " [0.93782467]\n",
      " [0.986207  ]\n",
      " [0.9610205 ]\n",
      " [0.902623  ]\n",
      " [0.9621783 ]\n",
      " [0.73599625]\n",
      " [0.9874577 ]\n",
      " [0.9867003 ]\n",
      " [0.9206534 ]\n",
      " [0.9916095 ]\n",
      " [0.25982648]\n",
      " [0.5011793 ]\n",
      " [0.1887213 ]\n",
      " [0.20756967]\n",
      " [0.36068746]\n",
      " [0.98006856]\n",
      " [0.9037441 ]\n",
      " [0.9428629 ]\n",
      " [0.9715091 ]\n",
      " [0.97604316]\n",
      " [0.9671533 ]\n",
      " [0.98263216]\n",
      " [0.96647996]\n",
      " [0.9689664 ]\n",
      " [0.96955556]\n",
      " [0.9755383 ]\n",
      " [0.9817931 ]\n",
      " [0.63819057]\n",
      " [0.30213943]\n",
      " [0.1122814 ]\n",
      " [0.20432843]\n",
      " [0.39899212]\n",
      " [0.5074504 ]\n",
      " [0.98818177]\n",
      " [0.9769999 ]\n",
      " [0.98306805]\n",
      " [0.9768172 ]\n",
      " [0.96594286]\n",
      " [0.8629433 ]\n",
      " [0.9373957 ]\n",
      " [0.9835007 ]\n",
      " [0.7991986 ]\n",
      " [0.9603647 ]\n",
      " [0.9551597 ]\n",
      " [0.9556242 ]\n",
      " [0.9837865 ]\n",
      " [0.9766832 ]\n",
      " [0.94919044]\n",
      " [0.9619554 ]\n",
      " [0.8999003 ]\n",
      " [0.82421976]\n",
      " [0.06268471]\n",
      " [0.82060194]\n",
      " [0.9650307 ]\n",
      " [0.98306656]\n",
      " [0.9756226 ]\n",
      " [0.98559177]\n",
      " [0.9405286 ]\n",
      " [0.8627193 ]\n",
      " [0.97193617]\n",
      " [0.5455581 ]\n",
      " [0.9626837 ]\n",
      " [0.9693783 ]\n",
      " [0.9122575 ]\n",
      " [0.9725448 ]\n",
      " [0.95669067]\n",
      " [0.86571956]\n",
      " [0.9830783 ]\n",
      " [0.96449107]\n",
      " [0.98830557]\n",
      " [0.81464505]\n",
      " [0.9888544 ]\n",
      " [0.9843502 ]\n",
      " [0.7738639 ]\n",
      " [0.34924775]\n",
      " [0.38945895]\n",
      " [0.99134517]\n",
      " [0.99079645]\n",
      " [0.848176  ]\n",
      " [0.63031936]\n",
      " [0.9361566 ]\n",
      " [0.77250224]\n",
      " [0.324257  ]\n",
      " [0.3536468 ]\n",
      " [0.9849134 ]\n",
      " [0.2896577 ]\n",
      " [0.48443314]\n",
      " [0.10735365]\n",
      " [0.14202632]\n",
      " [0.99152726]\n",
      " [0.98207134]\n",
      " [0.9720481 ]\n",
      " [0.9799713 ]\n",
      " [0.8682597 ]\n",
      " [0.9838493 ]\n",
      " [0.9765976 ]\n",
      " [0.9196061 ]\n",
      " [0.86111474]\n",
      " [0.98000413]\n",
      " [0.9358597 ]]\n",
      "[[0.889337  ]\n",
      " [0.87545127]\n",
      " [0.99076945]\n",
      " [0.99375004]\n",
      " [0.99045396]\n",
      " [0.99158   ]\n",
      " [0.99206865]\n",
      " [0.96968174]\n",
      " [0.9888418 ]\n",
      " [0.9362516 ]\n",
      " [0.45412078]\n",
      " [0.6179572 ]\n",
      " [0.34972578]\n",
      " [0.264224  ]\n",
      " [0.28812855]\n",
      " [0.4045504 ]\n",
      " [0.06333952]\n",
      " [0.3947301 ]\n",
      " [0.41290697]\n",
      " [0.44115666]\n",
      " [0.50828975]\n",
      " [0.26215804]\n",
      " [0.06414258]\n",
      " [0.41663453]\n",
      " [0.28126734]\n",
      " [0.40750077]\n",
      " [0.5484837 ]\n",
      " [0.63705415]\n",
      " [0.61938953]\n",
      " [0.6081855 ]]\n",
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_78 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 2s 65ms/step - loss: 2.5060 - accuracy: 0.0994 - val_loss: 3.1195 - val_accuracy: 0.1600\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.6852 - accuracy: 0.1141 - val_loss: 1.8811 - val_accuracy: 0.1600\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 1.0416 - accuracy: 0.1231 - val_loss: 0.9939 - val_accuracy: 0.1600\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.7362 - accuracy: 0.1952 - val_loss: 0.6106 - val_accuracy: 0.8400\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6119 - accuracy: 0.9164 - val_loss: 0.5402 - val_accuracy: 0.8400\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6860 - accuracy: 0.8910 - val_loss: 0.6136 - val_accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5979 - accuracy: 0.9131 - val_loss: 0.6582 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6705 - accuracy: 0.6846 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6983 - accuracy: 0.2877 - val_loss: 0.7104 - val_accuracy: 0.3200\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6165 - accuracy: 0.4360 - val_loss: 0.6589 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6751 - accuracy: 0.7865 - val_loss: 0.6542 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7277 - accuracy: 0.8294 - val_loss: 0.6307 - val_accuracy: 0.8800\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7609 - accuracy: 0.7663 - val_loss: 0.6685 - val_accuracy: 0.6400\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7376 - accuracy: 0.6623 - val_loss: 0.6570 - val_accuracy: 0.7600\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.7262 - accuracy: 0.8761 - val_loss: 0.6058 - val_accuracy: 0.8800\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6843 - accuracy: 0.9046 - val_loss: 0.6222 - val_accuracy: 0.9200\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5349 - accuracy: 0.9227 - val_loss: 0.6092 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6863 - accuracy: 0.8829 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5848 - accuracy: 0.6811 - val_loss: 0.6392 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5367 - accuracy: 0.8785 - val_loss: 0.6054 - val_accuracy: 0.9600\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 2s 90ms/step - loss: 0.5729 - binary_accuracy: 0.9465 - val_loss: 0.6239 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5566 - binary_accuracy: 0.7789 - val_loss: 0.6653 - val_binary_accuracy: 0.6400\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5962 - binary_accuracy: 0.6489 - val_loss: 0.6203 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.6372 - binary_accuracy: 0.6532 - val_loss: 0.6352 - val_binary_accuracy: 0.6800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.5509 - binary_accuracy: 0.9290 - val_loss: 0.5602 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5241 - binary_accuracy: 0.9511 - val_loss: 0.5672 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4791 - binary_accuracy: 0.9102 - val_loss: 0.5915 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5250 - binary_accuracy: 0.8208 - val_loss: 0.6144 - val_binary_accuracy: 0.7200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5883 - binary_accuracy: 0.7880 - val_loss: 0.5557 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.5224 - binary_accuracy: 0.8629 - val_loss: 0.5345 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6100 - binary_accuracy: 0.8882 - val_loss: 0.5710 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.4545 - binary_accuracy: 0.8991 - val_loss: 0.4948 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.4401 - binary_accuracy: 0.9176 - val_loss: 0.5763 - val_binary_accuracy: 0.8400\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.5434 - binary_accuracy: 0.7456 - val_loss: 0.5389 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4421 - binary_accuracy: 0.8803 - val_loss: 0.4852 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4865 - binary_accuracy: 0.8975 - val_loss: 0.5445 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4621 - binary_accuracy: 0.8575 - val_loss: 0.5441 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5128 - binary_accuracy: 0.8494 - val_loss: 0.4784 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4743 - binary_accuracy: 0.9596 - val_loss: 0.4169 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4671 - binary_accuracy: 0.9363 - val_loss: 0.5493 - val_binary_accuracy: 0.8400\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4068 - binary_accuracy: 0.8783 - val_loss: 0.4372 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3783 - binary_accuracy: 0.9449 - val_loss: 0.4672 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4613 - binary_accuracy: 0.8779 - val_loss: 0.4568 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4517 - binary_accuracy: 0.9275 - val_loss: 0.3936 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3716 - binary_accuracy: 0.9607 - val_loss: 0.3948 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.3368 - binary_accuracy: 0.9217 - val_loss: 0.4168 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3838 - binary_accuracy: 0.9183 - val_loss: 0.4264 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3333 - binary_accuracy: 0.9127 - val_loss: 0.3628 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3484 - binary_accuracy: 0.9087 - val_loss: 0.4511 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3531 - binary_accuracy: 0.9234 - val_loss: 0.3083 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3695 - binary_accuracy: 0.9773 - val_loss: 0.3825 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.3501 - binary_accuracy: 0.9224 - val_loss: 0.3195 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.3145 - binary_accuracy: 0.9731 - val_loss: 0.3022 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3496 - binary_accuracy: 0.9390 - val_loss: 0.3315 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2807 - binary_accuracy: 0.9204 - val_loss: 0.2990 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2984 - binary_accuracy: 0.8799 - val_loss: 0.3925 - val_binary_accuracy: 0.8800\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2820 - binary_accuracy: 0.9085 - val_loss: 0.2096 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2343 - binary_accuracy: 0.9563 - val_loss: 0.3234 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.3123 - binary_accuracy: 0.8829 - val_loss: 0.2532 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2344 - binary_accuracy: 0.9390 - val_loss: 0.2330 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2323 - binary_accuracy: 0.9440 - val_loss: 0.2093 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1866 - binary_accuracy: 0.9447 - val_loss: 0.2543 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1705 - binary_accuracy: 0.9237 - val_loss: 0.1787 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1621 - binary_accuracy: 0.9541 - val_loss: 0.2077 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1618 - binary_accuracy: 0.9693 - val_loss: 0.1610 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1406 - binary_accuracy: 0.9719 - val_loss: 0.1924 - val_binary_accuracy: 0.9200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1650 - binary_accuracy: 0.9389 - val_loss: 0.1371 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1314 - binary_accuracy: 0.9667 - val_loss: 0.1407 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1422 - binary_accuracy: 0.9608 - val_loss: 0.1220 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1636 - binary_accuracy: 0.9700 - val_loss: 0.1303 - val_binary_accuracy: 0.9600\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 4607\n",
      "[[0.97306424]\n",
      " [0.5253889 ]\n",
      " [0.9452396 ]\n",
      " [0.96644086]\n",
      " [0.76523215]\n",
      " [0.86642   ]\n",
      " [0.9845487 ]\n",
      " [0.66743463]\n",
      " [0.9764034 ]\n",
      " [0.9808468 ]\n",
      " [0.9864629 ]\n",
      " [0.9516707 ]\n",
      " [0.9286039 ]\n",
      " [0.9744992 ]\n",
      " [0.98773766]\n",
      " [0.9724187 ]\n",
      " [0.61643934]\n",
      " [0.967388  ]\n",
      " [0.9711944 ]\n",
      " [0.9787708 ]\n",
      " [0.98038644]\n",
      " [0.5064209 ]\n",
      " [0.8992453 ]\n",
      " [0.6565137 ]\n",
      " [0.9548844 ]\n",
      " [0.96270984]\n",
      " [0.23216446]\n",
      " [0.9445384 ]\n",
      " [0.7796674 ]\n",
      " [0.96266764]\n",
      " [0.9692402 ]\n",
      " [0.7862513 ]\n",
      " [0.9639286 ]\n",
      " [0.6274532 ]\n",
      " [0.95002663]\n",
      " [0.9189963 ]\n",
      " [0.86805826]\n",
      " [0.8470247 ]\n",
      " [0.7948525 ]\n",
      " [0.9758428 ]\n",
      " [0.05946356]\n",
      " [0.08922957]\n",
      " [0.12091814]\n",
      " [0.96555924]\n",
      " [0.98428625]\n",
      " [0.98437816]\n",
      " [0.9687099 ]\n",
      " [0.22548513]\n",
      " [0.12925924]\n",
      " [0.09212788]\n",
      " [0.07579279]\n",
      " [0.28195444]\n",
      " [0.90255046]\n",
      " [0.9798902 ]\n",
      " [0.96434945]\n",
      " [0.9729382 ]\n",
      " [0.937442  ]\n",
      " [0.9730599 ]\n",
      " [0.98109657]\n",
      " [0.96149045]\n",
      " [0.969857  ]\n",
      " [0.88353795]\n",
      " [0.9831645 ]\n",
      " [0.96730053]\n",
      " [0.9061214 ]\n",
      " [0.8573023 ]\n",
      " [0.9659796 ]\n",
      " [0.96717113]\n",
      " [0.91144794]\n",
      " [0.7435184 ]\n",
      " [0.9748011 ]\n",
      " [0.8678063 ]\n",
      " [0.950477  ]\n",
      " [0.79603714]\n",
      " [0.93698055]\n",
      " [0.9232956 ]\n",
      " [0.8539815 ]\n",
      " [0.9878485 ]\n",
      " [0.4134734 ]\n",
      " [0.06809215]\n",
      " [0.6424417 ]\n",
      " [0.05105875]\n",
      " [0.11855481]\n",
      " [0.04566943]\n",
      " [0.1299704 ]\n",
      " [0.8173032 ]\n",
      " [0.08843412]\n",
      " [0.2683345 ]\n",
      " [0.09195969]\n",
      " [0.06524985]\n",
      " [0.9779003 ]\n",
      " [0.33654135]\n",
      " [0.94525737]\n",
      " [0.9544864 ]\n",
      " [0.97385854]\n",
      " [0.9710668 ]\n",
      " [0.12729691]\n",
      " [0.11468782]\n",
      " [0.15596932]\n",
      " [0.17675684]\n",
      " [0.0945134 ]\n",
      " [0.04894015]\n",
      " [0.08016278]\n",
      " [0.10476676]\n",
      " [0.08727602]\n",
      " [0.97409296]\n",
      " [0.9859926 ]\n",
      " [0.938233  ]\n",
      " [0.93241906]\n",
      " [0.08272556]\n",
      " [0.14278138]\n",
      " [0.08376328]\n",
      " [0.978986  ]\n",
      " [0.09136586]\n",
      " [0.9506523 ]\n",
      " [0.98283285]\n",
      " [0.9729014 ]\n",
      " [0.43491268]\n",
      " [0.9711146 ]\n",
      " [0.9220248 ]\n",
      " [0.96637505]\n",
      " [0.93157405]\n",
      " [0.90487885]\n",
      " [0.89971685]\n",
      " [0.9602055 ]\n",
      " [0.98515123]\n",
      " [0.86072695]\n",
      " [0.8481451 ]\n",
      " [0.9635859 ]\n",
      " [0.98204136]]\n",
      "[[0.99212   ]\n",
      " [0.99396414]\n",
      " [0.9839012 ]\n",
      " [0.96010363]\n",
      " [0.95506305]\n",
      " [0.91539574]\n",
      " [0.9858937 ]\n",
      " [0.9692833 ]\n",
      " [0.9605482 ]\n",
      " [0.9816497 ]\n",
      " [0.97383183]\n",
      " [0.97420686]\n",
      " [0.9911271 ]\n",
      " [0.988772  ]\n",
      " [0.9866377 ]\n",
      " [0.99058366]\n",
      " [0.98958427]\n",
      " [0.9721682 ]\n",
      " [0.96816313]\n",
      " [0.9849135 ]\n",
      " [0.9592928 ]\n",
      " [0.98421323]\n",
      " [0.973664  ]\n",
      " [0.9801744 ]\n",
      " [0.9838774 ]\n",
      " [0.9817718 ]\n",
      " [0.9684012 ]\n",
      " [0.9879765 ]\n",
      " [0.9877721 ]\n",
      " [0.9789467 ]\n",
      " [0.9797233 ]\n",
      " [0.9761496 ]\n",
      " [0.9839184 ]\n",
      " [0.8110531 ]\n",
      " [0.88295144]\n",
      " [0.754871  ]\n",
      " [0.8844381 ]\n",
      " [0.9782607 ]\n",
      " [0.97499156]\n",
      " [0.9860555 ]\n",
      " [0.99156636]\n",
      " [0.9883023 ]\n",
      " [0.98716414]\n",
      " [0.95758516]\n",
      " [0.92611426]\n",
      " [0.9866261 ]\n",
      " [0.9903438 ]\n",
      " [0.9830231 ]\n",
      " [0.99083394]\n",
      " [0.98707527]\n",
      " [0.92902327]\n",
      " [0.9902137 ]\n",
      " [0.9940599 ]\n",
      " [0.9725406 ]\n",
      " [0.96975416]\n",
      " [0.8009    ]\n",
      " [0.96127933]\n",
      " [0.94123423]\n",
      " [0.96388286]\n",
      " [0.990285  ]\n",
      " [0.978448  ]\n",
      " [0.98554534]\n",
      " [0.9850803 ]\n",
      " [0.9617756 ]\n",
      " [0.8984661 ]\n",
      " [0.9838861 ]\n",
      " [0.9152192 ]\n",
      " [0.9827785 ]\n",
      " [0.88322586]\n",
      " [0.97307545]\n",
      " [0.9884073 ]\n",
      " [0.98751706]\n",
      " [0.9881555 ]\n",
      " [0.9890643 ]\n",
      " [0.98753357]\n",
      " [0.9776158 ]\n",
      " [0.9894118 ]\n",
      " [0.9801909 ]\n",
      " [0.98667634]\n",
      " [0.99317497]\n",
      " [0.9803279 ]\n",
      " [0.9883885 ]\n",
      " [0.1408775 ]\n",
      " [0.4149927 ]\n",
      " [0.21879159]\n",
      " [0.06171565]\n",
      " [0.24437535]\n",
      " [0.4726954 ]\n",
      " [0.25443655]\n",
      " [0.2975299 ]\n",
      " [0.4854964 ]\n",
      " [0.0981611 ]\n",
      " [0.26787597]\n",
      " [0.7735725 ]\n",
      " [0.6619268 ]\n",
      " [0.39839447]\n",
      " [0.09668531]\n",
      " [0.30093232]\n",
      " [0.11435264]\n",
      " [0.2944492 ]\n",
      " [0.6639427 ]\n",
      " [0.4632743 ]\n",
      " [0.15904887]\n",
      " [0.08960639]\n",
      " [0.10334732]\n",
      " [0.2514957 ]\n",
      " [0.5129276 ]]\n",
      "[[0.8630189 ]\n",
      " [0.82922953]\n",
      " [0.6287512 ]\n",
      " [0.8271398 ]\n",
      " [0.7496949 ]\n",
      " [0.63783586]\n",
      " [0.64786774]\n",
      " [0.8819354 ]\n",
      " [0.83442116]\n",
      " [0.68180835]\n",
      " [0.94059247]\n",
      " [0.8974483 ]\n",
      " [0.7800461 ]\n",
      " [0.93402505]\n",
      " [0.7319529 ]\n",
      " [0.86224514]\n",
      " [0.78611016]\n",
      " [0.85280675]\n",
      " [0.8211018 ]\n",
      " [0.65711355]\n",
      " [0.80509853]\n",
      " [0.7719861 ]\n",
      " [0.99037385]\n",
      " [0.9896797 ]\n",
      " [0.9938564 ]\n",
      " [0.9929295 ]\n",
      " [0.99175596]\n",
      " [0.98923993]\n",
      " [0.97955716]\n",
      " [0.98906296]\n",
      " [0.9930454 ]\n",
      " [0.9732982 ]\n",
      " [0.99223316]\n",
      " [0.97843516]\n",
      " [0.9911549 ]\n",
      " [0.9830686 ]\n",
      " [0.9920328 ]\n",
      " [0.9824523 ]\n",
      " [0.9919527 ]\n",
      " [0.9909101 ]\n",
      " [0.9937682 ]\n",
      " [0.99084574]\n",
      " [0.98919827]\n",
      " [0.93363947]\n",
      " [0.99035317]\n",
      " [0.9849348 ]\n",
      " [0.9921485 ]\n",
      " [0.989903  ]\n",
      " [0.98979014]\n",
      " [0.9858942 ]\n",
      " [0.99071854]\n",
      " [0.989336  ]\n",
      " [0.9733931 ]\n",
      " [0.9843502 ]\n",
      " [0.99121   ]\n",
      " [0.98735654]\n",
      " [0.99298793]\n",
      " [0.9900675 ]\n",
      " [0.9907391 ]\n",
      " [0.98900884]\n",
      " [0.9913446 ]\n",
      " [0.99155736]\n",
      " [0.9749672 ]\n",
      " [0.9814    ]\n",
      " [0.9884261 ]\n",
      " [0.98946875]\n",
      " [0.9598997 ]\n",
      " [0.94542825]\n",
      " [0.98694813]\n",
      " [0.9693684 ]\n",
      " [0.99245584]\n",
      " [0.98962796]\n",
      " [0.9925459 ]\n",
      " [0.9819958 ]\n",
      " [0.9919607 ]\n",
      " [0.98435336]\n",
      " [0.98693246]\n",
      " [0.9879061 ]\n",
      " [0.99150085]\n",
      " [0.9898254 ]\n",
      " [0.99342334]\n",
      " [0.9888525 ]\n",
      " [0.9895914 ]\n",
      " [0.98560625]\n",
      " [0.9915097 ]\n",
      " [0.99095345]\n",
      " [0.9876894 ]\n",
      " [0.96423   ]\n",
      " [0.9918424 ]\n",
      " [0.9758715 ]\n",
      " [0.9722811 ]\n",
      " [0.98245114]\n",
      " [0.98200536]\n",
      " [0.9875924 ]\n",
      " [0.99022734]\n",
      " [0.99422616]\n",
      " [0.9898673 ]\n",
      " [0.9892295 ]\n",
      " [0.9901326 ]\n",
      " [0.99305254]\n",
      " [0.9896784 ]\n",
      " [0.9910546 ]\n",
      " [0.98974025]\n",
      " [0.9840866 ]\n",
      " [0.9897682 ]\n",
      " [0.98628277]\n",
      " [0.98577106]\n",
      " [0.9856286 ]\n",
      " [0.9903679 ]\n",
      " [0.9901453 ]\n",
      " [0.9737889 ]\n",
      " [0.9449446 ]\n",
      " [0.9874062 ]\n",
      " [0.9894795 ]\n",
      " [0.99452955]\n",
      " [0.99449027]\n",
      " [0.99021345]\n",
      " [0.98424083]\n",
      " [0.99036646]\n",
      " [0.9909582 ]\n",
      " [0.9843816 ]\n",
      " [0.98168474]\n",
      " [0.9894386 ]\n",
      " [0.9928543 ]]\n",
      "[[0.05793158]\n",
      " [0.04716286]\n",
      " [0.07447726]\n",
      " [0.04580731]\n",
      " [0.36241686]\n",
      " [0.04769101]\n",
      " [0.06604823]\n",
      " [0.14768754]\n",
      " [0.04576274]\n",
      " [0.08698631]\n",
      " [0.02847557]\n",
      " [0.07071032]\n",
      " [0.03056023]\n",
      " [0.04905412]\n",
      " [0.3193523 ]\n",
      " [0.971308  ]\n",
      " [0.98773813]\n",
      " [0.9749902 ]\n",
      " [0.9857971 ]\n",
      " [0.82659245]\n",
      " [0.9789508 ]\n",
      " [0.7255434 ]\n",
      " [0.97214794]\n",
      " [0.97436804]\n",
      " [0.9867557 ]\n",
      " [0.9899989 ]\n",
      " [0.9445437 ]\n",
      " [0.986099  ]\n",
      " [0.9359311 ]\n",
      " [0.9811586 ]\n",
      " [0.9702149 ]\n",
      " [0.6147744 ]\n",
      " [0.984185  ]\n",
      " [0.8820696 ]\n",
      " [0.75254875]\n",
      " [0.9639052 ]\n",
      " [0.46599847]\n",
      " [0.9587269 ]\n",
      " [0.97980106]\n",
      " [0.97530293]\n",
      " [0.97976446]\n",
      " [0.67629266]\n",
      " [0.98930407]\n",
      " [0.985552  ]\n",
      " [0.90049464]\n",
      " [0.97278553]\n",
      " [0.97464377]\n",
      " [0.8478441 ]\n",
      " [0.9862185 ]\n",
      " [0.9764082 ]\n",
      " [0.9690508 ]\n",
      " [0.9834763 ]\n",
      " [0.97262245]\n",
      " [0.96935946]\n",
      " [0.98069626]\n",
      " [0.8881846 ]\n",
      " [0.9253734 ]\n",
      " [0.83960223]\n",
      " [0.98683596]\n",
      " [0.772491  ]\n",
      " [0.93337834]\n",
      " [0.9620056 ]\n",
      " [0.9527038 ]\n",
      " [0.97316426]\n",
      " [0.97879046]\n",
      " [0.94770133]\n",
      " [0.96656156]\n",
      " [0.97184515]\n",
      " [0.98179334]\n",
      " [0.9794622 ]\n",
      " [0.93088305]\n",
      " [0.88082653]\n",
      " [0.12681815]\n",
      " [0.8324861 ]\n",
      " [0.86643064]\n",
      " [0.9161354 ]\n",
      " [0.90584385]\n",
      " [0.77392954]\n",
      " [0.9666119 ]\n",
      " [0.8163658 ]\n",
      " [0.88691527]\n",
      " [0.9415972 ]\n",
      " [0.8917799 ]\n",
      " [0.8799271 ]\n",
      " [0.03496861]\n",
      " [0.97888696]\n",
      " [0.98655474]\n",
      " [0.97094977]\n",
      " [0.9847232 ]\n",
      " [0.9404569 ]\n",
      " [0.94130206]\n",
      " [0.9821054 ]\n",
      " [0.8413896 ]\n",
      " [0.9130242 ]\n",
      " [0.9342923 ]\n",
      " [0.90535337]\n",
      " [0.8878432 ]\n",
      " [0.95583385]\n",
      " [0.97052515]\n",
      " [0.20732477]\n",
      " [0.8792116 ]\n",
      " [0.98145753]\n",
      " [0.8807554 ]\n",
      " [0.95901316]\n",
      " [0.6253884 ]\n",
      " [0.8684199 ]\n",
      " [0.977866  ]\n",
      " [0.81288695]\n",
      " [0.9729488 ]\n",
      " [0.9868068 ]\n",
      " [0.9227036 ]\n",
      " [0.9759149 ]\n",
      " [0.96153164]\n",
      " [0.9801461 ]\n",
      " [0.97036767]\n",
      " [0.88334686]\n",
      " [0.46523643]\n",
      " [0.5971777 ]\n",
      " [0.9877314 ]\n",
      " [0.8060156 ]\n",
      " [0.7981759 ]\n",
      " [0.9572494 ]\n",
      " [0.9824377 ]]\n",
      "[[0.7218084 ]\n",
      " [0.73054844]\n",
      " [0.7427985 ]\n",
      " [0.72843003]\n",
      " [0.7744391 ]\n",
      " [0.71451384]\n",
      " [0.7010954 ]\n",
      " [0.7193156 ]\n",
      " [0.73981446]\n",
      " [0.71109366]\n",
      " [0.71569324]\n",
      " [0.71472317]\n",
      " [0.6901712 ]\n",
      " [0.71693623]\n",
      " [0.7254488 ]\n",
      " [0.99768674]\n",
      " [0.99530834]\n",
      " [0.9515018 ]\n",
      " [0.99003804]\n",
      " [0.764695  ]\n",
      " [0.99339867]\n",
      " [0.9950546 ]\n",
      " [0.7150618 ]\n",
      " [0.96814865]\n",
      " [0.9898636 ]\n",
      " [0.8087033 ]\n",
      " [0.9762363 ]\n",
      " [0.83865106]\n",
      " [0.72809654]\n",
      " [0.9566811 ]\n",
      " [0.99526536]\n",
      " [0.95349   ]\n",
      " [0.92505693]\n",
      " [0.9952512 ]\n",
      " [0.930383  ]\n",
      " [0.9884089 ]\n",
      " [0.71968764]\n",
      " [0.8442253 ]\n",
      " [0.98703194]\n",
      " [0.9719529 ]\n",
      " [0.8295823 ]\n",
      " [0.8345781 ]\n",
      " [0.88448447]\n",
      " [0.94199437]\n",
      " [0.89400417]\n",
      " [0.98963296]\n",
      " [0.988624  ]\n",
      " [0.89243805]\n",
      " [0.9957086 ]\n",
      " [0.7356934 ]\n",
      " [0.99295795]\n",
      " [0.99503183]\n",
      " [0.941262  ]\n",
      " [0.9022001 ]\n",
      " [0.9748127 ]\n",
      " [0.9195314 ]\n",
      " [0.9804059 ]\n",
      " [0.7473249 ]\n",
      " [0.990915  ]\n",
      " [0.90121263]\n",
      " [0.97513425]\n",
      " [0.96017575]\n",
      " [0.9934744 ]\n",
      " [0.9843238 ]\n",
      " [0.9277857 ]\n",
      " [0.99345917]\n",
      " [0.80204755]\n",
      " [0.9177604 ]\n",
      " [0.9837663 ]\n",
      " [0.80852705]\n",
      " [0.8862238 ]\n",
      " [0.83564556]\n",
      " [0.6977005 ]\n",
      " [0.9347828 ]\n",
      " [0.8168491 ]]\n",
      "[[0.8267297 ]\n",
      " [0.8832503 ]\n",
      " [0.9930583 ]\n",
      " [0.8928104 ]\n",
      " [0.9440844 ]\n",
      " [0.90875673]\n",
      " [0.9894176 ]\n",
      " [0.9145628 ]\n",
      " [0.90389377]\n",
      " [0.89335024]\n",
      " [0.98281646]\n",
      " [0.99243647]\n",
      " [0.98385435]\n",
      " [0.9674412 ]\n",
      " [0.96359044]\n",
      " [0.9898471 ]\n",
      " [0.99592763]\n",
      " [0.95495486]\n",
      " [0.9973545 ]\n",
      " [0.96600235]\n",
      " [0.9626684 ]\n",
      " [0.7274461 ]\n",
      " [0.7178481 ]\n",
      " [0.6964784 ]\n",
      " [0.716912  ]\n",
      " [0.7168378 ]\n",
      " [0.7090889 ]\n",
      " [0.7417807 ]\n",
      " [0.7180073 ]\n",
      " [0.6995807 ]\n",
      " [0.706864  ]\n",
      " [0.7898047 ]\n",
      " [0.7392775 ]\n",
      " [0.97743064]\n",
      " [0.88165975]\n",
      " [0.9348122 ]\n",
      " [0.9896534 ]\n",
      " [0.82394224]\n",
      " [0.66948724]\n",
      " [0.9581087 ]\n",
      " [0.7263601 ]\n",
      " [0.74266386]\n",
      " [0.72849584]\n",
      " [0.7211435 ]\n",
      " [0.82551765]]\n",
      "[[0.705299  ]\n",
      " [0.71128815]\n",
      " [0.7386977 ]\n",
      " [0.7279084 ]\n",
      " [0.722746  ]\n",
      " [0.7069835 ]\n",
      " [0.71727026]\n",
      " [0.71099985]\n",
      " [0.7138913 ]\n",
      " [0.74677575]\n",
      " [0.7210686 ]\n",
      " [0.70296216]\n",
      " [0.71245635]\n",
      " [0.7961185 ]\n",
      " [0.7308818 ]\n",
      " [0.7423182 ]\n",
      " [0.73173887]\n",
      " [0.722662  ]\n",
      " [0.8939444 ]\n",
      " [0.9931853 ]\n",
      " [0.96625537]\n",
      " [0.9641301 ]\n",
      " [0.79408437]\n",
      " [0.9835488 ]\n",
      " [0.8881942 ]\n",
      " [0.9802524 ]\n",
      " [0.9825529 ]\n",
      " [0.9282816 ]\n",
      " [0.8592113 ]\n",
      " [0.8298178 ]\n",
      " [0.8108771 ]\n",
      " [0.9496584 ]\n",
      " [0.95034826]\n",
      " [0.9594244 ]\n",
      " [0.94692254]\n",
      " [0.889187  ]\n",
      " [0.9453041 ]\n",
      " [0.9720172 ]\n",
      " [0.7380836 ]\n",
      " [0.7509449 ]\n",
      " [0.9290715 ]\n",
      " [0.97194034]\n",
      " [0.92924696]\n",
      " [0.77700347]\n",
      " [0.9784596 ]\n",
      " [0.9952519 ]\n",
      " [0.83849573]\n",
      " [0.9290179 ]\n",
      " [0.8668329 ]\n",
      " [0.9973008 ]\n",
      " [0.71169156]\n",
      " [0.73824596]\n",
      " [0.9696378 ]\n",
      " [0.8896838 ]\n",
      " [0.9392885 ]\n",
      " [0.92056227]\n",
      " [0.90625364]\n",
      " [0.76386786]\n",
      " [0.93592453]\n",
      " [0.9775589 ]\n",
      " [0.9836767 ]\n",
      " [0.9100656 ]\n",
      " [0.70593065]\n",
      " [0.9457012 ]\n",
      " [0.74531174]\n",
      " [0.75989956]\n",
      " [0.9359884 ]\n",
      " [0.9797631 ]\n",
      " [0.7351776 ]\n",
      " [0.73405635]]\n",
      "[[0.9648758 ]\n",
      " [0.91182506]\n",
      " [0.983127  ]\n",
      " [0.82592076]\n",
      " [0.98036057]\n",
      " [0.89510024]\n",
      " [0.64562416]\n",
      " [0.93612266]\n",
      " [0.39782298]\n",
      " [0.9906741 ]\n",
      " [0.9769544 ]\n",
      " [0.8055019 ]\n",
      " [0.98318094]\n",
      " [0.07946709]\n",
      " [0.12901701]\n",
      " [0.04025046]\n",
      " [0.09634285]\n",
      " [0.1807464 ]\n",
      " [0.9796998 ]\n",
      " [0.8327181 ]\n",
      " [0.91762096]\n",
      " [0.91943634]\n",
      " [0.9143495 ]\n",
      " [0.8797494 ]\n",
      " [0.9487017 ]\n",
      " [0.84234285]\n",
      " [0.8891391 ]\n",
      " [0.9343456 ]\n",
      " [0.9708566 ]\n",
      " [0.97011673]\n",
      " [0.13646361]\n",
      " [0.08164797]\n",
      " [0.12747617]\n",
      " [0.04029864]\n",
      " [0.15919961]\n",
      " [0.30435565]\n",
      " [0.97896326]\n",
      " [0.9196226 ]\n",
      " [0.9623733 ]\n",
      " [0.9792433 ]\n",
      " [0.9606839 ]\n",
      " [0.46897882]\n",
      " [0.9553865 ]\n",
      " [0.96351   ]\n",
      " [0.7894497 ]\n",
      " [0.86538786]\n",
      " [0.9433342 ]\n",
      " [0.9600523 ]\n",
      " [0.968334  ]\n",
      " [0.9456061 ]\n",
      " [0.8618735 ]\n",
      " [0.94301736]\n",
      " [0.7763622 ]\n",
      " [0.62226033]\n",
      " [0.13500181]\n",
      " [0.6584372 ]\n",
      " [0.9099667 ]\n",
      " [0.95937234]\n",
      " [0.9516252 ]\n",
      " [0.95351076]\n",
      " [0.74735564]\n",
      " [0.32653227]\n",
      " [0.6542335 ]\n",
      " [0.11437233]\n",
      " [0.93224704]\n",
      " [0.9412805 ]\n",
      " [0.9499725 ]\n",
      " [0.9722516 ]\n",
      " [0.86078846]\n",
      " [0.75695705]\n",
      " [0.96430326]\n",
      " [0.92803496]\n",
      " [0.9892145 ]\n",
      " [0.72231215]\n",
      " [0.98368675]\n",
      " [0.95962226]\n",
      " [0.8783461 ]\n",
      " [0.10754538]\n",
      " [0.08080193]\n",
      " [0.9806215 ]\n",
      " [0.97970974]\n",
      " [0.2432611 ]\n",
      " [0.42498395]\n",
      " [0.7440663 ]\n",
      " [0.19544144]\n",
      " [0.06712268]\n",
      " [0.6355984 ]\n",
      " [0.9731881 ]\n",
      " [0.11271903]\n",
      " [0.08651148]\n",
      " [0.08967785]\n",
      " [0.18189357]\n",
      " [0.986558  ]\n",
      " [0.97963643]\n",
      " [0.9389961 ]\n",
      " [0.96936363]\n",
      " [0.8044466 ]\n",
      " [0.9646816 ]\n",
      " [0.9001529 ]\n",
      " [0.45624766]\n",
      " [0.37385434]\n",
      " [0.94471455]\n",
      " [0.9089579 ]]\n",
      "[[0.944275  ]\n",
      " [0.89111716]\n",
      " [0.98615384]\n",
      " [0.99272305]\n",
      " [0.9894734 ]\n",
      " [0.9902705 ]\n",
      " [0.99155104]\n",
      " [0.93882966]\n",
      " [0.96164674]\n",
      " [0.86239666]\n",
      " [0.23164964]\n",
      " [0.41019046]\n",
      " [0.3462807 ]\n",
      " [0.14699775]\n",
      " [0.51435846]\n",
      " [0.15145925]\n",
      " [0.13365233]\n",
      " [0.6881696 ]\n",
      " [0.5100776 ]\n",
      " [0.46220618]\n",
      " [0.23457964]\n",
      " [0.19685327]\n",
      " [0.22491409]\n",
      " [0.36996675]\n",
      " [0.3766008 ]\n",
      " [0.21833238]\n",
      " [0.33299527]\n",
      " [0.60408664]\n",
      " [0.5841811 ]\n",
      " [0.60239697]]\n",
      "Model: \"model_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_80 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 97ms/step - loss: 0.9746 - accuracy: 0.8190 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.8581 - accuracy: 0.7895 - val_loss: 0.5911 - val_accuracy: 0.7333\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.7346 - accuracy: 0.8764 - val_loss: 0.5389 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.6195 - accuracy: 0.8607 - val_loss: 0.4977 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4305 - accuracy: 0.8905 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4713 - accuracy: 0.8786 - val_loss: 0.4518 - val_accuracy: 0.7333\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4770 - accuracy: 0.9005 - val_loss: 0.4396 - val_accuracy: 0.7333\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4422 - accuracy: 0.8957 - val_loss: 0.4311 - val_accuracy: 0.7333\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2511 - accuracy: 0.9167 - val_loss: 0.4257 - val_accuracy: 0.7333\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2810 - accuracy: 0.9000 - val_loss: 0.4233 - val_accuracy: 0.7333\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2815 - accuracy: 0.9262 - val_loss: 0.4227 - val_accuracy: 0.7333\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2390 - accuracy: 0.9076 - val_loss: 0.4223 - val_accuracy: 0.7333\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2023 - accuracy: 0.9521 - val_loss: 0.4231 - val_accuracy: 0.7333\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1718 - accuracy: 0.9605 - val_loss: 0.4250 - val_accuracy: 0.7333\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1515 - accuracy: 0.9457 - val_loss: 0.4267 - val_accuracy: 0.7333\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1577 - accuracy: 0.9605 - val_loss: 0.4285 - val_accuracy: 0.7333\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1469 - accuracy: 0.9331 - val_loss: 0.4285 - val_accuracy: 0.7333\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1388 - accuracy: 0.9688 - val_loss: 0.4295 - val_accuracy: 0.7333\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1220 - accuracy: 0.9355 - val_loss: 0.4310 - val_accuracy: 0.7333\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1303 - accuracy: 0.9521 - val_loss: 0.4337 - val_accuracy: 0.7333\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 126ms/step - loss: 0.2227 - binary_accuracy: 0.9188 - val_loss: 0.4022 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1466 - binary_accuracy: 0.9355 - val_loss: 0.3806 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0790 - binary_accuracy: 0.9745 - val_loss: 0.3694 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1306 - binary_accuracy: 0.9236 - val_loss: 0.3499 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1052 - binary_accuracy: 0.9348 - val_loss: 0.3333 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0778 - binary_accuracy: 0.9617 - val_loss: 0.3220 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0743 - binary_accuracy: 0.9605 - val_loss: 0.3184 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1129 - binary_accuracy: 0.9176 - val_loss: 0.3114 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0872 - binary_accuracy: 0.9236 - val_loss: 0.3027 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0575 - binary_accuracy: 0.9545 - val_loss: 0.2982 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0905 - binary_accuracy: 0.9355 - val_loss: 0.2988 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0519 - binary_accuracy: 0.9736 - val_loss: 0.2983 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0808 - binary_accuracy: 0.9140 - val_loss: 0.3011 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0440 - binary_accuracy: 0.9876 - val_loss: 0.3021 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0647 - binary_accuracy: 0.9467 - val_loss: 0.3124 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0459 - binary_accuracy: 0.9793 - val_loss: 0.3038 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0650 - binary_accuracy: 0.9467 - val_loss: 0.3046 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0486 - binary_accuracy: 0.9610 - val_loss: 0.3089 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0321 - binary_accuracy: 0.9924 - val_loss: 0.3144 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0526 - binary_accuracy: 0.9626 - val_loss: 0.3249 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0399 - binary_accuracy: 0.9840 - val_loss: 0.3249 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0255 - binary_accuracy: 0.9952 - val_loss: 0.3232 - val_binary_accuracy: 0.8000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0429 - binary_accuracy: 0.9840 - val_loss: 0.3282 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0284 - binary_accuracy: 0.9924 - val_loss: 0.3363 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0503 - binary_accuracy: 0.9626 - val_loss: 0.3247 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0189 - binary_accuracy: 0.9952 - val_loss: 0.3237 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0275 - binary_accuracy: 0.9924 - val_loss: 0.3399 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0305 - binary_accuracy: 0.9626 - val_loss: 0.3514 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0366 - binary_accuracy: 0.9626 - val_loss: 0.3331 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0297 - binary_accuracy: 0.9626 - val_loss: 0.3256 - val_binary_accuracy: 0.8667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0197 - binary_accuracy: 0.9924 - val_loss: 0.3330 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0284 - binary_accuracy: 0.9626 - val_loss: 0.3473 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0214 - binary_accuracy: 1.0000 - val_loss: 0.3487 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0271 - binary_accuracy: 1.0000 - val_loss: 0.3427 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0212 - binary_accuracy: 1.0000 - val_loss: 0.3402 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0136 - binary_accuracy: 1.0000 - val_loss: 0.3460 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.3514 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0079 - binary_accuracy: 1.0000 - val_loss: 0.3537 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0108 - binary_accuracy: 1.0000 - val_loss: 0.3448 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0152 - binary_accuracy: 1.0000 - val_loss: 0.3499 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 0.3534 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0105 - binary_accuracy: 1.0000 - val_loss: 0.3564 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0142 - binary_accuracy: 1.0000 - val_loss: 0.3542 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0079 - binary_accuracy: 1.0000 - val_loss: 0.3678 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0095 - binary_accuracy: 1.0000 - val_loss: 0.3600 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.3679 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0145 - binary_accuracy: 1.0000 - val_loss: 0.3635 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 0.3688 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0119 - binary_accuracy: 1.0000 - val_loss: 0.3737 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 0.3705 - val_binary_accuracy: 0.9333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 8121\n",
      "[[0.99753714]\n",
      " [0.9958947 ]\n",
      " [0.99640983]\n",
      " [0.9964934 ]\n",
      " [0.9960001 ]\n",
      " [0.99632215]\n",
      " [0.9970746 ]\n",
      " [0.9956682 ]\n",
      " [0.9961281 ]\n",
      " [0.99663526]\n",
      " [0.99698204]\n",
      " [0.995673  ]\n",
      " [0.99592566]\n",
      " [0.9962857 ]\n",
      " [0.99611497]\n",
      " [0.9968502 ]\n",
      " [0.99636877]\n",
      " [0.9958483 ]\n",
      " [0.99614066]\n",
      " [0.9962915 ]\n",
      " [0.99623615]\n",
      " [0.9954092 ]\n",
      " [0.9955765 ]\n",
      " [0.9964647 ]\n",
      " [0.9963431 ]\n",
      " [0.9964779 ]\n",
      " [0.9959254 ]\n",
      " [0.996176  ]\n",
      " [0.99570256]\n",
      " [0.99627125]\n",
      " [0.9970149 ]\n",
      " [0.9959253 ]\n",
      " [0.9959616 ]\n",
      " [0.9946055 ]\n",
      " [0.99600285]\n",
      " [0.9960819 ]\n",
      " [0.99602556]\n",
      " [0.99622405]\n",
      " [0.99607545]\n",
      " [0.9959835 ]\n",
      " [0.9946444 ]\n",
      " [0.9945399 ]\n",
      " [0.9945496 ]\n",
      " [0.99601233]\n",
      " [0.99684554]\n",
      " [0.99679404]\n",
      " [0.9964904 ]\n",
      " [0.9962807 ]\n",
      " [0.9957949 ]\n",
      " [0.99515545]\n",
      " [0.99567235]\n",
      " [0.99544   ]\n",
      " [0.99698704]\n",
      " [0.99768865]\n",
      " [0.9957172 ]\n",
      " [0.9971916 ]\n",
      " [0.996684  ]\n",
      " [0.9969975 ]\n",
      " [0.99647444]\n",
      " [0.99666   ]\n",
      " [0.9967127 ]\n",
      " [0.99560505]\n",
      " [0.99637246]\n",
      " [0.9959543 ]\n",
      " [0.99574226]\n",
      " [0.99601424]\n",
      " [0.9970476 ]\n",
      " [0.99612266]\n",
      " [0.99569905]\n",
      " [0.99612063]\n",
      " [0.99635065]\n",
      " [0.9958199 ]\n",
      " [0.9959786 ]\n",
      " [0.9962149 ]\n",
      " [0.99610955]\n",
      " [0.9958192 ]\n",
      " [0.995589  ]\n",
      " [0.9966266 ]\n",
      " [0.9959162 ]\n",
      " [0.99471825]\n",
      " [0.9961605 ]\n",
      " [0.9945233 ]\n",
      " [0.99586713]\n",
      " [0.99529713]\n",
      " [0.9953963 ]\n",
      " [0.99652404]\n",
      " [0.99492717]\n",
      " [0.995858  ]\n",
      " [0.99628025]\n",
      " [0.9954105 ]\n",
      " [0.9963103 ]\n",
      " [0.9957379 ]\n",
      " [0.9969145 ]\n",
      " [0.9965263 ]\n",
      " [0.99630827]\n",
      " [0.9967874 ]\n",
      " [0.99538416]\n",
      " [0.99441284]\n",
      " [0.99587554]\n",
      " [0.9952441 ]\n",
      " [0.99520653]\n",
      " [0.9941607 ]\n",
      " [0.9949307 ]\n",
      " [0.99494123]\n",
      " [0.99466705]\n",
      " [0.9964875 ]\n",
      " [0.99704844]\n",
      " [0.9963135 ]\n",
      " [0.9969308 ]\n",
      " [0.99515474]\n",
      " [0.99534506]\n",
      " [0.9952892 ]\n",
      " [0.9964233 ]\n",
      " [0.99562705]\n",
      " [0.9972699 ]\n",
      " [0.99684566]\n",
      " [0.99746454]\n",
      " [0.9958086 ]\n",
      " [0.99657756]\n",
      " [0.9961344 ]\n",
      " [0.99612325]\n",
      " [0.99600166]\n",
      " [0.9958877 ]\n",
      " [0.9952201 ]\n",
      " [0.9967198 ]\n",
      " [0.99668497]\n",
      " [0.99545974]\n",
      " [0.9961104 ]\n",
      " [0.9965932 ]\n",
      " [0.9960024 ]]\n",
      "[[0.9976133 ]\n",
      " [0.9973333 ]\n",
      " [0.9976787 ]\n",
      " [0.99752814]\n",
      " [0.99729055]\n",
      " [0.9971704 ]\n",
      " [0.9967596 ]\n",
      " [0.9967422 ]\n",
      " [0.99646014]\n",
      " [0.99720395]\n",
      " [0.99691916]\n",
      " [0.99683124]\n",
      " [0.99691236]\n",
      " [0.99706537]\n",
      " [0.9970204 ]\n",
      " [0.99681   ]\n",
      " [0.9968765 ]\n",
      " [0.9964477 ]\n",
      " [0.99703157]\n",
      " [0.99740404]\n",
      " [0.9964761 ]\n",
      " [0.9969482 ]\n",
      " [0.9968437 ]\n",
      " [0.996798  ]\n",
      " [0.9971179 ]\n",
      " [0.99713683]\n",
      " [0.9967338 ]\n",
      " [0.99733883]\n",
      " [0.9972662 ]\n",
      " [0.99706346]\n",
      " [0.9969933 ]\n",
      " [0.99677086]\n",
      " [0.9971928 ]\n",
      " [0.99637187]\n",
      " [0.9964786 ]\n",
      " [0.99640024]\n",
      " [0.9968311 ]\n",
      " [0.99716693]\n",
      " [0.9971641 ]\n",
      " [0.99677736]\n",
      " [0.9969874 ]\n",
      " [0.99671054]\n",
      " [0.9975261 ]\n",
      " [0.99704057]\n",
      " [0.99680847]\n",
      " [0.9971872 ]\n",
      " [0.99731463]\n",
      " [0.9971125 ]\n",
      " [0.99680436]\n",
      " [0.9966185 ]\n",
      " [0.9956606 ]\n",
      " [0.9972167 ]\n",
      " [0.99754363]\n",
      " [0.9973241 ]\n",
      " [0.9972408 ]\n",
      " [0.9962029 ]\n",
      " [0.99685186]\n",
      " [0.99688405]\n",
      " [0.99668795]\n",
      " [0.99706227]\n",
      " [0.9968695 ]\n",
      " [0.9969013 ]\n",
      " [0.9970168 ]\n",
      " [0.9964211 ]\n",
      " [0.99654454]\n",
      " [0.997045  ]\n",
      " [0.9964636 ]\n",
      " [0.9971812 ]\n",
      " [0.99643314]\n",
      " [0.9965822 ]\n",
      " [0.997635  ]\n",
      " [0.9974281 ]\n",
      " [0.9973264 ]\n",
      " [0.9967976 ]\n",
      " [0.99718386]\n",
      " [0.9971328 ]\n",
      " [0.997329  ]\n",
      " [0.9972439 ]\n",
      " [0.9969541 ]\n",
      " [0.9979528 ]\n",
      " [0.9974704 ]\n",
      " [0.9974287 ]\n",
      " [0.996429  ]\n",
      " [0.9960342 ]\n",
      " [0.99577254]\n",
      " [0.9950788 ]\n",
      " [0.9961951 ]\n",
      " [0.9958169 ]\n",
      " [0.9956151 ]\n",
      " [0.9957029 ]\n",
      " [0.9955923 ]\n",
      " [0.9947614 ]\n",
      " [0.99617624]\n",
      " [0.9961163 ]\n",
      " [0.996079  ]\n",
      " [0.9965347 ]\n",
      " [0.99572265]\n",
      " [0.9963653 ]\n",
      " [0.9960198 ]\n",
      " [0.99574775]\n",
      " [0.9959369 ]\n",
      " [0.9966107 ]\n",
      " [0.99623305]\n",
      " [0.995999  ]\n",
      " [0.99578756]\n",
      " [0.9965861 ]\n",
      " [0.9965726 ]]\n",
      "[[0.9964893 ]\n",
      " [0.9964265 ]\n",
      " [0.99682957]\n",
      " [0.9962463 ]\n",
      " [0.99652773]\n",
      " [0.9964418 ]\n",
      " [0.9968748 ]\n",
      " [0.99631715]\n",
      " [0.9962238 ]\n",
      " [0.9963468 ]\n",
      " [0.9965946 ]\n",
      " [0.9962399 ]\n",
      " [0.9959188 ]\n",
      " [0.99652016]\n",
      " [0.9963426 ]\n",
      " [0.9964064 ]\n",
      " [0.99645233]\n",
      " [0.9960938 ]\n",
      " [0.9960807 ]\n",
      " [0.99590826]\n",
      " [0.99626786]\n",
      " [0.99659985]\n",
      " [0.9970246 ]\n",
      " [0.99701476]\n",
      " [0.9971872 ]\n",
      " [0.9972946 ]\n",
      " [0.99735427]\n",
      " [0.99718994]\n",
      " [0.9979417 ]\n",
      " [0.9972572 ]\n",
      " [0.9973182 ]\n",
      " [0.99633753]\n",
      " [0.9971444 ]\n",
      " [0.9968658 ]\n",
      " [0.9971866 ]\n",
      " [0.99675816]\n",
      " [0.9973398 ]\n",
      " [0.996979  ]\n",
      " [0.9973219 ]\n",
      " [0.9970835 ]\n",
      " [0.9972761 ]\n",
      " [0.99719113]\n",
      " [0.99689144]\n",
      " [0.9966493 ]\n",
      " [0.9972619 ]\n",
      " [0.99704343]\n",
      " [0.99711007]\n",
      " [0.9970687 ]\n",
      " [0.99714845]\n",
      " [0.9969958 ]\n",
      " [0.9971523 ]\n",
      " [0.99732804]\n",
      " [0.99709046]\n",
      " [0.99706775]\n",
      " [0.9972445 ]\n",
      " [0.9971813 ]\n",
      " [0.99712735]\n",
      " [0.9969881 ]\n",
      " [0.99724907]\n",
      " [0.9970407 ]\n",
      " [0.9970547 ]\n",
      " [0.9971263 ]\n",
      " [0.9971667 ]\n",
      " [0.9974469 ]\n",
      " [0.9971961 ]\n",
      " [0.9969284 ]\n",
      " [0.9971558 ]\n",
      " [0.9969112 ]\n",
      " [0.9974745 ]\n",
      " [0.99741346]\n",
      " [0.9974185 ]\n",
      " [0.99704117]\n",
      " [0.99715686]\n",
      " [0.9969183 ]\n",
      " [0.99712926]\n",
      " [0.9972045 ]\n",
      " [0.99692935]\n",
      " [0.99683785]\n",
      " [0.997609  ]\n",
      " [0.9975587 ]\n",
      " [0.99725854]\n",
      " [0.9969332 ]\n",
      " [0.9971818 ]\n",
      " [0.99700564]\n",
      " [0.9972179 ]\n",
      " [0.99708134]\n",
      " [0.9970421 ]\n",
      " [0.9966073 ]\n",
      " [0.99728084]\n",
      " [0.99644214]\n",
      " [0.99695265]\n",
      " [0.9969567 ]\n",
      " [0.99733514]\n",
      " [0.99720156]\n",
      " [0.99718684]\n",
      " [0.99720407]\n",
      " [0.9968508 ]\n",
      " [0.9969489 ]\n",
      " [0.99683255]\n",
      " [0.99700266]\n",
      " [0.99763787]\n",
      " [0.9973464 ]\n",
      " [0.9970488 ]\n",
      " [0.997218  ]\n",
      " [0.99711716]\n",
      " [0.99711007]\n",
      " [0.9970605 ]\n",
      " [0.99692035]\n",
      " [0.9970688 ]\n",
      " [0.9970235 ]\n",
      " [0.9970687 ]\n",
      " [0.99694484]\n",
      " [0.9972149 ]\n",
      " [0.99720687]\n",
      " [0.99731785]\n",
      " [0.997361  ]\n",
      " [0.9973834 ]\n",
      " [0.9971654 ]\n",
      " [0.99712914]\n",
      " [0.9975262 ]\n",
      " [0.9972018 ]\n",
      " [0.99707735]\n",
      " [0.9974287 ]\n",
      " [0.99722075]]\n",
      "[[0.9958645 ]\n",
      " [0.99563736]\n",
      " [0.9956346 ]\n",
      " [0.99546415]\n",
      " [0.99611264]\n",
      " [0.99582577]\n",
      " [0.9966007 ]\n",
      " [0.9962142 ]\n",
      " [0.9953435 ]\n",
      " [0.99590576]\n",
      " [0.995682  ]\n",
      " [0.9962863 ]\n",
      " [0.9949432 ]\n",
      " [0.9951382 ]\n",
      " [0.99618995]\n",
      " [0.996806  ]\n",
      " [0.9971085 ]\n",
      " [0.9978528 ]\n",
      " [0.997081  ]\n",
      " [0.9969537 ]\n",
      " [0.99671304]\n",
      " [0.99643695]\n",
      " [0.99695694]\n",
      " [0.9975159 ]\n",
      " [0.99674016]\n",
      " [0.9970822 ]\n",
      " [0.9971474 ]\n",
      " [0.99651706]\n",
      " [0.9963192 ]\n",
      " [0.99629045]\n",
      " [0.9963362 ]\n",
      " [0.9960978 ]\n",
      " [0.9973584 ]\n",
      " [0.99663013]\n",
      " [0.99637127]\n",
      " [0.99689806]\n",
      " [0.99630797]\n",
      " [0.9975521 ]\n",
      " [0.9967475 ]\n",
      " [0.996874  ]\n",
      " [0.99668866]\n",
      " [0.9966175 ]\n",
      " [0.9969126 ]\n",
      " [0.996317  ]\n",
      " [0.996027  ]\n",
      " [0.9965245 ]\n",
      " [0.9973605 ]\n",
      " [0.99638534]\n",
      " [0.9966864 ]\n",
      " [0.99702066]\n",
      " [0.99688405]\n",
      " [0.99679285]\n",
      " [0.99734604]\n",
      " [0.9961371 ]\n",
      " [0.99807966]\n",
      " [0.99728   ]\n",
      " [0.99710375]\n",
      " [0.9962142 ]\n",
      " [0.99603796]\n",
      " [0.99655044]\n",
      " [0.9980445 ]\n",
      " [0.99657047]\n",
      " [0.99664766]\n",
      " [0.9959008 ]\n",
      " [0.99670714]\n",
      " [0.9969995 ]\n",
      " [0.99669975]\n",
      " [0.9963768 ]\n",
      " [0.99659234]\n",
      " [0.9961755 ]\n",
      " [0.99686974]\n",
      " [0.99660814]\n",
      " [0.99639016]\n",
      " [0.9967692 ]\n",
      " [0.9959044 ]\n",
      " [0.9954183 ]\n",
      " [0.99708444]\n",
      " [0.99616635]\n",
      " [0.9966633 ]\n",
      " [0.99722713]\n",
      " [0.9960056 ]\n",
      " [0.99705005]\n",
      " [0.99659616]\n",
      " [0.9968972 ]\n",
      " [0.9953843 ]\n",
      " [0.997198  ]\n",
      " [0.99698275]\n",
      " [0.99765563]\n",
      " [0.99670804]\n",
      " [0.99611205]\n",
      " [0.99681693]\n",
      " [0.9966893 ]\n",
      " [0.9962314 ]\n",
      " [0.9970335 ]\n",
      " [0.9967219 ]\n",
      " [0.9963786 ]\n",
      " [0.9969177 ]\n",
      " [0.99646723]\n",
      " [0.99641305]\n",
      " [0.995865  ]\n",
      " [0.9970196 ]\n",
      " [0.99712247]\n",
      " [0.9962697 ]\n",
      " [0.99609095]\n",
      " [0.9964407 ]\n",
      " [0.9968714 ]\n",
      " [0.99681515]\n",
      " [0.9967997 ]\n",
      " [0.9963576 ]\n",
      " [0.9968792 ]\n",
      " [0.99560463]\n",
      " [0.997413  ]\n",
      " [0.9968725 ]\n",
      " [0.9966518 ]\n",
      " [0.9971758 ]\n",
      " [0.9961467 ]\n",
      " [0.9962697 ]\n",
      " [0.9970034 ]\n",
      " [0.9966191 ]\n",
      " [0.99681735]\n",
      " [0.9962708 ]\n",
      " [0.9960562 ]\n",
      " [0.9972289 ]]\n",
      "[[2.7926592e-03]\n",
      " [1.0698539e-03]\n",
      " [1.7207232e-03]\n",
      " [2.8919780e-03]\n",
      " [9.9254334e-01]\n",
      " [2.4611943e-03]\n",
      " [3.0621503e-02]\n",
      " [1.3476785e-03]\n",
      " [3.1929975e-04]\n",
      " [5.9199296e-03]\n",
      " [2.3529401e-01]\n",
      " [4.7621829e-03]\n",
      " [1.1364934e-02]\n",
      " [1.0597389e-03]\n",
      " [1.7555315e-02]\n",
      " [9.9893838e-01]\n",
      " [9.9891317e-01]\n",
      " [9.9881738e-01]\n",
      " [9.9918848e-01]\n",
      " [9.4916302e-01]\n",
      " [9.9943453e-01]\n",
      " [9.9932563e-01]\n",
      " [9.9894875e-01]\n",
      " [9.9864179e-01]\n",
      " [9.9869436e-01]\n",
      " [9.9931538e-01]\n",
      " [9.9905378e-01]\n",
      " [9.9940491e-01]\n",
      " [8.9403510e-01]\n",
      " [9.9884039e-01]\n",
      " [9.9856073e-01]\n",
      " [9.9944311e-01]\n",
      " [9.9901366e-01]\n",
      " [9.9908412e-01]\n",
      " [9.9920052e-01]\n",
      " [9.9873298e-01]\n",
      " [7.7333260e-01]\n",
      " [9.9924183e-01]\n",
      " [9.9903858e-01]\n",
      " [9.9899000e-01]\n",
      " [9.9914491e-01]\n",
      " [9.9714392e-01]\n",
      " [9.9924231e-01]\n",
      " [9.9927825e-01]\n",
      " [9.9866748e-01]\n",
      " [9.9906272e-01]\n",
      " [9.9878401e-01]\n",
      " [9.9819785e-01]\n",
      " [9.9670607e-01]\n",
      " [7.7852434e-01]\n",
      " [9.9939632e-01]\n",
      " [9.9804127e-01]\n",
      " [9.9913919e-01]\n",
      " [9.9719882e-01]\n",
      " [9.9739337e-01]\n",
      " [9.9829310e-01]\n",
      " [9.9909818e-01]\n",
      " [9.8246002e-01]\n",
      " [9.9920470e-01]\n",
      " [9.9926144e-01]\n",
      " [9.9855655e-01]\n",
      " [9.9956769e-01]\n",
      " [9.9874949e-01]\n",
      " [9.9919325e-01]\n",
      " [9.9870420e-01]\n",
      " [9.9818891e-01]\n",
      " [9.9068367e-01]\n",
      " [9.9904519e-01]\n",
      " [9.9912781e-01]\n",
      " [9.9748105e-01]\n",
      " [9.9842155e-01]\n",
      " [9.9771982e-01]\n",
      " [9.3680769e-01]\n",
      " [9.9939728e-01]\n",
      " [9.9529856e-01]]\n",
      "[[9.9651140e-01]\n",
      " [9.8349357e-01]\n",
      " [9.9733341e-01]\n",
      " [9.9919611e-01]\n",
      " [9.9944228e-01]\n",
      " [9.9941576e-01]\n",
      " [9.9898607e-01]\n",
      " [9.3872172e-01]\n",
      " [9.9884820e-01]\n",
      " [9.9918181e-01]\n",
      " [9.9924445e-01]\n",
      " [9.9942601e-01]\n",
      " [9.9920672e-01]\n",
      " [9.9606043e-01]\n",
      " [9.9934369e-01]\n",
      " [9.9910575e-01]\n",
      " [9.9915791e-01]\n",
      " [9.9707639e-01]\n",
      " [9.9869138e-01]\n",
      " [9.9898297e-01]\n",
      " [9.9926275e-01]\n",
      " [3.2452051e-02]\n",
      " [9.9154178e-04]\n",
      " [1.5009608e-02]\n",
      " [4.6227821e-03]\n",
      " [2.5497934e-01]\n",
      " [8.9025022e-03]\n",
      " [3.7810803e-04]\n",
      " [2.0416141e-03]\n",
      " [5.7174496e-02]\n",
      " [4.5901453e-03]\n",
      " [9.9707460e-01]\n",
      " [9.2416185e-01]\n",
      " [9.9925560e-01]\n",
      " [9.9758887e-01]\n",
      " [9.9916244e-01]\n",
      " [9.9897242e-01]\n",
      " [9.9865365e-01]\n",
      " [9.9849832e-01]\n",
      " [9.9827993e-01]\n",
      " [2.3835409e-03]\n",
      " [1.6888950e-03]\n",
      " [1.2350924e-03]\n",
      " [3.3946531e-03]\n",
      " [9.9502110e-01]]\n",
      "[[4.6249349e-03]\n",
      " [9.5269345e-03]\n",
      " [6.2032440e-04]\n",
      " [3.0704867e-02]\n",
      " [8.4160315e-04]\n",
      " [1.6051877e-02]\n",
      " [4.4302498e-03]\n",
      " [3.8649559e-01]\n",
      " [7.9188813e-03]\n",
      " [3.6328915e-04]\n",
      " [1.4996420e-03]\n",
      " [1.7607011e-02]\n",
      " [4.0696836e-03]\n",
      " [9.9906236e-01]\n",
      " [5.4459083e-03]\n",
      " [3.9314055e-03]\n",
      " [2.1541766e-03]\n",
      " [2.6915707e-03]\n",
      " [9.9952364e-01]\n",
      " [9.9740905e-01]\n",
      " [9.9890041e-01]\n",
      " [9.9938750e-01]\n",
      " [9.9879563e-01]\n",
      " [9.9922860e-01]\n",
      " [9.9917370e-01]\n",
      " [9.9825555e-01]\n",
      " [9.9921679e-01]\n",
      " [9.9808657e-01]\n",
      " [9.9945623e-01]\n",
      " [9.9625337e-01]\n",
      " [9.9937516e-01]\n",
      " [9.8828888e-01]\n",
      " [9.9941814e-01]\n",
      " [9.9942172e-01]\n",
      " [9.9910057e-01]\n",
      " [9.9826247e-01]\n",
      " [9.9689341e-01]\n",
      " [9.9938858e-01]\n",
      " [9.7119200e-01]\n",
      " [9.6739644e-01]\n",
      " [9.9868816e-01]\n",
      " [9.9918836e-01]\n",
      " [9.9927205e-01]\n",
      " [9.2969179e-01]\n",
      " [9.9949348e-01]\n",
      " [9.9893886e-01]\n",
      " [9.9821895e-01]\n",
      " [9.9943942e-01]\n",
      " [9.9762267e-01]\n",
      " [9.9868900e-01]\n",
      " [9.7746253e-01]\n",
      " [4.4393942e-01]\n",
      " [9.9850816e-01]\n",
      " [9.9846256e-01]\n",
      " [9.9934036e-01]\n",
      " [9.9894410e-01]\n",
      " [9.9934584e-01]\n",
      " [9.9727637e-01]\n",
      " [9.9873561e-01]\n",
      " [9.9914861e-01]\n",
      " [9.9933356e-01]\n",
      " [9.9720997e-01]\n",
      " [9.9762976e-01]\n",
      " [9.9901187e-01]\n",
      " [9.0520233e-01]\n",
      " [1.8138605e-01]\n",
      " [9.9806517e-01]\n",
      " [9.8400289e-01]\n",
      " [2.5278240e-02]\n",
      " [9.6003473e-01]]\n",
      "[[0.9967199 ]\n",
      " [0.99660516]\n",
      " [0.9969292 ]\n",
      " [0.99631625]\n",
      " [0.99686337]\n",
      " [0.9964725 ]\n",
      " [0.99666756]\n",
      " [0.99631506]\n",
      " [0.99635124]\n",
      " [0.9975521 ]\n",
      " [0.996558  ]\n",
      " [0.9964849 ]\n",
      " [0.9972784 ]\n",
      " [0.99595547]\n",
      " [0.9960504 ]\n",
      " [0.9957041 ]\n",
      " [0.99526393]\n",
      " [0.99539304]\n",
      " [0.99634546]\n",
      " [0.9966742 ]\n",
      " [0.9965062 ]\n",
      " [0.99698764]\n",
      " [0.9968393 ]\n",
      " [0.9964946 ]\n",
      " [0.99690104]\n",
      " [0.99697506]\n",
      " [0.9970499 ]\n",
      " [0.9965844 ]\n",
      " [0.99698645]\n",
      " [0.99655473]\n",
      " [0.996005  ]\n",
      " [0.9960819 ]\n",
      " [0.99600935]\n",
      " [0.9954313 ]\n",
      " [0.9962769 ]\n",
      " [0.9962838 ]\n",
      " [0.996572  ]\n",
      " [0.9963457 ]\n",
      " [0.9968053 ]\n",
      " [0.9971706 ]\n",
      " [0.99734265]\n",
      " [0.996503  ]\n",
      " [0.996316  ]\n",
      " [0.996711  ]\n",
      " [0.9961695 ]\n",
      " [0.99676955]\n",
      " [0.9961966 ]\n",
      " [0.995968  ]\n",
      " [0.9970395 ]\n",
      " [0.9968534 ]\n",
      " [0.9963983 ]\n",
      " [0.9962806 ]\n",
      " [0.9965515 ]\n",
      " [0.9962924 ]\n",
      " [0.9953353 ]\n",
      " [0.99620456]\n",
      " [0.9965258 ]\n",
      " [0.9975914 ]\n",
      " [0.99646616]\n",
      " [0.9969854 ]\n",
      " [0.9966538 ]\n",
      " [0.9963529 ]\n",
      " [0.9969704 ]\n",
      " [0.99572265]\n",
      " [0.9968322 ]\n",
      " [0.99727446]\n",
      " [0.9960568 ]\n",
      " [0.99710554]\n",
      " [0.99701273]\n",
      " [0.9957985 ]\n",
      " [0.99731797]\n",
      " [0.9971681 ]\n",
      " [0.996858  ]\n",
      " [0.9966723 ]\n",
      " [0.9964275 ]\n",
      " [0.99641573]\n",
      " [0.99578875]\n",
      " [0.99528414]\n",
      " [0.99566084]\n",
      " [0.9963593 ]\n",
      " [0.9963552 ]\n",
      " [0.9964277 ]\n",
      " [0.995846  ]\n",
      " [0.9959757 ]\n",
      " [0.9962368 ]\n",
      " [0.99620336]\n",
      " [0.9963104 ]\n",
      " [0.9967064 ]\n",
      " [0.9958811 ]\n",
      " [0.9965629 ]\n",
      " [0.996079  ]\n",
      " [0.9954873 ]\n",
      " [0.9968604 ]\n",
      " [0.99673355]\n",
      " [0.99647045]\n",
      " [0.99694294]\n",
      " [0.9962619 ]\n",
      " [0.99689674]\n",
      " [0.99704045]\n",
      " [0.9964399 ]\n",
      " [0.9957457 ]\n",
      " [0.99619615]\n",
      " [0.996514  ]]\n",
      "[[0.9972989 ]\n",
      " [0.9970049 ]\n",
      " [0.9972324 ]\n",
      " [0.9971764 ]\n",
      " [0.99704367]\n",
      " [0.99718827]\n",
      " [0.9975126 ]\n",
      " [0.9968918 ]\n",
      " [0.9971244 ]\n",
      " [0.99671316]\n",
      " [0.99645376]\n",
      " [0.9964399 ]\n",
      " [0.99644166]\n",
      " [0.9960608 ]\n",
      " [0.99637896]\n",
      " [0.9961932 ]\n",
      " [0.9956962 ]\n",
      " [0.9964457 ]\n",
      " [0.99660766]\n",
      " [0.9965969 ]\n",
      " [0.9965006 ]\n",
      " [0.995501  ]\n",
      " [0.99585754]\n",
      " [0.99607843]\n",
      " [0.9960907 ]\n",
      " [0.99610525]\n",
      " [0.99684477]\n",
      " [0.99659425]\n",
      " [0.9967616 ]\n",
      " [0.99684995]]\n",
      "Model: \"model_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_82 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 153ms/step - loss: 1.7826 - accuracy: 0.6611 - val_loss: 1.2900 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5247 - accuracy: 0.6978 - val_loss: 1.1528 - val_accuracy: 0.5556\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.8091 - accuracy: 0.6011 - val_loss: 1.0226 - val_accuracy: 0.5556\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0164 - accuracy: 0.7478 - val_loss: 0.9122 - val_accuracy: 0.5556\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3452 - accuracy: 0.6478 - val_loss: 0.8076 - val_accuracy: 0.5556\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.1730 - accuracy: 0.6311 - val_loss: 0.7136 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0369 - accuracy: 0.6011 - val_loss: 0.6301 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8780 - accuracy: 0.6711 - val_loss: 0.5553 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7055 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6456 - accuracy: 0.7956 - val_loss: 0.4305 - val_accuracy: 0.7778\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5478 - accuracy: 0.8033 - val_loss: 0.3778 - val_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4926 - accuracy: 0.8956 - val_loss: 0.3317 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5551 - accuracy: 0.8567 - val_loss: 0.2943 - val_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4274 - accuracy: 0.9133 - val_loss: 0.2609 - val_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3504 - accuracy: 0.9444 - val_loss: 0.2344 - val_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2732 - accuracy: 0.9778 - val_loss: 0.2110 - val_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2837 - accuracy: 0.9644 - val_loss: 0.1914 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3928 - accuracy: 0.9067 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3681 - accuracy: 0.9067 - val_loss: 0.1625 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3583 - accuracy: 0.8933 - val_loss: 0.1516 - val_accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 173ms/step - loss: 0.3752 - binary_accuracy: 0.8567 - val_loss: 0.0865 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1514 - binary_accuracy: 0.9711 - val_loss: 0.0665 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.1293 - binary_accuracy: 0.9411 - val_loss: 0.0590 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1505 - binary_accuracy: 0.9344 - val_loss: 0.0545 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1003 - binary_accuracy: 0.9889 - val_loss: 0.0511 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1171 - binary_accuracy: 0.9522 - val_loss: 0.0483 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0744 - binary_accuracy: 0.9889 - val_loss: 0.0456 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0711 - binary_accuracy: 0.9822 - val_loss: 0.0434 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0689 - binary_accuracy: 0.9822 - val_loss: 0.0411 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0789 - binary_accuracy: 0.9522 - val_loss: 0.0390 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0623 - binary_accuracy: 0.9889 - val_loss: 0.0367 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0646 - binary_accuracy: 0.9722 - val_loss: 0.0351 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0687 - binary_accuracy: 1.0000 - val_loss: 0.0327 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0553 - binary_accuracy: 0.9722 - val_loss: 0.0306 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0389 - binary_accuracy: 0.9889 - val_loss: 0.0289 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0648 - binary_accuracy: 0.9522 - val_loss: 0.0279 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0532 - binary_accuracy: 1.0000 - val_loss: 0.0268 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0433 - binary_accuracy: 1.0000 - val_loss: 0.0256 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0392 - binary_accuracy: 1.0000 - val_loss: 0.0245 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0436 - binary_accuracy: 1.0000 - val_loss: 0.0237 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0448 - binary_accuracy: 1.0000 - val_loss: 0.0226 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0406 - binary_accuracy: 1.0000 - val_loss: 0.0217 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0401 - binary_accuracy: 1.0000 - val_loss: 0.0208 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0330 - binary_accuracy: 1.0000 - val_loss: 0.0199 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0358 - binary_accuracy: 1.0000 - val_loss: 0.0192 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0323 - binary_accuracy: 1.0000 - val_loss: 0.0186 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0290 - binary_accuracy: 1.0000 - val_loss: 0.0180 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0330 - binary_accuracy: 1.0000 - val_loss: 0.0175 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0295 - binary_accuracy: 1.0000 - val_loss: 0.0170 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0223 - binary_accuracy: 1.0000 - val_loss: 0.0165 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0228 - binary_accuracy: 1.0000 - val_loss: 0.0160 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0304 - binary_accuracy: 1.0000 - val_loss: 0.0158 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0201 - binary_accuracy: 1.0000 - val_loss: 0.0154 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0279 - binary_accuracy: 1.0000 - val_loss: 0.0152 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0176 - binary_accuracy: 1.0000 - val_loss: 0.0146 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0175 - binary_accuracy: 1.0000 - val_loss: 0.0142 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0183 - binary_accuracy: 1.0000 - val_loss: 0.0139 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0204 - binary_accuracy: 1.0000 - val_loss: 0.0136 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0154 - binary_accuracy: 1.0000 - val_loss: 0.0132 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0177 - binary_accuracy: 1.0000 - val_loss: 0.0128 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0192 - binary_accuracy: 1.0000 - val_loss: 0.0125 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0194 - binary_accuracy: 1.0000 - val_loss: 0.0122 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0190 - binary_accuracy: 1.0000 - val_loss: 0.0120 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0196 - binary_accuracy: 1.0000 - val_loss: 0.0118 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0148 - binary_accuracy: 1.0000 - val_loss: 0.0115 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 0.0112 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0147 - binary_accuracy: 1.0000 - val_loss: 0.0110 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0163 - binary_accuracy: 1.0000 - val_loss: 0.0108 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 0.0105 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0131 - binary_accuracy: 1.0000 - val_loss: 0.0103 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 9692\n",
      "[[0.9292631 ]\n",
      " [0.88011193]\n",
      " [0.93042064]\n",
      " [0.92446303]\n",
      " [0.89494485]\n",
      " [0.91328007]\n",
      " [0.9539885 ]\n",
      " [0.8855326 ]\n",
      " [0.9329907 ]\n",
      " [0.9413014 ]\n",
      " [0.9434901 ]\n",
      " [0.93006235]\n",
      " [0.91317946]\n",
      " [0.93632025]\n",
      " [0.94549847]\n",
      " [0.93055034]\n",
      " [0.90200937]\n",
      " [0.92662823]\n",
      " [0.9291107 ]\n",
      " [0.9353691 ]\n",
      " [0.9406783 ]\n",
      " [0.90058595]\n",
      " [0.92476344]\n",
      " [0.91008407]\n",
      " [0.9326312 ]\n",
      " [0.92561394]\n",
      " [0.8876806 ]\n",
      " [0.9428613 ]\n",
      " [0.88918626]\n",
      " [0.9400191 ]\n",
      " [0.9385661 ]\n",
      " [0.9101048 ]\n",
      " [0.91985476]\n",
      " [0.89697576]\n",
      " [0.91782254]\n",
      " [0.91405857]\n",
      " [0.91270214]\n",
      " [0.9146051 ]\n",
      " [0.9150504 ]\n",
      " [0.9349029 ]\n",
      " [0.8530073 ]\n",
      " [0.86405873]\n",
      " [0.88015014]\n",
      " [0.92435414]\n",
      " [0.9435695 ]\n",
      " [0.9397259 ]\n",
      " [0.9223049 ]\n",
      " [0.8991118 ]\n",
      " [0.82614493]\n",
      " [0.87600243]\n",
      " [0.85498905]\n",
      " [0.9086396 ]\n",
      " [0.9263042 ]\n",
      " [0.9460619 ]\n",
      " [0.9227453 ]\n",
      " [0.9288953 ]\n",
      " [0.9126665 ]\n",
      " [0.92529356]\n",
      " [0.93522084]\n",
      " [0.9278934 ]\n",
      " [0.9276063 ]\n",
      " [0.9079647 ]\n",
      " [0.9403922 ]\n",
      " [0.9346073 ]\n",
      " [0.9134758 ]\n",
      " [0.89606494]\n",
      " [0.9252133 ]\n",
      " [0.92532164]\n",
      " [0.89985543]\n",
      " [0.90585345]\n",
      " [0.926273  ]\n",
      " [0.8984359 ]\n",
      " [0.91608155]\n",
      " [0.8907452 ]\n",
      " [0.91188926]\n",
      " [0.9062917 ]\n",
      " [0.90476876]\n",
      " [0.94302994]\n",
      " [0.9139573 ]\n",
      " [0.86747867]\n",
      " [0.8892296 ]\n",
      " [0.82773626]\n",
      " [0.8944823 ]\n",
      " [0.83189166]\n",
      " [0.8816499 ]\n",
      " [0.89314204]\n",
      " [0.86251694]\n",
      " [0.8944045 ]\n",
      " [0.85700434]\n",
      " [0.8538194 ]\n",
      " [0.93501323]\n",
      " [0.85336256]\n",
      " [0.92157704]\n",
      " [0.92442495]\n",
      " [0.935218  ]\n",
      " [0.92535424]\n",
      " [0.86638546]\n",
      " [0.8682078 ]\n",
      " [0.8816125 ]\n",
      " [0.8819231 ]\n",
      " [0.8652581 ]\n",
      " [0.83147043]\n",
      " [0.87043977]\n",
      " [0.86455077]\n",
      " [0.8798411 ]\n",
      " [0.92591006]\n",
      " [0.94195676]\n",
      " [0.92362124]\n",
      " [0.9287818 ]\n",
      " [0.8484893 ]\n",
      " [0.88983727]\n",
      " [0.8620288 ]\n",
      " [0.9261571 ]\n",
      " [0.8547928 ]\n",
      " [0.9379882 ]\n",
      " [0.94759464]\n",
      " [0.9310767 ]\n",
      " [0.88373446]\n",
      " [0.9387852 ]\n",
      " [0.92553216]\n",
      " [0.93118066]\n",
      " [0.9153122 ]\n",
      " [0.9210245 ]\n",
      " [0.9209808 ]\n",
      " [0.9235345 ]\n",
      " [0.93526036]\n",
      " [0.9275381 ]\n",
      " [0.92322034]\n",
      " [0.9299453 ]\n",
      " [0.93825483]]\n",
      "[[0.9491847 ]\n",
      " [0.95658666]\n",
      " [0.93455756]\n",
      " [0.9263167 ]\n",
      " [0.9191882 ]\n",
      " [0.9073199 ]\n",
      " [0.93914497]\n",
      " [0.93276846]\n",
      " [0.9281036 ]\n",
      " [0.9284013 ]\n",
      " [0.92228866]\n",
      " [0.92528695]\n",
      " [0.94508195]\n",
      " [0.9446408 ]\n",
      " [0.94029343]\n",
      " [0.93712467]\n",
      " [0.9405967 ]\n",
      " [0.92440504]\n",
      " [0.9318023 ]\n",
      " [0.9513766 ]\n",
      " [0.9282812 ]\n",
      " [0.9400298 ]\n",
      " [0.92564535]\n",
      " [0.9352376 ]\n",
      " [0.9366422 ]\n",
      " [0.9357933 ]\n",
      " [0.9290428 ]\n",
      " [0.9513193 ]\n",
      " [0.9469404 ]\n",
      " [0.93544847]\n",
      " [0.92976254]\n",
      " [0.92785734]\n",
      " [0.93575025]\n",
      " [0.89492595]\n",
      " [0.89510643]\n",
      " [0.88577724]\n",
      " [0.9106634 ]\n",
      " [0.93373924]\n",
      " [0.9349607 ]\n",
      " [0.9378744 ]\n",
      " [0.95228887]\n",
      " [0.9487324 ]\n",
      " [0.9400388 ]\n",
      " [0.9143449 ]\n",
      " [0.9061794 ]\n",
      " [0.9407129 ]\n",
      " [0.94366574]\n",
      " [0.93306553]\n",
      " [0.9440828 ]\n",
      " [0.9414641 ]\n",
      " [0.91288126]\n",
      " [0.9458377 ]\n",
      " [0.95816004]\n",
      " [0.9482402 ]\n",
      " [0.9321153 ]\n",
      " [0.8926177 ]\n",
      " [0.92791903]\n",
      " [0.9053192 ]\n",
      " [0.9173839 ]\n",
      " [0.9476771 ]\n",
      " [0.9258606 ]\n",
      " [0.9379355 ]\n",
      " [0.9432908 ]\n",
      " [0.9288466 ]\n",
      " [0.92237544]\n",
      " [0.9307961 ]\n",
      " [0.90541565]\n",
      " [0.9214702 ]\n",
      " [0.8704875 ]\n",
      " [0.9152922 ]\n",
      " [0.9461517 ]\n",
      " [0.94392735]\n",
      " [0.94718015]\n",
      " [0.9525947 ]\n",
      " [0.9398629 ]\n",
      " [0.9356838 ]\n",
      " [0.9411108 ]\n",
      " [0.93281174]\n",
      " [0.94366455]\n",
      " [0.9619599 ]\n",
      " [0.93514407]\n",
      " [0.94394076]\n",
      " [0.86001843]\n",
      " [0.8974603 ]\n",
      " [0.86040765]\n",
      " [0.81614757]\n",
      " [0.88140815]\n",
      " [0.898364  ]\n",
      " [0.88695216]\n",
      " [0.9011081 ]\n",
      " [0.8895588 ]\n",
      " [0.862761  ]\n",
      " [0.87960565]\n",
      " [0.91949743]\n",
      " [0.91081905]\n",
      " [0.87347305]\n",
      " [0.8511812 ]\n",
      " [0.9175286 ]\n",
      " [0.8731794 ]\n",
      " [0.901383  ]\n",
      " [0.90828574]\n",
      " [0.9119054 ]\n",
      " [0.88027567]\n",
      " [0.86977935]\n",
      " [0.869284  ]\n",
      " [0.8990457 ]\n",
      " [0.9101848 ]]\n",
      "[[0.9295433 ]\n",
      " [0.93544805]\n",
      " [0.9427687 ]\n",
      " [0.9302743 ]\n",
      " [0.9275801 ]\n",
      " [0.9108048 ]\n",
      " [0.9247126 ]\n",
      " [0.94205385]\n",
      " [0.9285794 ]\n",
      " [0.935559  ]\n",
      " [0.9459404 ]\n",
      " [0.93856084]\n",
      " [0.9315127 ]\n",
      " [0.93472207]\n",
      " [0.9187269 ]\n",
      " [0.9190012 ]\n",
      " [0.93476886]\n",
      " [0.934233  ]\n",
      " [0.9309487 ]\n",
      " [0.9181583 ]\n",
      " [0.9399275 ]\n",
      " [0.9306643 ]\n",
      " [0.95732445]\n",
      " [0.9588769 ]\n",
      " [0.9630251 ]\n",
      " [0.96183836]\n",
      " [0.9627727 ]\n",
      " [0.9569276 ]\n",
      " [0.94686836]\n",
      " [0.9524566 ]\n",
      " [0.9572305 ]\n",
      " [0.9416762 ]\n",
      " [0.9607575 ]\n",
      " [0.9486349 ]\n",
      " [0.9551132 ]\n",
      " [0.94728005]\n",
      " [0.96921676]\n",
      " [0.947652  ]\n",
      " [0.9614285 ]\n",
      " [0.96292216]\n",
      " [0.9663295 ]\n",
      " [0.96089494]\n",
      " [0.94714946]\n",
      " [0.9288049 ]\n",
      " [0.9551025 ]\n",
      " [0.94959724]\n",
      " [0.9566141 ]\n",
      " [0.95246017]\n",
      " [0.9558555 ]\n",
      " [0.9491303 ]\n",
      " [0.95578265]\n",
      " [0.9639536 ]\n",
      " [0.9389594 ]\n",
      " [0.95132846]\n",
      " [0.95799077]\n",
      " [0.9503966 ]\n",
      " [0.96230245]\n",
      " [0.96233004]\n",
      " [0.96135116]\n",
      " [0.9548868 ]\n",
      " [0.9536293 ]\n",
      " [0.95881027]\n",
      " [0.9423377 ]\n",
      " [0.94906104]\n",
      " [0.9483456 ]\n",
      " [0.95590365]\n",
      " [0.92522264]\n",
      " [0.9305561 ]\n",
      " [0.94718516]\n",
      " [0.941805  ]\n",
      " [0.96541405]\n",
      " [0.95854974]\n",
      " [0.9577235 ]\n",
      " [0.94040394]\n",
      " [0.9610257 ]\n",
      " [0.95121455]\n",
      " [0.9566238 ]\n",
      " [0.9584849 ]\n",
      " [0.95780987]\n",
      " [0.9551377 ]\n",
      " [0.96280634]\n",
      " [0.9520281 ]\n",
      " [0.9575318 ]\n",
      " [0.9518896 ]\n",
      " [0.964098  ]\n",
      " [0.9578862 ]\n",
      " [0.94928676]\n",
      " [0.93315   ]\n",
      " [0.9663911 ]\n",
      " [0.93684924]\n",
      " [0.93881345]\n",
      " [0.94592047]\n",
      " [0.95258725]\n",
      " [0.9556636 ]\n",
      " [0.9584255 ]\n",
      " [0.96448153]\n",
      " [0.95787036]\n",
      " [0.95440793]\n",
      " [0.9511698 ]\n",
      " [0.9641964 ]\n",
      " [0.9515895 ]\n",
      " [0.95279974]\n",
      " [0.9552444 ]\n",
      " [0.9417997 ]\n",
      " [0.95419914]\n",
      " [0.95086545]\n",
      " [0.95278513]\n",
      " [0.9518345 ]\n",
      " [0.95588166]\n",
      " [0.9543522 ]\n",
      " [0.9447713 ]\n",
      " [0.935417  ]\n",
      " [0.95757544]\n",
      " [0.95840406]\n",
      " [0.970909  ]\n",
      " [0.9695674 ]\n",
      " [0.96625274]\n",
      " [0.9484227 ]\n",
      " [0.9568578 ]\n",
      " [0.9641445 ]\n",
      " [0.94235325]\n",
      " [0.9393244 ]\n",
      " [0.95741206]\n",
      " [0.96017313]]\n",
      "[[0.8403238 ]\n",
      " [0.8509689 ]\n",
      " [0.8795835 ]\n",
      " [0.82907283]\n",
      " [0.8470157 ]\n",
      " [0.8400026 ]\n",
      " [0.8374584 ]\n",
      " [0.8792671 ]\n",
      " [0.84843636]\n",
      " [0.8773383 ]\n",
      " [0.8150044 ]\n",
      " [0.88293123]\n",
      " [0.808061  ]\n",
      " [0.8535856 ]\n",
      " [0.9083166 ]\n",
      " [0.91905123]\n",
      " [0.94277793]\n",
      " [0.9214675 ]\n",
      " [0.9471946 ]\n",
      " [0.88723534]\n",
      " [0.92948544]\n",
      " [0.89656526]\n",
      " [0.9255087 ]\n",
      " [0.92824465]\n",
      " [0.9334589 ]\n",
      " [0.96022916]\n",
      " [0.9060147 ]\n",
      " [0.951157  ]\n",
      " [0.9110121 ]\n",
      " [0.9294639 ]\n",
      " [0.922973  ]\n",
      " [0.87666374]\n",
      " [0.95454484]\n",
      " [0.9101848 ]\n",
      " [0.8913707 ]\n",
      " [0.9215015 ]\n",
      " [0.8673829 ]\n",
      " [0.94063044]\n",
      " [0.9236853 ]\n",
      " [0.9306897 ]\n",
      " [0.9344885 ]\n",
      " [0.88473743]\n",
      " [0.94459605]\n",
      " [0.9387287 ]\n",
      " [0.8913523 ]\n",
      " [0.925093  ]\n",
      " [0.9241368 ]\n",
      " [0.8913835 ]\n",
      " [0.9406498 ]\n",
      " [0.9288867 ]\n",
      " [0.9260322 ]\n",
      " [0.93493885]\n",
      " [0.92536604]\n",
      " [0.9202995 ]\n",
      " [0.9440824 ]\n",
      " [0.91998124]\n",
      " [0.89870465]\n",
      " [0.90831727]\n",
      " [0.94251055]\n",
      " [0.9032271 ]\n",
      " [0.94301546]\n",
      " [0.9118033 ]\n",
      " [0.91808534]\n",
      " [0.93308127]\n",
      " [0.93961674]\n",
      " [0.9301427 ]\n",
      " [0.92766863]\n",
      " [0.9301852 ]\n",
      " [0.9354216 ]\n",
      " [0.9286748 ]\n",
      " [0.92451155]\n",
      " [0.8997815 ]\n",
      " [0.8653641 ]\n",
      " [0.89608765]\n",
      " [0.9023316 ]\n",
      " [0.9114672 ]\n",
      " [0.9022489 ]\n",
      " [0.8982509 ]\n",
      " [0.9315648 ]\n",
      " [0.91936964]\n",
      " [0.9047759 ]\n",
      " [0.9044551 ]\n",
      " [0.9302051 ]\n",
      " [0.9103459 ]\n",
      " [0.8074639 ]\n",
      " [0.9299372 ]\n",
      " [0.93601996]\n",
      " [0.9264675 ]\n",
      " [0.9420038 ]\n",
      " [0.9135101 ]\n",
      " [0.928957  ]\n",
      " [0.93128216]\n",
      " [0.8983541 ]\n",
      " [0.9088049 ]\n",
      " [0.915798  ]\n",
      " [0.9134232 ]\n",
      " [0.90267175]\n",
      " [0.9218671 ]\n",
      " [0.918554  ]\n",
      " [0.8651684 ]\n",
      " [0.92067945]\n",
      " [0.9347708 ]\n",
      " [0.8884699 ]\n",
      " [0.94203925]\n",
      " [0.8920814 ]\n",
      " [0.90684134]\n",
      " [0.9315483 ]\n",
      " [0.8886591 ]\n",
      " [0.9357782 ]\n",
      " [0.9406303 ]\n",
      " [0.9121325 ]\n",
      " [0.9512194 ]\n",
      " [0.9194861 ]\n",
      " [0.94157434]\n",
      " [0.9290682 ]\n",
      " [0.8914533 ]\n",
      " [0.8758092 ]\n",
      " [0.9049612 ]\n",
      " [0.94118005]\n",
      " [0.8870596 ]\n",
      " [0.8857873 ]\n",
      " [0.912623  ]\n",
      " [0.93574345]]\n",
      "[[1.4060402e-03]\n",
      " [4.7575026e-03]\n",
      " [1.5426369e-02]\n",
      " [2.6354352e-03]\n",
      " [7.9181410e-02]\n",
      " [5.6649591e-03]\n",
      " [1.5908526e-02]\n",
      " [7.6532881e-03]\n",
      " [7.6757988e-04]\n",
      " [1.8340368e-02]\n",
      " [2.0997711e-03]\n",
      " [5.9502651e-03]\n",
      " [2.7678895e-04]\n",
      " [6.4083346e-04]\n",
      " [2.4145186e-02]\n",
      " [9.9730921e-01]\n",
      " [9.9748862e-01]\n",
      " [9.9457490e-01]\n",
      " [9.9718177e-01]\n",
      " [4.4665539e-01]\n",
      " [9.8409235e-01]\n",
      " [9.9516535e-01]\n",
      " [6.9443536e-01]\n",
      " [9.9824727e-01]\n",
      " [9.9590439e-01]\n",
      " [9.6778196e-01]\n",
      " [9.7216874e-01]\n",
      " [9.8838449e-01]\n",
      " [2.7236149e-01]\n",
      " [9.8545331e-01]\n",
      " [9.9838006e-01]\n",
      " [9.9702698e-01]\n",
      " [9.9636936e-01]\n",
      " [9.9572718e-01]\n",
      " [9.9212962e-01]\n",
      " [9.9545199e-01]\n",
      " [4.0720753e-02]\n",
      " [9.9429882e-01]\n",
      " [9.9581283e-01]\n",
      " [9.9600452e-01]\n",
      " [8.9052635e-01]\n",
      " [9.9569231e-01]\n",
      " [9.3562418e-01]\n",
      " [9.9551445e-01]\n",
      " [9.9808264e-01]\n",
      " [9.9466008e-01]\n",
      " [9.9251926e-01]\n",
      " [9.8636138e-01]\n",
      " [9.9901819e-01]\n",
      " [4.4896290e-02]\n",
      " [9.8349863e-01]\n",
      " [9.9706322e-01]\n",
      " [9.7024781e-01]\n",
      " [9.9346524e-01]\n",
      " [9.9856514e-01]\n",
      " [8.9090991e-01]\n",
      " [9.5444864e-01]\n",
      " [8.2064950e-01]\n",
      " [9.9671602e-01]\n",
      " [9.6657312e-01]\n",
      " [9.9844033e-01]\n",
      " [9.9536514e-01]\n",
      " [9.9775380e-01]\n",
      " [9.9398488e-01]\n",
      " [9.8719990e-01]\n",
      " [9.9751770e-01]\n",
      " [9.8857552e-01]\n",
      " [9.9286228e-01]\n",
      " [9.9384403e-01]\n",
      " [9.6840626e-01]\n",
      " [9.5055521e-01]\n",
      " [9.7878176e-01]\n",
      " [3.8651053e-03]\n",
      " [9.9209833e-01]\n",
      " [9.9652988e-01]]\n",
      "[[9.9671751e-01]\n",
      " [9.8896676e-01]\n",
      " [9.9942529e-01]\n",
      " [9.8435152e-01]\n",
      " [9.9538946e-01]\n",
      " [9.9572939e-01]\n",
      " [9.9531955e-01]\n",
      " [9.6616369e-01]\n",
      " [9.5866311e-01]\n",
      " [9.9605560e-01]\n",
      " [9.9366790e-01]\n",
      " [9.9386495e-01]\n",
      " [9.9729294e-01]\n",
      " [9.9629253e-01]\n",
      " [9.9324799e-01]\n",
      " [9.9625468e-01]\n",
      " [9.9779946e-01]\n",
      " [9.8658293e-01]\n",
      " [9.9900466e-01]\n",
      " [9.9280131e-01]\n",
      " [9.9587041e-01]\n",
      " [2.5639107e-02]\n",
      " [9.1149885e-04]\n",
      " [2.6149084e-04]\n",
      " [5.3154589e-03]\n",
      " [2.0583724e-03]\n",
      " [2.0554971e-02]\n",
      " [5.8861636e-04]\n",
      " [8.1896642e-03]\n",
      " [1.7198522e-02]\n",
      " [5.3156028e-03]\n",
      " [4.1124072e-02]\n",
      " [8.4377217e-01]\n",
      " [9.9902463e-01]\n",
      " [9.8777872e-01]\n",
      " [9.9496198e-01]\n",
      " [9.9624038e-01]\n",
      " [9.9428719e-01]\n",
      " [9.7023386e-01]\n",
      " [9.9915028e-01]\n",
      " [2.1762114e-03]\n",
      " [1.2520891e-02]\n",
      " [3.7396071e-03]\n",
      " [1.5047351e-03]\n",
      " [9.9414802e-01]]\n",
      "[[9.6789375e-03]\n",
      " [1.2803693e-02]\n",
      " [6.7725219e-03]\n",
      " [2.5925910e-02]\n",
      " [8.9766772e-04]\n",
      " [2.3181103e-04]\n",
      " [5.0668493e-03]\n",
      " [2.0366954e-03]\n",
      " [1.7043903e-02]\n",
      " [8.4450474e-04]\n",
      " [7.3371422e-03]\n",
      " [1.2560128e-02]\n",
      " [4.5297127e-03]\n",
      " [1.9564222e-01]\n",
      " [2.1409735e-03]\n",
      " [1.7683128e-02]\n",
      " [5.6942408e-03]\n",
      " [1.2266412e-03]\n",
      " [9.9314475e-01]\n",
      " [9.9939084e-01]\n",
      " [9.9071807e-01]\n",
      " [9.9027234e-01]\n",
      " [9.9670511e-01]\n",
      " [9.9557388e-01]\n",
      " [9.9214208e-01]\n",
      " [9.9065316e-01]\n",
      " [9.9223256e-01]\n",
      " [9.8783374e-01]\n",
      " [9.8766673e-01]\n",
      " [9.8791158e-01]\n",
      " [9.8869717e-01]\n",
      " [9.9734974e-01]\n",
      " [9.9127966e-01]\n",
      " [9.4078380e-01]\n",
      " [9.8944598e-01]\n",
      " [9.8482239e-01]\n",
      " [7.5393599e-01]\n",
      " [9.9478793e-01]\n",
      " [7.6949120e-01]\n",
      " [4.4508028e-01]\n",
      " [9.9340266e-01]\n",
      " [9.8996186e-01]\n",
      " [9.6341062e-01]\n",
      " [9.4218403e-02]\n",
      " [9.7295141e-01]\n",
      " [9.9312216e-01]\n",
      " [8.4235829e-01]\n",
      " [9.9468493e-01]\n",
      " [4.6694827e-01]\n",
      " [9.9536210e-01]\n",
      " [2.8104007e-01]\n",
      " [1.0071514e-02]\n",
      " [9.7243553e-01]\n",
      " [9.8741210e-01]\n",
      " [9.9201548e-01]\n",
      " [9.9434352e-01]\n",
      " [9.6925688e-01]\n",
      " [9.5010120e-01]\n",
      " [9.8761046e-01]\n",
      " [9.6124309e-01]\n",
      " [9.9261135e-01]\n",
      " [8.3672482e-01]\n",
      " [5.1279652e-01]\n",
      " [9.8928422e-01]\n",
      " [4.6046931e-02]\n",
      " [6.6453330e-03]\n",
      " [9.2774183e-01]\n",
      " [9.8209274e-01]\n",
      " [8.1292691e-04]\n",
      " [9.0179521e-01]]\n",
      "[[0.9311446 ]\n",
      " [0.9090673 ]\n",
      " [0.9440892 ]\n",
      " [0.9080295 ]\n",
      " [0.93941975]\n",
      " [0.9118046 ]\n",
      " [0.89537364]\n",
      " [0.9122166 ]\n",
      " [0.8688844 ]\n",
      " [0.96061546]\n",
      " [0.935661  ]\n",
      " [0.8965318 ]\n",
      " [0.9376756 ]\n",
      " [0.8636563 ]\n",
      " [0.8588778 ]\n",
      " [0.8247401 ]\n",
      " [0.84172094]\n",
      " [0.83864   ]\n",
      " [0.9366986 ]\n",
      " [0.9014671 ]\n",
      " [0.91035604]\n",
      " [0.9080801 ]\n",
      " [0.90931815]\n",
      " [0.90298367]\n",
      " [0.9085204 ]\n",
      " [0.9085408 ]\n",
      " [0.90703833]\n",
      " [0.9181232 ]\n",
      " [0.9336049 ]\n",
      " [0.9306827 ]\n",
      " [0.8282385 ]\n",
      " [0.86579126]\n",
      " [0.8797522 ]\n",
      " [0.81696975]\n",
      " [0.8924388 ]\n",
      " [0.88471335]\n",
      " [0.93184185]\n",
      " [0.9014343 ]\n",
      " [0.9296167 ]\n",
      " [0.94504917]\n",
      " [0.92917645]\n",
      " [0.8812027 ]\n",
      " [0.9230545 ]\n",
      " [0.9256149 ]\n",
      " [0.899946  ]\n",
      " [0.90721834]\n",
      " [0.9217891 ]\n",
      " [0.91915256]\n",
      " [0.92422986]\n",
      " [0.9244682 ]\n",
      " [0.917968  ]\n",
      " [0.92704123]\n",
      " [0.8989504 ]\n",
      " [0.89768034]\n",
      " [0.8876465 ]\n",
      " [0.88114536]\n",
      " [0.91208744]\n",
      " [0.92678785]\n",
      " [0.9136715 ]\n",
      " [0.9224139 ]\n",
      " [0.89487565]\n",
      " [0.8585434 ]\n",
      " [0.8854545 ]\n",
      " [0.87001646]\n",
      " [0.924472  ]\n",
      " [0.92205334]\n",
      " [0.9225682 ]\n",
      " [0.93366987]\n",
      " [0.90703785]\n",
      " [0.8856908 ]\n",
      " [0.93375653]\n",
      " [0.92000294]\n",
      " [0.9487139 ]\n",
      " [0.9090584 ]\n",
      " [0.9343646 ]\n",
      " [0.9212785 ]\n",
      " [0.9108232 ]\n",
      " [0.7854968 ]\n",
      " [0.8621628 ]\n",
      " [0.93557453]\n",
      " [0.93403274]\n",
      " [0.85838   ]\n",
      " [0.88816845]\n",
      " [0.8845383 ]\n",
      " [0.8504396 ]\n",
      " [0.87346774]\n",
      " [0.9246717 ]\n",
      " [0.93709916]\n",
      " [0.88007486]\n",
      " [0.8588857 ]\n",
      " [0.88206995]\n",
      " [0.87167925]\n",
      " [0.9370539 ]\n",
      " [0.9313245 ]\n",
      " [0.92252964]\n",
      " [0.9316629 ]\n",
      " [0.89617133]\n",
      " [0.9258008 ]\n",
      " [0.89903754]\n",
      " [0.8728243 ]\n",
      " [0.85103816]\n",
      " [0.9177702 ]\n",
      " [0.903999  ]]\n",
      "[[0.93618095]\n",
      " [0.9218287 ]\n",
      " [0.94541854]\n",
      " [0.95956516]\n",
      " [0.94952834]\n",
      " [0.9469438 ]\n",
      " [0.95608854]\n",
      " [0.9358168 ]\n",
      " [0.93113226]\n",
      " [0.9046845 ]\n",
      " [0.8903971 ]\n",
      " [0.91442007]\n",
      " [0.89953905]\n",
      " [0.88076246]\n",
      " [0.90103096]\n",
      " [0.8888887 ]\n",
      " [0.8855061 ]\n",
      " [0.9089075 ]\n",
      " [0.913211  ]\n",
      " [0.9023034 ]\n",
      " [0.9005555 ]\n",
      " [0.8887072 ]\n",
      " [0.89924335]\n",
      " [0.898975  ]\n",
      " [0.89523464]\n",
      " [0.8992966 ]\n",
      " [0.9082989 ]\n",
      " [0.90984696]\n",
      " [0.90441   ]\n",
      " [0.8943262 ]]\n",
      "Model: \"model_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_84 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 2s 99ms/step - loss: 1.2384 - accuracy: 0.1974 - val_loss: 1.0282 - val_accuracy: 0.4286\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0254 - accuracy: 0.5135 - val_loss: 0.7892 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9675 - accuracy: 0.7020 - val_loss: 0.6131 - val_accuracy: 0.5714\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.8562 - accuracy: 0.6847 - val_loss: 0.4911 - val_accuracy: 0.6429\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.7083 - accuracy: 0.7613 - val_loss: 0.3950 - val_accuracy: 0.7857\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.6373 - accuracy: 0.7680 - val_loss: 0.3216 - val_accuracy: 0.9286\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.6884 - accuracy: 0.7537 - val_loss: 0.2682 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.5274 - accuracy: 0.8348 - val_loss: 0.2247 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.5344 - accuracy: 0.7991 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4276 - accuracy: 0.8820 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3588 - accuracy: 0.8939 - val_loss: 0.1547 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.5745 - accuracy: 0.8276 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3463 - accuracy: 0.8964 - val_loss: 0.1303 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3713 - accuracy: 0.8412 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.4087 - accuracy: 0.8610 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2897 - accuracy: 0.8305 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3274 - accuracy: 0.8439 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.3046 - accuracy: 0.9230 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.4468 - accuracy: 0.8677 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2556 - accuracy: 0.8999 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 128ms/step - loss: 0.3475 - binary_accuracy: 0.8752 - val_loss: 0.0801 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.4118 - binary_accuracy: 0.8495 - val_loss: 0.0786 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2777 - binary_accuracy: 0.8407 - val_loss: 0.0772 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2531 - binary_accuracy: 0.8801 - val_loss: 0.0775 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.3238 - binary_accuracy: 0.8781 - val_loss: 0.0800 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2175 - binary_accuracy: 0.9313 - val_loss: 0.0758 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2225 - binary_accuracy: 0.9294 - val_loss: 0.0712 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1625 - binary_accuracy: 0.9620 - val_loss: 0.0690 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1967 - binary_accuracy: 0.9194 - val_loss: 0.0736 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.2127 - binary_accuracy: 0.9110 - val_loss: 0.0724 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1213 - binary_accuracy: 0.9703 - val_loss: 0.0677 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1423 - binary_accuracy: 0.9405 - val_loss: 0.0704 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1189 - binary_accuracy: 0.9401 - val_loss: 0.0729 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1034 - binary_accuracy: 0.9790 - val_loss: 0.0687 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1305 - binary_accuracy: 0.9456 - val_loss: 0.0704 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1599 - binary_accuracy: 0.9130 - val_loss: 0.0698 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1089 - binary_accuracy: 0.9834 - val_loss: 0.0656 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1037 - binary_accuracy: 0.9722 - val_loss: 0.0661 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1373 - binary_accuracy: 0.9757 - val_loss: 0.0645 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0787 - binary_accuracy: 0.9834 - val_loss: 0.0610 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0957 - binary_accuracy: 0.9460 - val_loss: 0.0584 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0941 - binary_accuracy: 0.9686 - val_loss: 0.0548 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0982 - binary_accuracy: 0.9572 - val_loss: 0.0549 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0733 - binary_accuracy: 0.9650 - val_loss: 0.0564 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0883 - binary_accuracy: 0.9572 - val_loss: 0.0544 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0687 - binary_accuracy: 0.9805 - val_loss: 0.0521 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0935 - binary_accuracy: 0.9388 - val_loss: 0.0525 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0834 - binary_accuracy: 0.9507 - val_loss: 0.0510 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0701 - binary_accuracy: 0.9834 - val_loss: 0.0487 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0619 - binary_accuracy: 0.9869 - val_loss: 0.0479 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0847 - binary_accuracy: 0.9623 - val_loss: 0.0517 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0589 - binary_accuracy: 1.0000 - val_loss: 0.0475 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0692 - binary_accuracy: 0.9920 - val_loss: 0.0431 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0584 - binary_accuracy: 0.9805 - val_loss: 0.0430 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0780 - binary_accuracy: 0.9623 - val_loss: 0.0473 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0514 - binary_accuracy: 1.0000 - val_loss: 0.0460 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0708 - binary_accuracy: 1.0000 - val_loss: 0.0392 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.0394 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0569 - binary_accuracy: 1.0000 - val_loss: 0.0405 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0650 - binary_accuracy: 1.0000 - val_loss: 0.0407 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0538 - binary_accuracy: 1.0000 - val_loss: 0.0386 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.0372 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0562 - binary_accuracy: 1.0000 - val_loss: 0.0370 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0551 - binary_accuracy: 1.0000 - val_loss: 0.0380 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0416 - binary_accuracy: 1.0000 - val_loss: 0.0342 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0496 - binary_accuracy: 1.0000 - val_loss: 0.0332 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0466 - binary_accuracy: 1.0000 - val_loss: 0.0330 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0387 - binary_accuracy: 1.0000 - val_loss: 0.0331 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0320 - binary_accuracy: 1.0000 - val_loss: 0.0313 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0352 - binary_accuracy: 1.0000 - val_loss: 0.0303 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 13904\n",
      "[[0.9083106 ]\n",
      " [0.8672187 ]\n",
      " [0.88450235]\n",
      " [0.89477986]\n",
      " [0.8710503 ]\n",
      " [0.8799882 ]\n",
      " [0.90712947]\n",
      " [0.8676284 ]\n",
      " [0.8837857 ]\n",
      " [0.89476675]\n",
      " [0.9103041 ]\n",
      " [0.86953646]\n",
      " [0.8722794 ]\n",
      " [0.88520247]\n",
      " [0.88563734]\n",
      " [0.8868985 ]\n",
      " [0.8679823 ]\n",
      " [0.8810582 ]\n",
      " [0.87830603]\n",
      " [0.8787494 ]\n",
      " [0.87956595]\n",
      " [0.85833853]\n",
      " [0.8806379 ]\n",
      " [0.8716998 ]\n",
      " [0.8808568 ]\n",
      " [0.88624644]\n",
      " [0.8685731 ]\n",
      " [0.8885634 ]\n",
      " [0.8652548 ]\n",
      " [0.891521  ]\n",
      " [0.8867791 ]\n",
      " [0.86525446]\n",
      " [0.87349695]\n",
      " [0.8459884 ]\n",
      " [0.8686861 ]\n",
      " [0.8762497 ]\n",
      " [0.86910605]\n",
      " [0.88116854]\n",
      " [0.87574744]\n",
      " [0.870955  ]\n",
      " [0.8325846 ]\n",
      " [0.8388989 ]\n",
      " [0.83219016]\n",
      " [0.8777786 ]\n",
      " [0.9004951 ]\n",
      " [0.90058684]\n",
      " [0.88452846]\n",
      " [0.8761141 ]\n",
      " [0.85573244]\n",
      " [0.856796  ]\n",
      " [0.8652495 ]\n",
      " [0.86864454]\n",
      " [0.8840266 ]\n",
      " [0.91675127]\n",
      " [0.8760553 ]\n",
      " [0.8962594 ]\n",
      " [0.87777597]\n",
      " [0.89415616]\n",
      " [0.883983  ]\n",
      " [0.8825153 ]\n",
      " [0.88360274]\n",
      " [0.87187505]\n",
      " [0.8894245 ]\n",
      " [0.87672216]\n",
      " [0.86291337]\n",
      " [0.8649081 ]\n",
      " [0.89551926]\n",
      " [0.8944478 ]\n",
      " [0.8763165 ]\n",
      " [0.8663406 ]\n",
      " [0.8849716 ]\n",
      " [0.8583459 ]\n",
      " [0.8795857 ]\n",
      " [0.87414014]\n",
      " [0.8652222 ]\n",
      " [0.8627896 ]\n",
      " [0.86424655]\n",
      " [0.8970598 ]\n",
      " [0.8698298 ]\n",
      " [0.8424271 ]\n",
      " [0.87823147]\n",
      " [0.84247035]\n",
      " [0.85526556]\n",
      " [0.8356449 ]\n",
      " [0.8567647 ]\n",
      " [0.8880561 ]\n",
      " [0.84813565]\n",
      " [0.87091935]\n",
      " [0.86319184]\n",
      " [0.8497939 ]\n",
      " [0.86972713]\n",
      " [0.8505502 ]\n",
      " [0.8946901 ]\n",
      " [0.8866285 ]\n",
      " [0.87823284]\n",
      " [0.88191044]\n",
      " [0.8594441 ]\n",
      " [0.8373416 ]\n",
      " [0.8713567 ]\n",
      " [0.8575848 ]\n",
      " [0.8519634 ]\n",
      " [0.8269222 ]\n",
      " [0.8390738 ]\n",
      " [0.8393668 ]\n",
      " [0.8332459 ]\n",
      " [0.88921446]\n",
      " [0.9065124 ]\n",
      " [0.87089545]\n",
      " [0.87868166]\n",
      " [0.84386456]\n",
      " [0.8473729 ]\n",
      " [0.8458551 ]\n",
      " [0.88614196]\n",
      " [0.85538685]\n",
      " [0.9090032 ]\n",
      " [0.88653773]\n",
      " [0.9020067 ]\n",
      " [0.8700556 ]\n",
      " [0.8810807 ]\n",
      " [0.865665  ]\n",
      " [0.8689585 ]\n",
      " [0.8736364 ]\n",
      " [0.8832181 ]\n",
      " [0.8610865 ]\n",
      " [0.8932324 ]\n",
      " [0.8993782 ]\n",
      " [0.8769269 ]\n",
      " [0.8758058 ]\n",
      " [0.88259554]\n",
      " [0.87461305]]\n",
      "[[0.9120653 ]\n",
      " [0.90970874]\n",
      " [0.9121282 ]\n",
      " [0.9061563 ]\n",
      " [0.9040244 ]\n",
      " [0.89939165]\n",
      " [0.9024448 ]\n",
      " [0.90052205]\n",
      " [0.8945886 ]\n",
      " [0.90102726]\n",
      " [0.8980139 ]\n",
      " [0.89835644]\n",
      " [0.89815456]\n",
      " [0.91032237]\n",
      " [0.90880835]\n",
      " [0.89801013]\n",
      " [0.90362877]\n",
      " [0.8897376 ]\n",
      " [0.8983707 ]\n",
      " [0.92266995]\n",
      " [0.8887376 ]\n",
      " [0.8856349 ]\n",
      " [0.88609767]\n",
      " [0.89930564]\n",
      " [0.898558  ]\n",
      " [0.9124642 ]\n",
      " [0.8937584 ]\n",
      " [0.8979322 ]\n",
      " [0.89250195]\n",
      " [0.8830507 ]\n",
      " [0.90200686]\n",
      " [0.89013326]\n",
      " [0.917885  ]\n",
      " [0.87325275]\n",
      " [0.88491064]\n",
      " [0.8712015 ]\n",
      " [0.89114535]\n",
      " [0.9096023 ]\n",
      " [0.90737075]\n",
      " [0.8902149 ]\n",
      " [0.9076586 ]\n",
      " [0.9045895 ]\n",
      " [0.90758985]\n",
      " [0.8910034 ]\n",
      " [0.88805807]\n",
      " [0.88778543]\n",
      " [0.90745956]\n",
      " [0.89995044]\n",
      " [0.8994065 ]\n",
      " [0.9002052 ]\n",
      " [0.87094   ]\n",
      " [0.9033128 ]\n",
      " [0.9258611 ]\n",
      " [0.9214563 ]\n",
      " [0.91115105]\n",
      " [0.8687177 ]\n",
      " [0.8916334 ]\n",
      " [0.9001935 ]\n",
      " [0.8986155 ]\n",
      " [0.899551  ]\n",
      " [0.89653146]\n",
      " [0.90389556]\n",
      " [0.9001479 ]\n",
      " [0.8955117 ]\n",
      " [0.8953861 ]\n",
      " [0.898599  ]\n",
      " [0.88221145]\n",
      " [0.9088217 ]\n",
      " [0.88170016]\n",
      " [0.89070386]\n",
      " [0.90157026]\n",
      " [0.89487994]\n",
      " [0.8922051 ]\n",
      " [0.9158008 ]\n",
      " [0.92530024]\n",
      " [0.92439294]\n",
      " [0.90132445]\n",
      " [0.90733254]\n",
      " [0.90132874]\n",
      " [0.9309325 ]\n",
      " [0.8924014 ]\n",
      " [0.8964782 ]\n",
      " [0.86902535]\n",
      " [0.8778607 ]\n",
      " [0.8698698 ]\n",
      " [0.8538101 ]\n",
      " [0.8692219 ]\n",
      " [0.8714157 ]\n",
      " [0.8609787 ]\n",
      " [0.861897  ]\n",
      " [0.8645317 ]\n",
      " [0.84494644]\n",
      " [0.87587243]\n",
      " [0.88018733]\n",
      " [0.87747645]\n",
      " [0.8793478 ]\n",
      " [0.85797423]\n",
      " [0.86654025]\n",
      " [0.8649762 ]\n",
      " [0.86363536]\n",
      " [0.8775629 ]\n",
      " [0.89090496]\n",
      " [0.8710594 ]\n",
      " [0.8441264 ]\n",
      " [0.8536025 ]\n",
      " [0.8811764 ]\n",
      " [0.8796047 ]]\n",
      "[[0.89118683]\n",
      " [0.8642436 ]\n",
      " [0.87718576]\n",
      " [0.8767137 ]\n",
      " [0.88273036]\n",
      " [0.8871835 ]\n",
      " [0.89014566]\n",
      " [0.8837302 ]\n",
      " [0.881292  ]\n",
      " [0.88599515]\n",
      " [0.8971136 ]\n",
      " [0.8762746 ]\n",
      " [0.8734182 ]\n",
      " [0.89339876]\n",
      " [0.8790099 ]\n",
      " [0.8820417 ]\n",
      " [0.88555664]\n",
      " [0.8862305 ]\n",
      " [0.8892153 ]\n",
      " [0.8694475 ]\n",
      " [0.89239913]\n",
      " [0.88962287]\n",
      " [0.9013853 ]\n",
      " [0.91114986]\n",
      " [0.9063358 ]\n",
      " [0.91624033]\n",
      " [0.9065503 ]\n",
      " [0.9026983 ]\n",
      " [0.9178382 ]\n",
      " [0.9055299 ]\n",
      " [0.91071504]\n",
      " [0.8882687 ]\n",
      " [0.9071833 ]\n",
      " [0.89731205]\n",
      " [0.9048494 ]\n",
      " [0.8983406 ]\n",
      " [0.92322844]\n",
      " [0.9072163 ]\n",
      " [0.91191703]\n",
      " [0.91750604]\n",
      " [0.92193186]\n",
      " [0.911592  ]\n",
      " [0.9014507 ]\n",
      " [0.8735727 ]\n",
      " [0.9097014 ]\n",
      " [0.9093682 ]\n",
      " [0.910504  ]\n",
      " [0.90675527]\n",
      " [0.8986635 ]\n",
      " [0.9050267 ]\n",
      " [0.90349084]\n",
      " [0.91023564]\n",
      " [0.89531374]\n",
      " [0.9068769 ]\n",
      " [0.9010682 ]\n",
      " [0.90243304]\n",
      " [0.90761095]\n",
      " [0.91709226]\n",
      " [0.90533346]\n",
      " [0.90880466]\n",
      " [0.9011273 ]\n",
      " [0.91032475]\n",
      " [0.8936592 ]\n",
      " [0.9062753 ]\n",
      " [0.9036971 ]\n",
      " [0.91566217]\n",
      " [0.9021743 ]\n",
      " [0.8958705 ]\n",
      " [0.90455043]\n",
      " [0.90689117]\n",
      " [0.9017771 ]\n",
      " [0.9045071 ]\n",
      " [0.9056435 ]\n",
      " [0.90080374]\n",
      " [0.9176254 ]\n",
      " [0.92235893]\n",
      " [0.89420533]\n",
      " [0.9031888 ]\n",
      " [0.9160368 ]\n",
      " [0.918861  ]\n",
      " [0.90534264]\n",
      " [0.89790154]\n",
      " [0.89507455]\n",
      " [0.89873296]\n",
      " [0.9099804 ]\n",
      " [0.91148955]\n",
      " [0.9036454 ]\n",
      " [0.884059  ]\n",
      " [0.90839535]\n",
      " [0.89536417]\n",
      " [0.8924237 ]\n",
      " [0.9045759 ]\n",
      " [0.8931932 ]\n",
      " [0.9026731 ]\n",
      " [0.90225244]\n",
      " [0.90916735]\n",
      " [0.88796455]\n",
      " [0.90430003]\n",
      " [0.9100796 ]\n",
      " [0.91806746]\n",
      " [0.9092877 ]\n",
      " [0.90460056]\n",
      " [0.9087625 ]\n",
      " [0.9025719 ]\n",
      " [0.8961403 ]\n",
      " [0.89043254]\n",
      " [0.902446  ]\n",
      " [0.9041678 ]\n",
      " [0.90226066]\n",
      " [0.9054257 ]\n",
      " [0.88496685]\n",
      " [0.87622935]\n",
      " [0.91045535]\n",
      " [0.9147459 ]\n",
      " [0.9157328 ]\n",
      " [0.9051333 ]\n",
      " [0.91436666]\n",
      " [0.8913086 ]\n",
      " [0.8931812 ]\n",
      " [0.9067461 ]\n",
      " [0.9009703 ]\n",
      " [0.90280426]\n",
      " [0.8933649 ]\n",
      " [0.9062975 ]]\n",
      "[[0.85180014]\n",
      " [0.8398173 ]\n",
      " [0.84472317]\n",
      " [0.8435453 ]\n",
      " [0.8526709 ]\n",
      " [0.849504  ]\n",
      " [0.8650251 ]\n",
      " [0.8727842 ]\n",
      " [0.84684384]\n",
      " [0.85548294]\n",
      " [0.830955  ]\n",
      " [0.8530063 ]\n",
      " [0.84050333]\n",
      " [0.8401483 ]\n",
      " [0.87196565]\n",
      " [0.88783604]\n",
      " [0.90721196]\n",
      " [0.91489357]\n",
      " [0.88864625]\n",
      " [0.89217705]\n",
      " [0.8908368 ]\n",
      " [0.86516094]\n",
      " [0.88709116]\n",
      " [0.8993369 ]\n",
      " [0.89588904]\n",
      " [0.9202058 ]\n",
      " [0.90239143]\n",
      " [0.9012563 ]\n",
      " [0.8759473 ]\n",
      " [0.88429314]\n",
      " [0.88247436]\n",
      " [0.8666761 ]\n",
      " [0.9104633 ]\n",
      " [0.88427544]\n",
      " [0.8716477 ]\n",
      " [0.8991305 ]\n",
      " [0.86870354]\n",
      " [0.9127011 ]\n",
      " [0.88842094]\n",
      " [0.8854469 ]\n",
      " [0.87319845]\n",
      " [0.88163203]\n",
      " [0.90341866]\n",
      " [0.87874776]\n",
      " [0.8786852 ]\n",
      " [0.89798015]\n",
      " [0.9027657 ]\n",
      " [0.8699819 ]\n",
      " [0.89462566]\n",
      " [0.88828754]\n",
      " [0.8835533 ]\n",
      " [0.88789016]\n",
      " [0.9003307 ]\n",
      " [0.87788004]\n",
      " [0.9248241 ]\n",
      " [0.88868207]\n",
      " [0.88941574]\n",
      " [0.86761767]\n",
      " [0.8821056 ]\n",
      " [0.8884184 ]\n",
      " [0.9244459 ]\n",
      " [0.87626076]\n",
      " [0.88723874]\n",
      " [0.8696564 ]\n",
      " [0.88217396]\n",
      " [0.9142445 ]\n",
      " [0.89057034]\n",
      " [0.87720054]\n",
      " [0.8879988 ]\n",
      " [0.8883206 ]\n",
      " [0.89779955]\n",
      " [0.8766952 ]\n",
      " [0.8567093 ]\n",
      " [0.880792  ]\n",
      " [0.8726035 ]\n",
      " [0.882178  ]\n",
      " [0.89885205]\n",
      " [0.8676981 ]\n",
      " [0.89565825]\n",
      " [0.89384526]\n",
      " [0.86851305]\n",
      " [0.8940934 ]\n",
      " [0.8866855 ]\n",
      " [0.89018077]\n",
      " [0.83593595]\n",
      " [0.8945262 ]\n",
      " [0.90391773]\n",
      " [0.89578056]\n",
      " [0.89852434]\n",
      " [0.8726044 ]\n",
      " [0.8849861 ]\n",
      " [0.8909781 ]\n",
      " [0.86209404]\n",
      " [0.8876075 ]\n",
      " [0.8861841 ]\n",
      " [0.8825519 ]\n",
      " [0.9009205 ]\n",
      " [0.8771138 ]\n",
      " [0.88131756]\n",
      " [0.86526656]\n",
      " [0.895351  ]\n",
      " [0.89344645]\n",
      " [0.8776962 ]\n",
      " [0.8742567 ]\n",
      " [0.8737761 ]\n",
      " [0.87765765]\n",
      " [0.9009105 ]\n",
      " [0.88411474]\n",
      " [0.8795716 ]\n",
      " [0.89424086]\n",
      " [0.8694956 ]\n",
      " [0.9268465 ]\n",
      " [0.89023113]\n",
      " [0.89813673]\n",
      " [0.897793  ]\n",
      " [0.8815644 ]\n",
      " [0.8668851 ]\n",
      " [0.88043606]\n",
      " [0.8852288 ]\n",
      " [0.8752836 ]\n",
      " [0.87455946]\n",
      " [0.88126117]\n",
      " [0.9098304 ]]\n",
      "[[0.02234995]\n",
      " [0.00895693]\n",
      " [0.00684049]\n",
      " [0.01035149]\n",
      " [0.1087974 ]\n",
      " [0.00655526]\n",
      " [0.03993533]\n",
      " [0.01613463]\n",
      " [0.02960385]\n",
      " [0.00830902]\n",
      " [0.02427747]\n",
      " [0.02148748]\n",
      " [0.0427308 ]\n",
      " [0.01655685]\n",
      " [0.05397278]\n",
      " [0.9870177 ]\n",
      " [0.98670805]\n",
      " [0.9965952 ]\n",
      " [0.99131656]\n",
      " [0.93018466]\n",
      " [0.98867744]\n",
      " [0.9762921 ]\n",
      " [0.98715055]\n",
      " [0.9858898 ]\n",
      " [0.9763315 ]\n",
      " [0.9414918 ]\n",
      " [0.99237895]\n",
      " [0.9737158 ]\n",
      " [0.7051297 ]\n",
      " [0.9660423 ]\n",
      " [0.99118245]\n",
      " [0.9824715 ]\n",
      " [0.98604244]\n",
      " [0.98670965]\n",
      " [0.9892663 ]\n",
      " [0.98424673]\n",
      " [0.39989612]\n",
      " [0.9699541 ]\n",
      " [0.9908382 ]\n",
      " [0.9882923 ]\n",
      " [0.9324673 ]\n",
      " [0.9780628 ]\n",
      " [0.99241614]\n",
      " [0.9689344 ]\n",
      " [0.9695654 ]\n",
      " [0.9906246 ]\n",
      " [0.99000764]\n",
      " [0.99801445]\n",
      " [0.9884292 ]\n",
      " [0.723661  ]\n",
      " [0.9780653 ]\n",
      " [0.96679693]\n",
      " [0.98744255]\n",
      " [0.9857653 ]\n",
      " [0.9872937 ]\n",
      " [0.9861624 ]\n",
      " [0.9937323 ]\n",
      " [0.9099234 ]\n",
      " [0.99092895]\n",
      " [0.9644859 ]\n",
      " [0.96657646]\n",
      " [0.9931085 ]\n",
      " [0.9754893 ]\n",
      " [0.9930941 ]\n",
      " [0.99271834]\n",
      " [0.9865687 ]\n",
      " [0.9360094 ]\n",
      " [0.99102235]\n",
      " [0.9875271 ]\n",
      " [0.97741115]\n",
      " [0.9631394 ]\n",
      " [0.97679853]\n",
      " [0.0189533 ]\n",
      " [0.9874385 ]\n",
      " [0.96875787]]\n",
      "[[0.949109  ]\n",
      " [0.9717409 ]\n",
      " [0.9908484 ]\n",
      " [0.9699599 ]\n",
      " [0.98914963]\n",
      " [0.9359229 ]\n",
      " [0.97955006]\n",
      " [0.87438047]\n",
      " [0.9884015 ]\n",
      " [0.964919  ]\n",
      " [0.9894673 ]\n",
      " [0.9919092 ]\n",
      " [0.9934169 ]\n",
      " [0.9738811 ]\n",
      " [0.98701394]\n",
      " [0.9910488 ]\n",
      " [0.99113125]\n",
      " [0.9792499 ]\n",
      " [0.98294383]\n",
      " [0.98556846]\n",
      " [0.9801956 ]\n",
      " [0.04680454]\n",
      " [0.0154083 ]\n",
      " [0.04420849]\n",
      " [0.01745981]\n",
      " [0.02749993]\n",
      " [0.01290124]\n",
      " [0.05770691]\n",
      " [0.01844585]\n",
      " [0.06366996]\n",
      " [0.00750398]\n",
      " [0.10164779]\n",
      " [0.56978524]\n",
      " [0.9749673 ]\n",
      " [0.98269445]\n",
      " [0.99187344]\n",
      " [0.98405695]\n",
      " [0.985187  ]\n",
      " [0.9408842 ]\n",
      " [0.9806832 ]\n",
      " [0.00854998]\n",
      " [0.00696661]\n",
      " [0.00977677]\n",
      " [0.02328143]\n",
      " [0.9415628 ]]\n",
      "[[0.01588026]\n",
      " [0.03000984]\n",
      " [0.01076937]\n",
      " [0.0384866 ]\n",
      " [0.01144483]\n",
      " [0.06153046]\n",
      " [0.01815664]\n",
      " [0.02201872]\n",
      " [0.00687674]\n",
      " [0.0532617 ]\n",
      " [0.01646454]\n",
      " [0.03425981]\n",
      " [0.00654549]\n",
      " [0.15613677]\n",
      " [0.01352405]\n",
      " [0.00731652]\n",
      " [0.0059483 ]\n",
      " [0.0191475 ]\n",
      " [0.98387027]\n",
      " [0.9923889 ]\n",
      " [0.986304  ]\n",
      " [0.9949685 ]\n",
      " [0.8948616 ]\n",
      " [0.9899039 ]\n",
      " [0.9951627 ]\n",
      " [0.9903048 ]\n",
      " [0.99059147]\n",
      " [0.9898915 ]\n",
      " [0.98212606]\n",
      " [0.9838397 ]\n",
      " [0.98267984]\n",
      " [0.95994925]\n",
      " [0.98592293]\n",
      " [0.97059566]\n",
      " [0.99603623]\n",
      " [0.98607486]\n",
      " [0.98730475]\n",
      " [0.9917298 ]\n",
      " [0.89105934]\n",
      " [0.98934174]\n",
      " [0.99032533]\n",
      " [0.99433374]\n",
      " [0.98899454]\n",
      " [0.9529523 ]\n",
      " [0.98668706]\n",
      " [0.9928402 ]\n",
      " [0.98061496]\n",
      " [0.98817223]\n",
      " [0.96361977]\n",
      " [0.98653203]\n",
      " [0.9480127 ]\n",
      " [0.7562913 ]\n",
      " [0.9936473 ]\n",
      " [0.9713936 ]\n",
      " [0.9899657 ]\n",
      " [0.98900896]\n",
      " [0.9715424 ]\n",
      " [0.9685288 ]\n",
      " [0.98894674]\n",
      " [0.99378306]\n",
      " [0.99383426]\n",
      " [0.9885931 ]\n",
      " [0.8991527 ]\n",
      " [0.99435174]\n",
      " [0.9199818 ]\n",
      " [0.8976807 ]\n",
      " [0.98661774]\n",
      " [0.9744659 ]\n",
      " [0.6577251 ]\n",
      " [0.8966964 ]]\n",
      "[[0.8961534 ]\n",
      " [0.8885937 ]\n",
      " [0.9031987 ]\n",
      " [0.8769842 ]\n",
      " [0.90186995]\n",
      " [0.87448186]\n",
      " [0.88630694]\n",
      " [0.87988544]\n",
      " [0.8701762 ]\n",
      " [0.9243945 ]\n",
      " [0.88771963]\n",
      " [0.87971854]\n",
      " [0.9011082 ]\n",
      " [0.856092  ]\n",
      " [0.8572266 ]\n",
      " [0.84698796]\n",
      " [0.8494598 ]\n",
      " [0.8506015 ]\n",
      " [0.8885902 ]\n",
      " [0.8841574 ]\n",
      " [0.8824877 ]\n",
      " [0.88710177]\n",
      " [0.88248765]\n",
      " [0.86420554]\n",
      " [0.8937343 ]\n",
      " [0.8814512 ]\n",
      " [0.88818234]\n",
      " [0.88487816]\n",
      " [0.9015429 ]\n",
      " [0.88683486]\n",
      " [0.84986913]\n",
      " [0.8588723 ]\n",
      " [0.86428255]\n",
      " [0.8309068 ]\n",
      " [0.86873704]\n",
      " [0.8685457 ]\n",
      " [0.88392514]\n",
      " [0.8541108 ]\n",
      " [0.88662064]\n",
      " [0.92289925]\n",
      " [0.9199546 ]\n",
      " [0.8782533 ]\n",
      " [0.8858555 ]\n",
      " [0.8795384 ]\n",
      " [0.87455297]\n",
      " [0.88891184]\n",
      " [0.8742131 ]\n",
      " [0.87589854]\n",
      " [0.89227915]\n",
      " [0.8860914 ]\n",
      " [0.8702724 ]\n",
      " [0.86842763]\n",
      " [0.8757663 ]\n",
      " [0.86559665]\n",
      " [0.8565634 ]\n",
      " [0.87356734]\n",
      " [0.87183136]\n",
      " [0.90835965]\n",
      " [0.87906706]\n",
      " [0.88041306]\n",
      " [0.8708487 ]\n",
      " [0.85623175]\n",
      " [0.8574057 ]\n",
      " [0.84781337]\n",
      " [0.87911814]\n",
      " [0.88896143]\n",
      " [0.8775297 ]\n",
      " [0.8991404 ]\n",
      " [0.87756234]\n",
      " [0.8678101 ]\n",
      " [0.9026957 ]\n",
      " [0.8861047 ]\n",
      " [0.90544504]\n",
      " [0.8780382 ]\n",
      " [0.8899568 ]\n",
      " [0.87811804]\n",
      " [0.8658312 ]\n",
      " [0.82271165]\n",
      " [0.85634905]\n",
      " [0.88189083]\n",
      " [0.8797921 ]\n",
      " [0.8705824 ]\n",
      " [0.8598203 ]\n",
      " [0.8739231 ]\n",
      " [0.8620951 ]\n",
      " [0.8617013 ]\n",
      " [0.89426327]\n",
      " [0.8835076 ]\n",
      " [0.85761887]\n",
      " [0.86920977]\n",
      " [0.8681815 ]\n",
      " [0.8579993 ]\n",
      " [0.90092844]\n",
      " [0.8953237 ]\n",
      " [0.86684406]\n",
      " [0.88368577]\n",
      " [0.86854136]\n",
      " [0.88825536]\n",
      " [0.8873417 ]\n",
      " [0.86548036]\n",
      " [0.8248259 ]\n",
      " [0.87898743]\n",
      " [0.88010406]]\n",
      "[[0.9111799 ]\n",
      " [0.8916691 ]\n",
      " [0.90657514]\n",
      " [0.91350794]\n",
      " [0.9013882 ]\n",
      " [0.90766597]\n",
      " [0.9042263 ]\n",
      " [0.8934922 ]\n",
      " [0.8742295 ]\n",
      " [0.889603  ]\n",
      " [0.8864515 ]\n",
      " [0.8861459 ]\n",
      " [0.88464206]\n",
      " [0.8708739 ]\n",
      " [0.8905467 ]\n",
      " [0.8640928 ]\n",
      " [0.86631036]\n",
      " [0.89151746]\n",
      " [0.8878373 ]\n",
      " [0.8959815 ]\n",
      " [0.888454  ]\n",
      " [0.86436474]\n",
      " [0.87156445]\n",
      " [0.8797785 ]\n",
      " [0.880863  ]\n",
      " [0.8672763 ]\n",
      " [0.89101875]\n",
      " [0.9027207 ]\n",
      " [0.90589964]\n",
      " [0.91004074]]\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_86 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 2s 71ms/step - loss: 1.4156 - accuracy: 0.7736 - val_loss: 0.5473 - val_accuracy: 0.7619\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.9218 - accuracy: 0.7882 - val_loss: 0.6017 - val_accuracy: 0.7619\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7730 - accuracy: 0.6877 - val_loss: 0.7480 - val_accuracy: 0.2857\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7317 - accuracy: 0.2128 - val_loss: 0.7883 - val_accuracy: 0.2381\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.7385 - accuracy: 0.2224 - val_loss: 0.7278 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7568 - accuracy: 0.3121 - val_loss: 0.6763 - val_accuracy: 0.5714\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7460 - accuracy: 0.6543 - val_loss: 0.6335 - val_accuracy: 0.7619\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6498 - accuracy: 0.8075 - val_loss: 0.6185 - val_accuracy: 0.7619\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6898 - accuracy: 0.7913 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7863 - accuracy: 0.3534 - val_loss: 0.7575 - val_accuracy: 0.2381\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7091 - accuracy: 0.2190 - val_loss: 0.6876 - val_accuracy: 0.5714\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6425 - accuracy: 0.5620 - val_loss: 0.6226 - val_accuracy: 0.7619\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.7702 - accuracy: 0.7074 - val_loss: 0.6366 - val_accuracy: 0.7619\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.5811 - accuracy: 0.8518 - val_loss: 0.6242 - val_accuracy: 0.7619\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.6620 - accuracy: 0.7044 - val_loss: 0.7327 - val_accuracy: 0.2381\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.7348 - accuracy: 0.2360 - val_loss: 0.7733 - val_accuracy: 0.2381\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.7014 - accuracy: 0.2103 - val_loss: 0.6821 - val_accuracy: 0.6190\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6396 - accuracy: 0.6485 - val_loss: 0.6026 - val_accuracy: 0.7619\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6674 - accuracy: 0.7816 - val_loss: 0.6066 - val_accuracy: 0.7619\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.6835 - accuracy: 0.7751 - val_loss: 0.6204 - val_accuracy: 0.8095\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 2s 95ms/step - loss: 0.5959 - binary_accuracy: 0.8599 - val_loss: 0.5796 - val_binary_accuracy: 0.7619\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5982 - binary_accuracy: 0.7696 - val_loss: 0.7202 - val_binary_accuracy: 0.2381\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6837 - binary_accuracy: 0.2230 - val_loss: 0.7086 - val_binary_accuracy: 0.2381\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6454 - binary_accuracy: 0.2149 - val_loss: 0.6454 - val_binary_accuracy: 0.8095\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6148 - binary_accuracy: 0.6827 - val_loss: 0.5906 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6425 - binary_accuracy: 0.8380 - val_loss: 0.6018 - val_binary_accuracy: 0.9048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6303 - binary_accuracy: 0.7992 - val_loss: 0.5889 - val_binary_accuracy: 0.9048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6270 - binary_accuracy: 0.8650 - val_loss: 0.5666 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6493 - binary_accuracy: 0.8796 - val_loss: 0.5656 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5711 - binary_accuracy: 0.8711 - val_loss: 0.5411 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5947 - binary_accuracy: 0.9036 - val_loss: 0.5667 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6257 - binary_accuracy: 0.8402 - val_loss: 0.5585 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5638 - binary_accuracy: 0.8526 - val_loss: 0.5260 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5857 - binary_accuracy: 0.9057 - val_loss: 0.5452 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6454 - binary_accuracy: 0.8741 - val_loss: 0.5439 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6093 - binary_accuracy: 0.9070 - val_loss: 0.5266 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6001 - binary_accuracy: 0.8459 - val_loss: 0.5730 - val_binary_accuracy: 0.8571\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6175 - binary_accuracy: 0.7291 - val_loss: 0.5422 - val_binary_accuracy: 0.9048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5678 - binary_accuracy: 0.9551 - val_loss: 0.4816 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5660 - binary_accuracy: 0.9194 - val_loss: 0.4911 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6001 - binary_accuracy: 0.8867 - val_loss: 0.5216 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5563 - binary_accuracy: 0.8241 - val_loss: 0.5527 - val_binary_accuracy: 0.8571\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5831 - binary_accuracy: 0.7286 - val_loss: 0.4720 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5394 - binary_accuracy: 0.9235 - val_loss: 0.4648 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5246 - binary_accuracy: 0.8727 - val_loss: 0.5431 - val_binary_accuracy: 0.8571\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5764 - binary_accuracy: 0.7478 - val_loss: 0.4735 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5753 - binary_accuracy: 0.9023 - val_loss: 0.4182 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5931 - binary_accuracy: 0.9252 - val_loss: 0.4317 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5823 - binary_accuracy: 0.8919 - val_loss: 0.4359 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5167 - binary_accuracy: 0.8433 - val_loss: 0.4610 - val_binary_accuracy: 0.9048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4828 - binary_accuracy: 0.8981 - val_loss: 0.4076 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4830 - binary_accuracy: 0.9325 - val_loss: 0.4110 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5132 - binary_accuracy: 0.8193 - val_loss: 0.4579 - val_binary_accuracy: 0.8571\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5083 - binary_accuracy: 0.8606 - val_loss: 0.3762 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5533 - binary_accuracy: 0.8442 - val_loss: 0.4304 - val_binary_accuracy: 0.9048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4706 - binary_accuracy: 0.8635 - val_loss: 0.3421 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4655 - binary_accuracy: 0.9101 - val_loss: 0.3797 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4085 - binary_accuracy: 0.8914 - val_loss: 0.3392 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4384 - binary_accuracy: 0.9053 - val_loss: 0.3293 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4323 - binary_accuracy: 0.9005 - val_loss: 0.2884 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4430 - binary_accuracy: 0.9318 - val_loss: 0.2926 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3777 - binary_accuracy: 0.8664 - val_loss: 0.3000 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4158 - binary_accuracy: 0.8735 - val_loss: 0.2509 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3558 - binary_accuracy: 0.9311 - val_loss: 0.2613 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3570 - binary_accuracy: 0.8861 - val_loss: 0.2558 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3089 - binary_accuracy: 0.9581 - val_loss: 0.2485 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3297 - binary_accuracy: 0.8015 - val_loss: 0.2468 - val_binary_accuracy: 0.9524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3067 - binary_accuracy: 0.9061 - val_loss: 0.2031 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3124 - binary_accuracy: 0.9487 - val_loss: 0.1811 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3053 - binary_accuracy: 0.9450 - val_loss: 0.2032 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 26378\n",
      "[[0.86071223]\n",
      " [0.5493231 ]\n",
      " [0.8338916 ]\n",
      " [0.8814927 ]\n",
      " [0.72965527]\n",
      " [0.74469554]\n",
      " [0.8492273 ]\n",
      " [0.6120351 ]\n",
      " [0.93777484]\n",
      " [0.90379953]\n",
      " [0.9337562 ]\n",
      " [0.88428754]\n",
      " [0.8804895 ]\n",
      " [0.90902644]\n",
      " [0.9573004 ]\n",
      " [0.8649106 ]\n",
      " [0.39492506]\n",
      " [0.89344215]\n",
      " [0.91699994]\n",
      " [0.9342986 ]\n",
      " [0.90679437]\n",
      " [0.6414202 ]\n",
      " [0.7984202 ]\n",
      " [0.5353384 ]\n",
      " [0.7816317 ]\n",
      " [0.7721359 ]\n",
      " [0.35827196]\n",
      " [0.77377933]\n",
      " [0.8324744 ]\n",
      " [0.8563222 ]\n",
      " [0.87670225]\n",
      " [0.6837392 ]\n",
      " [0.9076425 ]\n",
      " [0.6534345 ]\n",
      " [0.8972014 ]\n",
      " [0.7810341 ]\n",
      " [0.7464002 ]\n",
      " [0.66616434]\n",
      " [0.7390383 ]\n",
      " [0.9429508 ]\n",
      " [0.20043488]\n",
      " [0.295866  ]\n",
      " [0.33062774]\n",
      " [0.9035318 ]\n",
      " [0.94019806]\n",
      " [0.93538576]\n",
      " [0.90747535]\n",
      " [0.23539414]\n",
      " [0.22242667]\n",
      " [0.19154069]\n",
      " [0.11628452]\n",
      " [0.3030349 ]\n",
      " [0.6593125 ]\n",
      " [0.8307821 ]\n",
      " [0.93561053]\n",
      " [0.82293075]\n",
      " [0.87230676]\n",
      " [0.8360346 ]\n",
      " [0.93054414]\n",
      " [0.8919755 ]\n",
      " [0.88069415]\n",
      " [0.82043   ]\n",
      " [0.9452595 ]\n",
      " [0.9218003 ]\n",
      " [0.8482218 ]\n",
      " [0.7291715 ]\n",
      " [0.78304297]\n",
      " [0.875997  ]\n",
      " [0.8776346 ]\n",
      " [0.71640885]\n",
      " [0.8878764 ]\n",
      " [0.80230653]\n",
      " [0.8457649 ]\n",
      " [0.60642844]\n",
      " [0.9085104 ]\n",
      " [0.8263093 ]\n",
      " [0.7665578 ]\n",
      " [0.92694414]\n",
      " [0.4399602 ]\n",
      " [0.20848808]\n",
      " [0.5759902 ]\n",
      " [0.2062922 ]\n",
      " [0.22054283]\n",
      " [0.1449695 ]\n",
      " [0.33323133]\n",
      " [0.75634384]\n",
      " [0.2932936 ]\n",
      " [0.39515203]\n",
      " [0.15657085]\n",
      " [0.18613224]\n",
      " [0.95335287]\n",
      " [0.49493623]\n",
      " [0.7747621 ]\n",
      " [0.86041164]\n",
      " [0.90142095]\n",
      " [0.93194425]\n",
      " [0.22747825]\n",
      " [0.40242887]\n",
      " [0.2134921 ]\n",
      " [0.3142629 ]\n",
      " [0.20099503]\n",
      " [0.19848262]\n",
      " [0.21042202]\n",
      " [0.27642182]\n",
      " [0.27334523]\n",
      " [0.8741232 ]\n",
      " [0.91083735]\n",
      " [0.8963218 ]\n",
      " [0.7898589 ]\n",
      " [0.21613063]\n",
      " [0.3297714 ]\n",
      " [0.2371228 ]\n",
      " [0.92426777]\n",
      " [0.20121826]\n",
      " [0.60087985]\n",
      " [0.92959523]\n",
      " [0.8356792 ]\n",
      " [0.62006366]\n",
      " [0.8709785 ]\n",
      " [0.77271837]\n",
      " [0.9121476 ]\n",
      " [0.85485697]\n",
      " [0.82014734]\n",
      " [0.80266935]\n",
      " [0.7493091 ]\n",
      " [0.9238308 ]\n",
      " [0.7924391 ]\n",
      " [0.66282535]\n",
      " [0.885642  ]\n",
      " [0.94968325]]\n",
      "[[0.9439004 ]\n",
      " [0.96868604]\n",
      " [0.918048  ]\n",
      " [0.8007667 ]\n",
      " [0.80121005]\n",
      " [0.73309743]\n",
      " [0.93618447]\n",
      " [0.83677703]\n",
      " [0.8306226 ]\n",
      " [0.90261835]\n",
      " [0.89484096]\n",
      " [0.8713286 ]\n",
      " [0.93695986]\n",
      " [0.9257663 ]\n",
      " [0.89616334]\n",
      " [0.964401  ]\n",
      " [0.9530027 ]\n",
      " [0.89963114]\n",
      " [0.77409977]\n",
      " [0.8198748 ]\n",
      " [0.8200028 ]\n",
      " [0.9209711 ]\n",
      " [0.88732946]\n",
      " [0.8710426 ]\n",
      " [0.9213774 ]\n",
      " [0.89508367]\n",
      " [0.83591294]\n",
      " [0.92347836]\n",
      " [0.9412356 ]\n",
      " [0.9119682 ]\n",
      " [0.8878562 ]\n",
      " [0.86561334]\n",
      " [0.86748403]\n",
      " [0.6256871 ]\n",
      " [0.68754154]\n",
      " [0.55191565]\n",
      " [0.6806103 ]\n",
      " [0.85636413]\n",
      " [0.7948052 ]\n",
      " [0.9482397 ]\n",
      " [0.96374667]\n",
      " [0.93774897]\n",
      " [0.8957911 ]\n",
      " [0.8578177 ]\n",
      " [0.779437  ]\n",
      " [0.9217838 ]\n",
      " [0.9429669 ]\n",
      " [0.9105014 ]\n",
      " [0.96533436]\n",
      " [0.9364768 ]\n",
      " [0.8326779 ]\n",
      " [0.8762115 ]\n",
      " [0.9277946 ]\n",
      " [0.76183254]\n",
      " [0.77427137]\n",
      " [0.6651004 ]\n",
      " [0.6714151 ]\n",
      " [0.70809   ]\n",
      " [0.8353502 ]\n",
      " [0.9470611 ]\n",
      " [0.9169535 ]\n",
      " [0.91946113]\n",
      " [0.8855001 ]\n",
      " [0.82429016]\n",
      " [0.66322976]\n",
      " [0.92633593]\n",
      " [0.79577816]\n",
      " [0.912107  ]\n",
      " [0.7619804 ]\n",
      " [0.8761359 ]\n",
      " [0.9295048 ]\n",
      " [0.9514705 ]\n",
      " [0.9516804 ]\n",
      " [0.8986644 ]\n",
      " [0.8799344 ]\n",
      " [0.8115664 ]\n",
      " [0.9385304 ]\n",
      " [0.87772506]\n",
      " [0.91326714]\n",
      " [0.8816223 ]\n",
      " [0.91404015]\n",
      " [0.9298134 ]\n",
      " [0.21059155]\n",
      " [0.29771078]\n",
      " [0.2684946 ]\n",
      " [0.17990643]\n",
      " [0.24697806]\n",
      " [0.32522   ]\n",
      " [0.30826095]\n",
      " [0.29430673]\n",
      " [0.45418358]\n",
      " [0.29225084]\n",
      " [0.19214901]\n",
      " [0.4787246 ]\n",
      " [0.42817432]\n",
      " [0.41013226]\n",
      " [0.22264661]\n",
      " [0.3566272 ]\n",
      " [0.19400151]\n",
      " [0.34546703]\n",
      " [0.41973534]\n",
      " [0.25004557]\n",
      " [0.22899027]\n",
      " [0.15652002]\n",
      " [0.29108018]\n",
      " [0.20606184]\n",
      " [0.39195698]]\n",
      "[[0.50203615]\n",
      " [0.49650714]\n",
      " [0.26701492]\n",
      " [0.46270394]\n",
      " [0.33494556]\n",
      " [0.33416873]\n",
      " [0.21495344]\n",
      " [0.51921207]\n",
      " [0.4047613 ]\n",
      " [0.30659083]\n",
      " [0.60245854]\n",
      " [0.57847214]\n",
      " [0.5356029 ]\n",
      " [0.6481578 ]\n",
      " [0.36188254]\n",
      " [0.51638156]\n",
      " [0.42135108]\n",
      " [0.46752402]\n",
      " [0.42173937]\n",
      " [0.39026016]\n",
      " [0.41903442]\n",
      " [0.39740932]\n",
      " [0.9061531 ]\n",
      " [0.88281494]\n",
      " [0.9432149 ]\n",
      " [0.9142102 ]\n",
      " [0.9053481 ]\n",
      " [0.8975022 ]\n",
      " [0.6924214 ]\n",
      " [0.91509706]\n",
      " [0.9170824 ]\n",
      " [0.7924301 ]\n",
      " [0.9290709 ]\n",
      " [0.7916191 ]\n",
      " [0.9059152 ]\n",
      " [0.8427635 ]\n",
      " [0.889855  ]\n",
      " [0.85123336]\n",
      " [0.9174077 ]\n",
      " [0.85198355]\n",
      " [0.90853506]\n",
      " [0.8524043 ]\n",
      " [0.8957176 ]\n",
      " [0.71001315]\n",
      " [0.90979695]\n",
      " [0.8490443 ]\n",
      " [0.9152647 ]\n",
      " [0.92337096]\n",
      " [0.88066536]\n",
      " [0.8320105 ]\n",
      " [0.91414326]\n",
      " [0.8806595 ]\n",
      " [0.7974808 ]\n",
      " [0.8432613 ]\n",
      " [0.9274339 ]\n",
      " [0.8931163 ]\n",
      " [0.93217266]\n",
      " [0.8648074 ]\n",
      " [0.84104466]\n",
      " [0.8816689 ]\n",
      " [0.92105705]\n",
      " [0.9256982 ]\n",
      " [0.7695528 ]\n",
      " [0.7387655 ]\n",
      " [0.9175304 ]\n",
      " [0.8783822 ]\n",
      " [0.68569314]\n",
      " [0.646736  ]\n",
      " [0.86301   ]\n",
      " [0.72092146]\n",
      " [0.93679714]\n",
      " [0.8845466 ]\n",
      " [0.93384165]\n",
      " [0.8248522 ]\n",
      " [0.9019195 ]\n",
      " [0.8202441 ]\n",
      " [0.86830986]\n",
      " [0.8633922 ]\n",
      " [0.885378  ]\n",
      " [0.8545156 ]\n",
      " [0.92188936]\n",
      " [0.88599044]\n",
      " [0.91734767]\n",
      " [0.87922853]\n",
      " [0.90746784]\n",
      " [0.9191478 ]\n",
      " [0.8741895 ]\n",
      " [0.7715771 ]\n",
      " [0.86664194]\n",
      " [0.8254805 ]\n",
      " [0.7595545 ]\n",
      " [0.81329876]\n",
      " [0.8421885 ]\n",
      " [0.874828  ]\n",
      " [0.8986078 ]\n",
      " [0.9505608 ]\n",
      " [0.9378167 ]\n",
      " [0.9224151 ]\n",
      " [0.902868  ]\n",
      " [0.9056217 ]\n",
      " [0.8820831 ]\n",
      " [0.92084813]\n",
      " [0.90374804]\n",
      " [0.8793634 ]\n",
      " [0.91836405]\n",
      " [0.9199266 ]\n",
      " [0.8170518 ]\n",
      " [0.8225473 ]\n",
      " [0.9198157 ]\n",
      " [0.8958553 ]\n",
      " [0.7768902 ]\n",
      " [0.685003  ]\n",
      " [0.83755946]\n",
      " [0.8547343 ]\n",
      " [0.94476235]\n",
      " [0.94467115]\n",
      " [0.9026205 ]\n",
      " [0.8935501 ]\n",
      " [0.91973615]\n",
      " [0.91281277]\n",
      " [0.84904665]\n",
      " [0.8267191 ]\n",
      " [0.86307234]\n",
      " [0.9302015 ]]\n",
      "[[0.20518139]\n",
      " [0.20270321]\n",
      " [0.27816924]\n",
      " [0.18782647]\n",
      " [0.5227787 ]\n",
      " [0.16983467]\n",
      " [0.1509523 ]\n",
      " [0.34802517]\n",
      " [0.24878299]\n",
      " [0.33382016]\n",
      " [0.1108304 ]\n",
      " [0.19209148]\n",
      " [0.17223442]\n",
      " [0.199696  ]\n",
      " [0.41900897]\n",
      " [0.9158967 ]\n",
      " [0.93795633]\n",
      " [0.8365147 ]\n",
      " [0.9367352 ]\n",
      " [0.7493752 ]\n",
      " [0.89665794]\n",
      " [0.7251786 ]\n",
      " [0.9006445 ]\n",
      " [0.82158476]\n",
      " [0.94324577]\n",
      " [0.9632376 ]\n",
      " [0.86633587]\n",
      " [0.92766607]\n",
      " [0.84956414]\n",
      " [0.9537651 ]\n",
      " [0.9059866 ]\n",
      " [0.59502167]\n",
      " [0.83278215]\n",
      " [0.7672751 ]\n",
      " [0.73040855]\n",
      " [0.8793169 ]\n",
      " [0.5249619 ]\n",
      " [0.5969737 ]\n",
      " [0.9263124 ]\n",
      " [0.9433685 ]\n",
      " [0.9545618 ]\n",
      " [0.57101905]\n",
      " [0.9255823 ]\n",
      " [0.95464635]\n",
      " [0.86601096]\n",
      " [0.88321126]\n",
      " [0.78486115]\n",
      " [0.7359722 ]\n",
      " [0.9507341 ]\n",
      " [0.89870673]\n",
      " [0.89534146]\n",
      " [0.935594  ]\n",
      " [0.8207198 ]\n",
      " [0.93561   ]\n",
      " [0.7959074 ]\n",
      " [0.64333206]\n",
      " [0.72867066]\n",
      " [0.62959427]\n",
      " [0.9658788 ]\n",
      " [0.6145957 ]\n",
      " [0.5227504 ]\n",
      " [0.9130042 ]\n",
      " [0.90209115]\n",
      " [0.94534665]\n",
      " [0.9101453 ]\n",
      " [0.79112923]\n",
      " [0.86168617]\n",
      " [0.92844355]\n",
      " [0.92246234]\n",
      " [0.94409597]\n",
      " [0.7327932 ]\n",
      " [0.73061043]\n",
      " [0.38633826]\n",
      " [0.72967714]\n",
      " [0.79446346]\n",
      " [0.86940795]\n",
      " [0.64857805]\n",
      " [0.71044034]\n",
      " [0.8059782 ]\n",
      " [0.48774204]\n",
      " [0.8481416 ]\n",
      " [0.7094815 ]\n",
      " [0.7290856 ]\n",
      " [0.70256364]\n",
      " [0.17640996]\n",
      " [0.88441217]\n",
      " [0.93152446]\n",
      " [0.88957626]\n",
      " [0.9227697 ]\n",
      " [0.8469653 ]\n",
      " [0.8234606 ]\n",
      " [0.9490001 ]\n",
      " [0.7823725 ]\n",
      " [0.67680675]\n",
      " [0.8391251 ]\n",
      " [0.7851664 ]\n",
      " [0.5691207 ]\n",
      " [0.88437545]\n",
      " [0.9142157 ]\n",
      " [0.4281597 ]\n",
      " [0.6398068 ]\n",
      " [0.91168314]\n",
      " [0.7501978 ]\n",
      " [0.8687042 ]\n",
      " [0.5648411 ]\n",
      " [0.7566497 ]\n",
      " [0.8991224 ]\n",
      " [0.716035  ]\n",
      " [0.9264131 ]\n",
      " [0.9262354 ]\n",
      " [0.8316308 ]\n",
      " [0.8518996 ]\n",
      " [0.84754527]\n",
      " [0.8926599 ]\n",
      " [0.7972959 ]\n",
      " [0.8045055 ]\n",
      " [0.47905228]\n",
      " [0.4193129 ]\n",
      " [0.95367587]\n",
      " [0.7758925 ]\n",
      " [0.71655834]\n",
      " [0.90455383]\n",
      " [0.8831139 ]]\n",
      "[[0.7447244 ]\n",
      " [0.7370902 ]\n",
      " [0.7339495 ]\n",
      " [0.73967177]\n",
      " [0.82061493]\n",
      " [0.765398  ]\n",
      " [0.7595388 ]\n",
      " [0.7483494 ]\n",
      " [0.71313554]\n",
      " [0.77055615]\n",
      " [0.7251285 ]\n",
      " [0.74847555]\n",
      " [0.7977986 ]\n",
      " [0.77375776]\n",
      " [0.7346874 ]\n",
      " [0.98204345]\n",
      " [0.98990697]\n",
      " [0.9376174 ]\n",
      " [0.9215757 ]\n",
      " [0.6894746 ]\n",
      " [0.90966403]\n",
      " [0.9778872 ]\n",
      " [0.7135915 ]\n",
      " [0.92883366]\n",
      " [0.94283897]\n",
      " [0.84126854]\n",
      " [0.91744614]\n",
      " [0.84550804]\n",
      " [0.7918012 ]\n",
      " [0.9282622 ]\n",
      " [0.976972  ]\n",
      " [0.8280898 ]\n",
      " [0.945698  ]\n",
      " [0.9371985 ]\n",
      " [0.6878474 ]\n",
      " [0.99766845]\n",
      " [0.7616825 ]\n",
      " [0.84204924]\n",
      " [0.8959737 ]\n",
      " [0.97721183]\n",
      " [0.781484  ]\n",
      " [0.83234364]\n",
      " [0.88504136]\n",
      " [0.94758874]\n",
      " [0.9634116 ]\n",
      " [0.9659972 ]\n",
      " [0.9836398 ]\n",
      " [0.8501874 ]\n",
      " [0.9947389 ]\n",
      " [0.7215729 ]\n",
      " [0.9533848 ]\n",
      " [0.99764603]\n",
      " [0.5980918 ]\n",
      " [0.8177229 ]\n",
      " [0.9605887 ]\n",
      " [0.93725675]\n",
      " [0.7493324 ]\n",
      " [0.70173705]\n",
      " [0.97718346]\n",
      " [0.871652  ]\n",
      " [0.9877787 ]\n",
      " [0.8685843 ]\n",
      " [0.9969502 ]\n",
      " [0.89669186]\n",
      " [0.62588286]\n",
      " [0.99703026]\n",
      " [0.7761255 ]\n",
      " [0.84565204]\n",
      " [0.9202177 ]\n",
      " [0.7184352 ]\n",
      " [0.74157536]\n",
      " [0.7447762 ]\n",
      " [0.7821602 ]\n",
      " [0.7807752 ]\n",
      " [0.887381  ]]\n",
      "[[0.8951036 ]\n",
      " [0.90049875]\n",
      " [0.99451065]\n",
      " [0.9234566 ]\n",
      " [0.7345306 ]\n",
      " [0.8979335 ]\n",
      " [0.8508632 ]\n",
      " [0.9386969 ]\n",
      " [0.8784633 ]\n",
      " [0.92354083]\n",
      " [0.9365304 ]\n",
      " [0.9636367 ]\n",
      " [0.89146686]\n",
      " [0.9912811 ]\n",
      " [0.9546589 ]\n",
      " [0.9644315 ]\n",
      " [0.9595546 ]\n",
      " [0.99002457]\n",
      " [0.99312544]\n",
      " [0.86420715]\n",
      " [0.93760663]\n",
      " [0.736524  ]\n",
      " [0.7709759 ]\n",
      " [0.80012405]\n",
      " [0.74677163]\n",
      " [0.72636336]\n",
      " [0.7690321 ]\n",
      " [0.7100185 ]\n",
      " [0.74759924]\n",
      " [0.7592997 ]\n",
      " [0.768913  ]\n",
      " [0.83812016]\n",
      " [0.7770201 ]\n",
      " [0.9625088 ]\n",
      " [0.88450783]\n",
      " [0.8765886 ]\n",
      " [0.93260574]\n",
      " [0.84627974]\n",
      " [0.8526108 ]\n",
      " [0.97214186]\n",
      " [0.737489  ]\n",
      " [0.73628247]\n",
      " [0.7412351 ]\n",
      " [0.74701726]\n",
      " [0.82679725]]\n",
      "[[0.74898016]\n",
      " [0.7476218 ]\n",
      " [0.77610105]\n",
      " [0.7318224 ]\n",
      " [0.7636965 ]\n",
      " [0.78964263]\n",
      " [0.7446818 ]\n",
      " [0.71654624]\n",
      " [0.76384085]\n",
      " [0.70159733]\n",
      " [0.74403447]\n",
      " [0.7529245 ]\n",
      " [0.76480424]\n",
      " [0.8233681 ]\n",
      " [0.7383842 ]\n",
      " [0.72700554]\n",
      " [0.7305709 ]\n",
      " [0.74452794]\n",
      " [0.80449146]\n",
      " [0.99373287]\n",
      " [0.98213816]\n",
      " [0.7653882 ]\n",
      " [0.7836865 ]\n",
      " [0.95896447]\n",
      " [0.83742994]\n",
      " [0.81402034]\n",
      " [0.8407608 ]\n",
      " [0.92090225]\n",
      " [0.8041678 ]\n",
      " [0.8447247 ]\n",
      " [0.7574786 ]\n",
      " [0.97950417]\n",
      " [0.89705825]\n",
      " [0.89502823]\n",
      " [0.88200235]\n",
      " [0.7456796 ]\n",
      " [0.9328622 ]\n",
      " [0.9326538 ]\n",
      " [0.7639773 ]\n",
      " [0.73997414]\n",
      " [0.83912283]\n",
      " [0.9645113 ]\n",
      " [0.71695083]\n",
      " [0.75344837]\n",
      " [0.9514443 ]\n",
      " [0.9785342 ]\n",
      " [0.72514874]\n",
      " [0.7420619 ]\n",
      " [0.8885746 ]\n",
      " [0.9837217 ]\n",
      " [0.73007846]\n",
      " [0.7115976 ]\n",
      " [0.9689717 ]\n",
      " [0.87274194]\n",
      " [0.57701147]\n",
      " [0.9301041 ]\n",
      " [0.89060295]\n",
      " [0.63930434]\n",
      " [0.7984067 ]\n",
      " [0.75739086]\n",
      " [0.8781354 ]\n",
      " [0.89047456]\n",
      " [0.81961316]\n",
      " [0.933032  ]\n",
      " [0.7485486 ]\n",
      " [0.6787953 ]\n",
      " [0.931459  ]\n",
      " [0.99338657]\n",
      " [0.77581894]\n",
      " [0.8689674 ]]\n",
      "[[0.8322642 ]\n",
      " [0.6716426 ]\n",
      " [0.9161647 ]\n",
      " [0.65305316]\n",
      " [0.8971712 ]\n",
      " [0.7865572 ]\n",
      " [0.51076406]\n",
      " [0.8164277 ]\n",
      " [0.34664735]\n",
      " [0.93652165]\n",
      " [0.93214107]\n",
      " [0.5764159 ]\n",
      " [0.90776724]\n",
      " [0.11905756]\n",
      " [0.1560576 ]\n",
      " [0.08029798]\n",
      " [0.19391982]\n",
      " [0.20646337]\n",
      " [0.9234863 ]\n",
      " [0.57567006]\n",
      " [0.7620329 ]\n",
      " [0.7483334 ]\n",
      " [0.77402616]\n",
      " [0.8265854 ]\n",
      " [0.79427445]\n",
      " [0.6854085 ]\n",
      " [0.6529054 ]\n",
      " [0.7982199 ]\n",
      " [0.8573231 ]\n",
      " [0.8735849 ]\n",
      " [0.21249036]\n",
      " [0.10609006]\n",
      " [0.22047184]\n",
      " [0.09082679]\n",
      " [0.16000028]\n",
      " [0.28774467]\n",
      " [0.9183535 ]\n",
      " [0.8475322 ]\n",
      " [0.87844694]\n",
      " [0.9039159 ]\n",
      " [0.8073179 ]\n",
      " [0.44998348]\n",
      " [0.8567478 ]\n",
      " [0.8742196 ]\n",
      " [0.57676303]\n",
      " [0.76938164]\n",
      " [0.8532927 ]\n",
      " [0.8904518 ]\n",
      " [0.87400854]\n",
      " [0.87410563]\n",
      " [0.73431283]\n",
      " [0.85012364]\n",
      " [0.590203  ]\n",
      " [0.51958096]\n",
      " [0.23790035]\n",
      " [0.5481212 ]\n",
      " [0.838189  ]\n",
      " [0.73343754]\n",
      " [0.9095042 ]\n",
      " [0.8393938 ]\n",
      " [0.57051337]\n",
      " [0.33510917]\n",
      " [0.5252521 ]\n",
      " [0.19189307]\n",
      " [0.82469094]\n",
      " [0.8252561 ]\n",
      " [0.8019968 ]\n",
      " [0.8831842 ]\n",
      " [0.47186014]\n",
      " [0.7347936 ]\n",
      " [0.88498294]\n",
      " [0.7985903 ]\n",
      " [0.9520293 ]\n",
      " [0.41149247]\n",
      " [0.9390438 ]\n",
      " [0.86997664]\n",
      " [0.7598767 ]\n",
      " [0.0946032 ]\n",
      " [0.17036992]\n",
      " [0.94110656]\n",
      " [0.93852526]\n",
      " [0.2797315 ]\n",
      " [0.44176507]\n",
      " [0.7092577 ]\n",
      " [0.3308471 ]\n",
      " [0.08793224]\n",
      " [0.31763995]\n",
      " [0.8792688 ]\n",
      " [0.17030096]\n",
      " [0.09593889]\n",
      " [0.13418762]\n",
      " [0.30323026]\n",
      " [0.9125054 ]\n",
      " [0.90301746]\n",
      " [0.8751693 ]\n",
      " [0.9056166 ]\n",
      " [0.6013076 ]\n",
      " [0.88567615]\n",
      " [0.76856184]\n",
      " [0.5183665 ]\n",
      " [0.5225672 ]\n",
      " [0.872297  ]\n",
      " [0.63359916]]\n",
      "[[0.67277944]\n",
      " [0.62577856]\n",
      " [0.89459   ]\n",
      " [0.9443122 ]\n",
      " [0.9370104 ]\n",
      " [0.94013476]\n",
      " [0.92288494]\n",
      " [0.73244274]\n",
      " [0.8465566 ]\n",
      " [0.66863954]\n",
      " [0.22014903]\n",
      " [0.30676785]\n",
      " [0.2557629 ]\n",
      " [0.23931399]\n",
      " [0.32823023]\n",
      " [0.24308185]\n",
      " [0.25013977]\n",
      " [0.41604167]\n",
      " [0.27895534]\n",
      " [0.26833123]\n",
      " [0.21216069]\n",
      " [0.28386745]\n",
      " [0.26974332]\n",
      " [0.32027993]\n",
      " [0.3009021 ]\n",
      " [0.27099106]\n",
      " [0.19983713]\n",
      " [0.27570623]\n",
      " [0.26621744]\n",
      " [0.28238133]]\n",
      "Model: \"model_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "weightlayer (Weightlayer)    ((None, 2869, 8), (1, 286 22952     \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 2869, 8)           0         \n",
      "_________________________________________________________________\n",
      "groupcaps (CapsuleLayer)     ((None, 20, 16), (None, 2 7344640   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 20, 16)            5392      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               48150     \n",
      "=================================================================\n",
      "Total params: 7,421,134\n",
      "Trainable params: 7,421,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        [(None, 2869, 1)]         0         \n",
      "_________________________________________________________________\n",
      "model_88 (Functional)        (None, 150)               7421134   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,421,285\n",
      "Trainable params: 151\n",
      "Non-trainable params: 7,421,134\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 211ms/step - loss: 0.7540 - accuracy: 0.3417 - val_loss: 0.7818 - val_accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7189 - accuracy: 0.3167 - val_loss: 0.7320 - val_accuracy: 0.1667\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7049 - accuracy: 0.2042 - val_loss: 0.7133 - val_accuracy: 0.1667\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7086 - accuracy: 0.2000 - val_loss: 0.7102 - val_accuracy: 0.3333\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7173 - accuracy: 0.3292 - val_loss: 0.7081 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7128 - accuracy: 0.3500 - val_loss: 0.7042 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - accuracy: 0.5250 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6710 - accuracy: 0.6292 - val_loss: 0.7053 - val_accuracy: 0.3333\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7072 - accuracy: 0.3875 - val_loss: 0.7210 - val_accuracy: 0.3333\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6847 - accuracy: 0.3167 - val_loss: 0.7253 - val_accuracy: 0.3333\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7242 - accuracy: 0.4042 - val_loss: 0.7349 - val_accuracy: 0.3333\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7191 - accuracy: 0.4167 - val_loss: 0.7285 - val_accuracy: 0.3333\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6849 - accuracy: 0.3375 - val_loss: 0.7048 - val_accuracy: 0.3333\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6702 - accuracy: 0.7042 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6852 - accuracy: 0.7750 - val_loss: 0.6854 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6493 - accuracy: 0.7750 - val_loss: 0.6862 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7157 - accuracy: 0.5917 - val_loss: 0.7014 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6696 - accuracy: 0.5542 - val_loss: 0.7021 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6395 - accuracy: 0.5083 - val_loss: 0.7041 - val_accuracy: 0.3333\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6810 - accuracy: 0.5042 - val_loss: 0.7179 - val_accuracy: 0.3333\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 238ms/step - loss: 0.6706 - binary_accuracy: 0.5583 - val_loss: 0.6618 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6885 - binary_accuracy: 0.7250 - val_loss: 0.6524 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6710 - binary_accuracy: 0.7125 - val_loss: 0.6416 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6324 - binary_accuracy: 0.7167 - val_loss: 0.6407 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.7031 - binary_accuracy: 0.6750 - val_loss: 0.6529 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6193 - binary_accuracy: 0.9000 - val_loss: 0.6586 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6194 - binary_accuracy: 0.9417 - val_loss: 0.6698 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6284 - binary_accuracy: 0.9667 - val_loss: 0.6754 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6350 - binary_accuracy: 0.7375 - val_loss: 0.6790 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6458 - binary_accuracy: 0.7000 - val_loss: 0.6810 - val_binary_accuracy: 0.5000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6116 - binary_accuracy: 0.4708 - val_loss: 0.6732 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6390 - binary_accuracy: 0.6792 - val_loss: 0.6692 - val_binary_accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6221 - binary_accuracy: 0.9417 - val_loss: 0.6554 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5876 - binary_accuracy: 1.0000 - val_loss: 0.6398 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6214 - binary_accuracy: 0.9792 - val_loss: 0.6402 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6180 - binary_accuracy: 1.0000 - val_loss: 0.6412 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5861 - binary_accuracy: 1.0000 - val_loss: 0.6398 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6071 - binary_accuracy: 1.0000 - val_loss: 0.6411 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5844 - binary_accuracy: 1.0000 - val_loss: 0.6347 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5958 - binary_accuracy: 1.0000 - val_loss: 0.6298 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5814 - binary_accuracy: 1.0000 - val_loss: 0.6182 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5836 - binary_accuracy: 0.9417 - val_loss: 0.6089 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5988 - binary_accuracy: 0.9083 - val_loss: 0.6020 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6185 - binary_accuracy: 0.8833 - val_loss: 0.5970 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5633 - binary_accuracy: 0.8875 - val_loss: 0.5906 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5555 - binary_accuracy: 0.8750 - val_loss: 0.5904 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5724 - binary_accuracy: 0.9083 - val_loss: 0.5955 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5888 - binary_accuracy: 0.9667 - val_loss: 0.5967 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5327 - binary_accuracy: 0.9458 - val_loss: 0.5854 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5735 - binary_accuracy: 0.9083 - val_loss: 0.5841 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5425 - binary_accuracy: 0.9333 - val_loss: 0.5778 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5549 - binary_accuracy: 0.9083 - val_loss: 0.5742 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5340 - binary_accuracy: 0.9792 - val_loss: 0.5781 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5458 - binary_accuracy: 0.9417 - val_loss: 0.5791 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5407 - binary_accuracy: 0.9792 - val_loss: 0.5749 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5301 - binary_accuracy: 0.9417 - val_loss: 0.5684 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5250 - binary_accuracy: 0.8833 - val_loss: 0.5671 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5051 - binary_accuracy: 0.9667 - val_loss: 0.5658 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5073 - binary_accuracy: 0.9667 - val_loss: 0.5566 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5483 - binary_accuracy: 0.8833 - val_loss: 0.5523 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5086 - binary_accuracy: 0.9333 - val_loss: 0.5406 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4990 - binary_accuracy: 0.8875 - val_loss: 0.5342 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.4946 - binary_accuracy: 0.8750 - val_loss: 0.5361 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5166 - binary_accuracy: 0.9083 - val_loss: 0.5396 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.4839 - binary_accuracy: 0.9458 - val_loss: 0.5364 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4771 - binary_accuracy: 0.9333 - val_loss: 0.5385 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.4892 - binary_accuracy: 0.9417 - val_loss: 0.5444 - val_binary_accuracy: 0.8333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.4663 - binary_accuracy: 0.9417 - val_loss: 0.5486 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4564 - binary_accuracy: 1.0000 - val_loss: 0.5566 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.4553 - binary_accuracy: 1.0000 - val_loss: 0.5530 - val_binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,binary_accuracy,val_loss,val_binary_accuracy\n",
      "training cohort: GSE 28750\n",
      "[[0.5985587 ]\n",
      " [0.4113204 ]\n",
      " [0.5725026 ]\n",
      " [0.6071864 ]\n",
      " [0.4765805 ]\n",
      " [0.47991595]\n",
      " [0.6818689 ]\n",
      " [0.43392363]\n",
      " [0.65060437]\n",
      " [0.63422906]\n",
      " [0.6531902 ]\n",
      " [0.57594776]\n",
      " [0.5272661 ]\n",
      " [0.61977595]\n",
      " [0.6882042 ]\n",
      " [0.6153465 ]\n",
      " [0.48517287]\n",
      " [0.60067564]\n",
      " [0.61375993]\n",
      " [0.6549263 ]\n",
      " [0.64949614]\n",
      " [0.4235904 ]\n",
      " [0.5186958 ]\n",
      " [0.47990704]\n",
      " [0.6047264 ]\n",
      " [0.5793219 ]\n",
      " [0.40896505]\n",
      " [0.566383  ]\n",
      " [0.4319512 ]\n",
      " [0.57864267]\n",
      " [0.61396194]\n",
      " [0.47708172]\n",
      " [0.5897374 ]\n",
      " [0.45688978]\n",
      " [0.58342147]\n",
      " [0.54933196]\n",
      " [0.5236879 ]\n",
      " [0.4867546 ]\n",
      " [0.46146253]\n",
      " [0.62987053]\n",
      " [0.3314306 ]\n",
      " [0.3408254 ]\n",
      " [0.3699493 ]\n",
      " [0.5746511 ]\n",
      " [0.64768845]\n",
      " [0.6306232 ]\n",
      " [0.6076437 ]\n",
      " [0.43209726]\n",
      " [0.34070683]\n",
      " [0.37092277]\n",
      " [0.3456052 ]\n",
      " [0.414696  ]\n",
      " [0.5692056 ]\n",
      " [0.65943253]\n",
      " [0.5732187 ]\n",
      " [0.62371814]\n",
      " [0.56057394]\n",
      " [0.6329949 ]\n",
      " [0.635525  ]\n",
      " [0.5691728 ]\n",
      " [0.575036  ]\n",
      " [0.51610005]\n",
      " [0.6232522 ]\n",
      " [0.5998742 ]\n",
      " [0.53901356]\n",
      " [0.5013404 ]\n",
      " [0.56667393]\n",
      " [0.560663  ]\n",
      " [0.51491976]\n",
      " [0.49489963]\n",
      " [0.6194381 ]\n",
      " [0.504947  ]\n",
      " [0.580557  ]\n",
      " [0.49139893]\n",
      " [0.5760896 ]\n",
      " [0.5398885 ]\n",
      " [0.49651375]\n",
      " [0.6657222 ]\n",
      " [0.41573495]\n",
      " [0.33183393]\n",
      " [0.4165248 ]\n",
      " [0.2913032 ]\n",
      " [0.3805118 ]\n",
      " [0.2998484 ]\n",
      " [0.3786006 ]\n",
      " [0.45453534]\n",
      " [0.36560762]\n",
      " [0.4342819 ]\n",
      " [0.36809182]\n",
      " [0.33338523]\n",
      " [0.62566984]\n",
      " [0.39324462]\n",
      " [0.59359956]\n",
      " [0.5707578 ]\n",
      " [0.616582  ]\n",
      " [0.6228831 ]\n",
      " [0.3440298 ]\n",
      " [0.3587184 ]\n",
      " [0.36927146]\n",
      " [0.38856998]\n",
      " [0.35309806]\n",
      " [0.29118314]\n",
      " [0.34933326]\n",
      " [0.3424435 ]\n",
      " [0.36737716]\n",
      " [0.62388045]\n",
      " [0.6650192 ]\n",
      " [0.57684404]\n",
      " [0.56507415]\n",
      " [0.35271677]\n",
      " [0.39318955]\n",
      " [0.36004615]\n",
      " [0.61502486]\n",
      " [0.36363474]\n",
      " [0.6187386 ]\n",
      " [0.64275485]\n",
      " [0.63238573]\n",
      " [0.3962126 ]\n",
      " [0.6234807 ]\n",
      " [0.5756287 ]\n",
      " [0.5982614 ]\n",
      " [0.5433199 ]\n",
      " [0.50059223]\n",
      " [0.5401045 ]\n",
      " [0.6058015 ]\n",
      " [0.65007067]\n",
      " [0.49778977]\n",
      " [0.5216885 ]\n",
      " [0.5742612 ]\n",
      " [0.6395757 ]]\n",
      "[[0.7441203 ]\n",
      " [0.7719138 ]\n",
      " [0.68030316]\n",
      " [0.59476405]\n",
      " [0.5896836 ]\n",
      " [0.5546561 ]\n",
      " [0.6793978 ]\n",
      " [0.626773  ]\n",
      " [0.60034996]\n",
      " [0.660988  ]\n",
      " [0.62178683]\n",
      " [0.6255734 ]\n",
      " [0.7307503 ]\n",
      " [0.7157677 ]\n",
      " [0.70257485]\n",
      " [0.7004689 ]\n",
      " [0.6825571 ]\n",
      " [0.59926   ]\n",
      " [0.624168  ]\n",
      " [0.705878  ]\n",
      " [0.61171937]\n",
      " [0.6826971 ]\n",
      " [0.6408286 ]\n",
      " [0.6689227 ]\n",
      " [0.6592253 ]\n",
      " [0.64815253]\n",
      " [0.6106407 ]\n",
      " [0.7087457 ]\n",
      " [0.7131747 ]\n",
      " [0.67217106]\n",
      " [0.6158132 ]\n",
      " [0.6205458 ]\n",
      " [0.6258413 ]\n",
      " [0.47812253]\n",
      " [0.49398905]\n",
      " [0.47018373]\n",
      " [0.51035094]\n",
      " [0.62632364]\n",
      " [0.6190416 ]\n",
      " [0.69704   ]\n",
      " [0.73524934]\n",
      " [0.70655745]\n",
      " [0.6860995 ]\n",
      " [0.5883183 ]\n",
      " [0.550397  ]\n",
      " [0.6853998 ]\n",
      " [0.708661  ]\n",
      " [0.6647186 ]\n",
      " [0.69656104]\n",
      " [0.6839627 ]\n",
      " [0.5451144 ]\n",
      " [0.7215677 ]\n",
      " [0.77444726]\n",
      " [0.6346066 ]\n",
      " [0.6215247 ]\n",
      " [0.4883059 ]\n",
      " [0.5946766 ]\n",
      " [0.55914783]\n",
      " [0.5902004 ]\n",
      " [0.70467293]\n",
      " [0.6083149 ]\n",
      " [0.6283641 ]\n",
      " [0.6888126 ]\n",
      " [0.5997719 ]\n",
      " [0.5324781 ]\n",
      " [0.6740664 ]\n",
      " [0.531373  ]\n",
      " [0.6662705 ]\n",
      " [0.4943858 ]\n",
      " [0.5891706 ]\n",
      " [0.7074854 ]\n",
      " [0.70270944]\n",
      " [0.70265543]\n",
      " [0.69380176]\n",
      " [0.6642911 ]\n",
      " [0.61852926]\n",
      " [0.70554614]\n",
      " [0.64265233]\n",
      " [0.6924045 ]\n",
      " [0.74128526]\n",
      " [0.6607356 ]\n",
      " [0.69309354]\n",
      " [0.39835942]\n",
      " [0.42889512]\n",
      " [0.39792347]\n",
      " [0.32062685]\n",
      " [0.4194097 ]\n",
      " [0.4436962 ]\n",
      " [0.41123596]\n",
      " [0.4125364 ]\n",
      " [0.44293165]\n",
      " [0.3385801 ]\n",
      " [0.4121156 ]\n",
      " [0.50799024]\n",
      " [0.4839785 ]\n",
      " [0.39120805]\n",
      " [0.3566436 ]\n",
      " [0.42833593]\n",
      " [0.3548353 ]\n",
      " [0.41566268]\n",
      " [0.4759167 ]\n",
      " [0.448022  ]\n",
      " [0.37319824]\n",
      " [0.37429404]\n",
      " [0.34977025]\n",
      " [0.41402742]\n",
      " [0.45879412]]\n",
      "[[0.5205886 ]\n",
      " [0.57034624]\n",
      " [0.53682375]\n",
      " [0.5456975 ]\n",
      " [0.51969826]\n",
      " [0.46359423]\n",
      " [0.4920185 ]\n",
      " [0.5691686 ]\n",
      " [0.53643996]\n",
      " [0.48448277]\n",
      " [0.5914925 ]\n",
      " [0.55525225]\n",
      " [0.5118633 ]\n",
      " [0.56590223]\n",
      " [0.48822474]\n",
      " [0.5287273 ]\n",
      " [0.5126182 ]\n",
      " [0.539441  ]\n",
      " [0.5203873 ]\n",
      " [0.47526225]\n",
      " [0.5222099 ]\n",
      " [0.5002722 ]\n",
      " [0.71517557]\n",
      " [0.71632445]\n",
      " [0.7512355 ]\n",
      " [0.74659693]\n",
      " [0.7421503 ]\n",
      " [0.72691673]\n",
      " [0.6274236 ]\n",
      " [0.7059859 ]\n",
      " [0.7421154 ]\n",
      " [0.6298799 ]\n",
      " [0.74199855]\n",
      " [0.6507757 ]\n",
      " [0.72317487]\n",
      " [0.6856427 ]\n",
      " [0.7278583 ]\n",
      " [0.64545596]\n",
      " [0.73605144]\n",
      " [0.701879  ]\n",
      " [0.73781973]\n",
      " [0.70336735]\n",
      " [0.6879304 ]\n",
      " [0.5828888 ]\n",
      " [0.7183287 ]\n",
      " [0.6765372 ]\n",
      " [0.7076818 ]\n",
      " [0.695213  ]\n",
      " [0.7183125 ]\n",
      " [0.6992144 ]\n",
      " [0.72628146]\n",
      " [0.706231  ]\n",
      " [0.6612762 ]\n",
      " [0.68008417]\n",
      " [0.7292226 ]\n",
      " [0.7067051 ]\n",
      " [0.7540717 ]\n",
      " [0.7101433 ]\n",
      " [0.7136347 ]\n",
      " [0.724345  ]\n",
      " [0.74394304]\n",
      " [0.73853904]\n",
      " [0.6474021 ]\n",
      " [0.658268  ]\n",
      " [0.70860523]\n",
      " [0.69370866]\n",
      " [0.57871825]\n",
      " [0.5672401 ]\n",
      " [0.69530475]\n",
      " [0.6126915 ]\n",
      " [0.7497841 ]\n",
      " [0.7299899 ]\n",
      " [0.74483055]\n",
      " [0.6604369 ]\n",
      " [0.73065054]\n",
      " [0.6487224 ]\n",
      " [0.7063937 ]\n",
      " [0.6907487 ]\n",
      " [0.7192702 ]\n",
      " [0.69658905]\n",
      " [0.7465342 ]\n",
      " [0.69177604]\n",
      " [0.7378172 ]\n",
      " [0.7130245 ]\n",
      " [0.7238192 ]\n",
      " [0.7265047 ]\n",
      " [0.68824816]\n",
      " [0.60549784]\n",
      " [0.71921337]\n",
      " [0.64204544]\n",
      " [0.6536294 ]\n",
      " [0.6691632 ]\n",
      " [0.70632803]\n",
      " [0.708314  ]\n",
      " [0.7114444 ]\n",
      " [0.762687  ]\n",
      " [0.7107293 ]\n",
      " [0.71061325]\n",
      " [0.7165279 ]\n",
      " [0.7364388 ]\n",
      " [0.69939905]\n",
      " [0.7055546 ]\n",
      " [0.72610724]\n",
      " [0.672973  ]\n",
      " [0.7197929 ]\n",
      " [0.7141502 ]\n",
      " [0.69793236]\n",
      " [0.69691205]\n",
      " [0.7394493 ]\n",
      " [0.71792847]\n",
      " [0.6720997 ]\n",
      " [0.64372224]\n",
      " [0.7251486 ]\n",
      " [0.7161571 ]\n",
      " [0.76148725]\n",
      " [0.7452373 ]\n",
      " [0.6943196 ]\n",
      " [0.6850303 ]\n",
      " [0.72358716]\n",
      " [0.7291138 ]\n",
      " [0.6745849 ]\n",
      " [0.65627414]\n",
      " [0.7146916 ]\n",
      " [0.7550817 ]]\n",
      "[[0.3632814 ]\n",
      " [0.35671353]\n",
      " [0.39069605]\n",
      " [0.34393355]\n",
      " [0.41096464]\n",
      " [0.3308451 ]\n",
      " [0.36908156]\n",
      " [0.42720354]\n",
      " [0.36239848]\n",
      " [0.39015698]\n",
      " [0.29676622]\n",
      " [0.37275878]\n",
      " [0.2833954 ]\n",
      " [0.3283045 ]\n",
      " [0.41814017]\n",
      " [0.6283194 ]\n",
      " [0.6616899 ]\n",
      " [0.6055947 ]\n",
      " [0.6623369 ]\n",
      " [0.45844343]\n",
      " [0.6530033 ]\n",
      " [0.49650788]\n",
      " [0.5883627 ]\n",
      " [0.64663994]\n",
      " [0.6520666 ]\n",
      " [0.70686316]\n",
      " [0.5215116 ]\n",
      " [0.6761492 ]\n",
      " [0.56921464]\n",
      " [0.6208118 ]\n",
      " [0.59305936]\n",
      " [0.43743214]\n",
      " [0.6959746 ]\n",
      " [0.49830276]\n",
      " [0.48976701]\n",
      " [0.6206462 ]\n",
      " [0.4057418 ]\n",
      " [0.6481393 ]\n",
      " [0.62968594]\n",
      " [0.61504006]\n",
      " [0.64809954]\n",
      " [0.42580047]\n",
      " [0.6967153 ]\n",
      " [0.6638167 ]\n",
      " [0.51633716]\n",
      " [0.57756823]\n",
      " [0.59191865]\n",
      " [0.5187284 ]\n",
      " [0.6451894 ]\n",
      " [0.6018641 ]\n",
      " [0.5890997 ]\n",
      " [0.6604982 ]\n",
      " [0.6564352 ]\n",
      " [0.5873741 ]\n",
      " [0.6708334 ]\n",
      " [0.5819257 ]\n",
      " [0.5528078 ]\n",
      " [0.5033342 ]\n",
      " [0.6606927 ]\n",
      " [0.43646955]\n",
      " [0.62178993]\n",
      " [0.57129806]\n",
      " [0.5521624 ]\n",
      " [0.6276377 ]\n",
      " [0.6630886 ]\n",
      " [0.5431829 ]\n",
      " [0.5745755 ]\n",
      " [0.60996026]\n",
      " [0.6461778 ]\n",
      " [0.62406313]\n",
      " [0.55411905]\n",
      " [0.54394007]\n",
      " [0.34554172]\n",
      " [0.5112799 ]\n",
      " [0.48675054]\n",
      " [0.5088064 ]\n",
      " [0.5594215 ]\n",
      " [0.5085746 ]\n",
      " [0.6108811 ]\n",
      " [0.53106284]\n",
      " [0.50537294]\n",
      " [0.5954164 ]\n",
      " [0.54433787]\n",
      " [0.5514674 ]\n",
      " [0.288952  ]\n",
      " [0.6466512 ]\n",
      " [0.67274964]\n",
      " [0.62026924]\n",
      " [0.6915269 ]\n",
      " [0.55568236]\n",
      " [0.5795181 ]\n",
      " [0.6253388 ]\n",
      " [0.51908857]\n",
      " [0.56348455]\n",
      " [0.527756  ]\n",
      " [0.52767456]\n",
      " [0.5568818 ]\n",
      " [0.59757483]\n",
      " [0.6449255 ]\n",
      " [0.35807154]\n",
      " [0.5293217 ]\n",
      " [0.640183  ]\n",
      " [0.52469176]\n",
      " [0.6106876 ]\n",
      " [0.43914217]\n",
      " [0.50777155]\n",
      " [0.63348794]\n",
      " [0.46041018]\n",
      " [0.62597364]\n",
      " [0.68742305]\n",
      " [0.5615391 ]\n",
      " [0.629965  ]\n",
      " [0.567768  ]\n",
      " [0.6658969 ]\n",
      " [0.6509436 ]\n",
      " [0.51048136]\n",
      " [0.41945314]\n",
      " [0.47965112]\n",
      " [0.6622077 ]\n",
      " [0.4906724 ]\n",
      " [0.4956058 ]\n",
      " [0.55884653]\n",
      " [0.6529068 ]]\n",
      "[[0.62449676]\n",
      " [0.67591566]\n",
      " [0.7010244 ]\n",
      " [0.6405004 ]\n",
      " [0.7374395 ]\n",
      " [0.62470204]\n",
      " [0.5899938 ]\n",
      " [0.6236873 ]\n",
      " [0.6068696 ]\n",
      " [0.6401085 ]\n",
      " [0.5996321 ]\n",
      " [0.60154253]\n",
      " [0.64157087]\n",
      " [0.6805895 ]\n",
      " [0.6332214 ]\n",
      " [0.9272239 ]\n",
      " [0.9265697 ]\n",
      " [0.91410637]\n",
      " [0.94074255]\n",
      " [0.6116568 ]\n",
      " [0.909104  ]\n",
      " [0.86249894]\n",
      " [0.55276364]\n",
      " [0.96884894]\n",
      " [0.93500704]\n",
      " [0.7270758 ]\n",
      " [0.790602  ]\n",
      " [0.78225625]\n",
      " [0.6509493 ]\n",
      " [0.71743345]\n",
      " [0.9227806 ]\n",
      " [0.91966736]\n",
      " [0.7968531 ]\n",
      " [0.9224714 ]\n",
      " [0.9499363 ]\n",
      " [0.83230364]\n",
      " [0.603954  ]\n",
      " [0.8876302 ]\n",
      " [0.917768  ]\n",
      " [0.87363833]\n",
      " [0.7260731 ]\n",
      " [0.80613613]\n",
      " [0.52145267]\n",
      " [0.8232632 ]\n",
      " [0.79088265]\n",
      " [0.9077809 ]\n",
      " [0.88983405]\n",
      " [0.8113643 ]\n",
      " [0.9476389 ]\n",
      " [0.58945525]\n",
      " [0.86165756]\n",
      " [0.8945349 ]\n",
      " [0.74927175]\n",
      " [0.8845022 ]\n",
      " [0.955095  ]\n",
      " [0.5411841 ]\n",
      " [0.8240593 ]\n",
      " [0.6721701 ]\n",
      " [0.89901525]\n",
      " [0.59500027]\n",
      " [0.9191082 ]\n",
      " [0.8608386 ]\n",
      " [0.9062849 ]\n",
      " [0.89693546]\n",
      " [0.93238527]\n",
      " [0.8934122 ]\n",
      " [0.76091695]\n",
      " [0.9144465 ]\n",
      " [0.8935362 ]\n",
      " [0.72173274]\n",
      " [0.7748217 ]\n",
      " [0.7596211 ]\n",
      " [0.57532644]\n",
      " [0.9033502 ]\n",
      " [0.6298919 ]]\n",
      "[[0.94974804]\n",
      " [0.7962029 ]\n",
      " [0.9508897 ]\n",
      " [0.80248594]\n",
      " [0.93326336]\n",
      " [0.8186558 ]\n",
      " [0.917037  ]\n",
      " [0.8745277 ]\n",
      " [0.62571853]\n",
      " [0.86697006]\n",
      " [0.88683784]\n",
      " [0.9610722 ]\n",
      " [0.9499404 ]\n",
      " [0.9020942 ]\n",
      " [0.8764423 ]\n",
      " [0.91320026]\n",
      " [0.934558  ]\n",
      " [0.8192546 ]\n",
      " [0.9412717 ]\n",
      " [0.95505834]\n",
      " [0.8938359 ]\n",
      " [0.6375931 ]\n",
      " [0.68898255]\n",
      " [0.64693147]\n",
      " [0.6062651 ]\n",
      " [0.60602593]\n",
      " [0.63380384]\n",
      " [0.6062704 ]\n",
      " [0.61877114]\n",
      " [0.5845672 ]\n",
      " [0.615897  ]\n",
      " [0.7186105 ]\n",
      " [0.628105  ]\n",
      " [0.96052086]\n",
      " [0.83500934]\n",
      " [0.86605227]\n",
      " [0.93072575]\n",
      " [0.827848  ]\n",
      " [0.56849444]\n",
      " [0.9719355 ]\n",
      " [0.63140374]\n",
      " [0.7019348 ]\n",
      " [0.67680556]\n",
      " [0.6220419 ]\n",
      " [0.7393753 ]]\n",
      "[[0.6054417 ]\n",
      " [0.60223794]\n",
      " [0.6900873 ]\n",
      " [0.636157  ]\n",
      " [0.6794385 ]\n",
      " [0.6544113 ]\n",
      " [0.60699755]\n",
      " [0.58807534]\n",
      " [0.6305626 ]\n",
      " [0.60179913]\n",
      " [0.62392646]\n",
      " [0.58845466]\n",
      " [0.6192606 ]\n",
      " [0.710591  ]\n",
      " [0.64660275]\n",
      " [0.70226216]\n",
      " [0.6744411 ]\n",
      " [0.62321883]\n",
      " [0.8110657 ]\n",
      " [0.9556723 ]\n",
      " [0.8297056 ]\n",
      " [0.9600132 ]\n",
      " [0.77926177]\n",
      " [0.89961225]\n",
      " [0.79857224]\n",
      " [0.9230686 ]\n",
      " [0.9192706 ]\n",
      " [0.810831  ]\n",
      " [0.7705768 ]\n",
      " [0.7083172 ]\n",
      " [0.7820045 ]\n",
      " [0.96425027]\n",
      " [0.912528  ]\n",
      " [0.38413388]\n",
      " [0.8087086 ]\n",
      " [0.90351903]\n",
      " [0.39056373]\n",
      " [0.916238  ]\n",
      " [0.6142175 ]\n",
      " [0.61991423]\n",
      " [0.86232615]\n",
      " [0.8619788 ]\n",
      " [0.7752123 ]\n",
      " [0.6333301 ]\n",
      " [0.8255283 ]\n",
      " [0.8583537 ]\n",
      " [0.58619285]\n",
      " [0.8729952 ]\n",
      " [0.6535886 ]\n",
      " [0.89847976]\n",
      " [0.5025856 ]\n",
      " [0.5960655 ]\n",
      " [0.69088465]\n",
      " [0.79149383]\n",
      " [0.93026215]\n",
      " [0.8821774 ]\n",
      " [0.61865246]\n",
      " [0.7023293 ]\n",
      " [0.891551  ]\n",
      " [0.8450617 ]\n",
      " [0.9142302 ]\n",
      " [0.4495546 ]\n",
      " [0.5184665 ]\n",
      " [0.8324724 ]\n",
      " [0.5769147 ]\n",
      " [0.6002934 ]\n",
      " [0.49761283]\n",
      " [0.9230379 ]\n",
      " [0.6827193 ]\n",
      " [0.6671922 ]]\n",
      "[[0.5661485 ]\n",
      " [0.5234092 ]\n",
      " [0.63777983]\n",
      " [0.49266344]\n",
      " [0.6296554 ]\n",
      " [0.52731645]\n",
      " [0.4211367 ]\n",
      " [0.5367814 ]\n",
      " [0.39300212]\n",
      " [0.71860284]\n",
      " [0.6329871 ]\n",
      " [0.49862358]\n",
      " [0.665807  ]\n",
      " [0.35494566]\n",
      " [0.37233707]\n",
      " [0.30181172]\n",
      " [0.3517074 ]\n",
      " [0.3925606 ]\n",
      " [0.6309479 ]\n",
      " [0.4704125 ]\n",
      " [0.51357406]\n",
      " [0.53422827]\n",
      " [0.54470414]\n",
      " [0.52223575]\n",
      " [0.56424433]\n",
      " [0.5137588 ]\n",
      " [0.52210635]\n",
      " [0.540413  ]\n",
      " [0.58162993]\n",
      " [0.62110436]\n",
      " [0.3382939 ]\n",
      " [0.34765834]\n",
      " [0.37238994]\n",
      " [0.28981924]\n",
      " [0.37270445]\n",
      " [0.4117081 ]\n",
      " [0.64793634]\n",
      " [0.57382756]\n",
      " [0.60785615]\n",
      " [0.62670815]\n",
      " [0.54267955]\n",
      " [0.43036866]\n",
      " [0.5681008 ]\n",
      " [0.5980167 ]\n",
      " [0.4863338 ]\n",
      " [0.49344358]\n",
      " [0.5497952 ]\n",
      " [0.5724758 ]\n",
      " [0.61145496]\n",
      " [0.5702503 ]\n",
      " [0.5125372 ]\n",
      " [0.58745474]\n",
      " [0.50893337]\n",
      " [0.46889633]\n",
      " [0.38115406]\n",
      " [0.46522912]\n",
      " [0.54830307]\n",
      " [0.6011462 ]\n",
      " [0.56641614]\n",
      " [0.5962461 ]\n",
      " [0.48033315]\n",
      " [0.39028305]\n",
      " [0.4967934 ]\n",
      " [0.38734877]\n",
      " [0.5623329 ]\n",
      " [0.5570447 ]\n",
      " [0.5690227 ]\n",
      " [0.6097308 ]\n",
      " [0.5408366 ]\n",
      " [0.46285325]\n",
      " [0.5922312 ]\n",
      " [0.5437787 ]\n",
      " [0.69445646]\n",
      " [0.505146  ]\n",
      " [0.6552567 ]\n",
      " [0.5957542 ]\n",
      " [0.51778936]\n",
      " [0.37961784]\n",
      " [0.3468412 ]\n",
      " [0.65544325]\n",
      " [0.6517172 ]\n",
      " [0.38433465]\n",
      " [0.43310562]\n",
      " [0.46345374]\n",
      " [0.35462916]\n",
      " [0.35539526]\n",
      " [0.4723075 ]\n",
      " [0.6384812 ]\n",
      " [0.37085608]\n",
      " [0.34200555]\n",
      " [0.3713104 ]\n",
      " [0.39192685]\n",
      " [0.6738282 ]\n",
      " [0.62897056]\n",
      " [0.58380264]\n",
      " [0.61314964]\n",
      " [0.4978829 ]\n",
      " [0.5972892 ]\n",
      " [0.53214157]\n",
      " [0.4191526 ]\n",
      " [0.41058242]\n",
      " [0.5663985 ]\n",
      " [0.524723  ]]\n",
      "[[0.5646845 ]\n",
      " [0.5290193 ]\n",
      " [0.697247  ]\n",
      " [0.76686186]\n",
      " [0.71627104]\n",
      " [0.71324956]\n",
      " [0.7390565 ]\n",
      " [0.60798866]\n",
      " [0.64912546]\n",
      " [0.52795535]\n",
      " [0.38758302]\n",
      " [0.44587752]\n",
      " [0.40502387]\n",
      " [0.3777427 ]\n",
      " [0.42762917]\n",
      " [0.3927963 ]\n",
      " [0.36955667]\n",
      " [0.4627078 ]\n",
      " [0.44109374]\n",
      " [0.43104163]\n",
      " [0.42121214]\n",
      " [0.39271873]\n",
      " [0.37994602]\n",
      " [0.4087256 ]\n",
      " [0.396813  ]\n",
      " [0.41743848]\n",
      " [0.4220752 ]\n",
      " [0.45208505]\n",
      " [0.42240337]\n",
      " [0.41193026]]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "pred = []\n",
    "for dataset, label, training_cohort in zip(datasets,labels,files):\n",
    "    xtr,xval, ytr,yval = train_test_split(dataset,label,test_size=0.2,random_state=42)\n",
    "\n",
    "    cw = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(ytr),y=ytr)\n",
    "    cw = {0:cw[0],1:cw[1]}\n",
    "    \n",
    "    model = training(xtr,ytr,xval,yval,cw)\n",
    "    print(\"training cohort: GSE\", training_cohort)\n",
    "    \n",
    "    test_result = []\n",
    "    #testresult = []\n",
    "    for x_test,y_test, test_cohort in zip(datasets,labels,files):\n",
    "        testresult=model.predict(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test,testresult)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        #print(\"test cohort GSE\", test_cohort, \"AUC:\", roc_auc)\n",
    "        test_result.append(roc_auc)\n",
    "        print(testresult)\n",
    "        pred.append(testresult)   \n",
    "    results.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfcde821-3395-4c47-abc1-96703285657d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcb24549-c9b1-457d-ac5b-155c76a7abfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[:9], files):\n",
    "    filename = f\"GSEGSE26440-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa86646b-9988-4f16-938c-0614b5c497f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[9:18], files):\n",
    "    filename = f\"GSE57065-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7ec4eb2-d943-4bd0-943f-94b725970d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[18:27], files):\n",
    "    filename = f\"GSE95233-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6af5d1fd-cb9e-42fc-9e62-a4f7c1092986",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[27:36], files):\n",
    "    filename = f\"GSE4607-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39aa5529-c6b1-44fd-88a0-eb4f2d020e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[36:45], files):\n",
    "    filename = f\"GSE8121-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18e158eb-c3da-4975-bc8b-b0f3e67d9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[45:54], files):\n",
    "    filename = f\"GSE9692-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f6696bf-91a1-4111-8a97-d02b4e1c8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[54:63], files):\n",
    "    filename = f\"GSE13904-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22079133-95f4-40b5-9395-2147cd1138ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[63:72], files):\n",
    "    filename = f\"GSE26378-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3f0f52c-763e-48ad-b767-dd1cd3f4bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "###把bulk数据预测label导出来\n",
    "for label, file in zip(pred[72:81], files):\n",
    "    filename = f\"GSE28750-{file}_predlabel.csv\"\n",
    "    #df = pd.DataFrame({\"label\": label})\n",
    "    np.savetxt(f\"../data/dataBulk/bulk_predlabel/{filename}\", label, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff17e480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSE26440</th>\n",
       "      <th>GSE57065</th>\n",
       "      <th>GSE95233</th>\n",
       "      <th>GSE4607</th>\n",
       "      <th>GSE8121</th>\n",
       "      <th>GSE9692</th>\n",
       "      <th>GSE13904</th>\n",
       "      <th>GSE26378</th>\n",
       "      <th>GSE28750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSE26440</th>\n",
       "      <td>0.999043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988272</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>0.883547</td>\n",
       "      <td>0.990708</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE57065</th>\n",
       "      <td>0.998406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.991975</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE95233</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE4607</th>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.996585</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.990128</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE8121</th>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.976585</td>\n",
       "      <td>0.988414</td>\n",
       "      <td>0.929630</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.943376</td>\n",
       "      <td>0.932636</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE9692</th>\n",
       "      <td>0.984056</td>\n",
       "      <td>0.964390</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994658</td>\n",
       "      <td>0.937282</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE13904</th>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.945633</td>\n",
       "      <td>0.971605</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944251</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE26378</th>\n",
       "      <td>0.998724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.812222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE28750</th>\n",
       "      <td>0.991390</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.995989</td>\n",
       "      <td>0.975926</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.992451</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GSE26440  GSE57065  GSE95233   GSE4607   GSE8121   GSE9692  \\\n",
       "GSE26440  0.999043  1.000000  1.000000  0.988272  0.973333  0.995556   \n",
       "GSE57065  0.998406  1.000000  0.999554  0.991975  0.893333  0.957778   \n",
       "GSE95233  0.994898  1.000000  1.000000  0.977160  0.954444  0.971111   \n",
       "GSE4607   0.999362  0.996585  0.996881  0.987654  0.877778  0.884444   \n",
       "GSE8121   0.926339  0.976585  0.988414  0.929630  0.985556  0.953333   \n",
       "GSE9692   0.984056  0.964390  0.962121  0.972222  0.985556  1.000000   \n",
       "GSE13904  0.969069  0.980000  0.945633  0.971605  0.985556  1.000000   \n",
       "GSE26378  0.998724  1.000000  1.000000  0.987654  0.812222  0.777778   \n",
       "GSE28750  0.991390  0.995122  0.995989  0.975926  0.991111  0.957778   \n",
       "\n",
       "          GSE13904  GSE26378  GSE28750  \n",
       "GSE26440  0.883547  0.990708      1.00  \n",
       "GSE57065  0.841880  1.000000      1.00  \n",
       "GSE95233  0.948718  0.996516      1.00  \n",
       "GSE4607   0.740385  0.990128      1.00  \n",
       "GSE8121   0.943376  0.932636      0.97  \n",
       "GSE9692   0.994658  0.937282      0.96  \n",
       "GSE13904  1.000000  0.944251      0.95  \n",
       "GSE26378  0.559829  0.999419      1.00  \n",
       "GSE28750  0.846154  0.992451      1.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_name = ['GSE' + name for name in files]\n",
    "df_results = pd.DataFrame(results, index = cohort_name, columns = cohort_name)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664f7e2",
   "metadata": {},
   "source": [
    "#  Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d01d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSE26440</th>\n",
       "      <th>GSE57065</th>\n",
       "      <th>GSE95233</th>\n",
       "      <th>GSE4607</th>\n",
       "      <th>GSE8121</th>\n",
       "      <th>GSE9692</th>\n",
       "      <th>GSE13904</th>\n",
       "      <th>GSE26378</th>\n",
       "      <th>GSE28750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSE26440</th>\n",
       "      <td>0.998406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.981111</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.992451</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE57065</th>\n",
       "      <td>0.999362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989506</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.998258</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE95233</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987037</td>\n",
       "      <td>0.917778</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.920940</td>\n",
       "      <td>0.997677</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE4607</th>\n",
       "      <td>0.997130</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.984321</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE8121</th>\n",
       "      <td>0.825574</td>\n",
       "      <td>0.947805</td>\n",
       "      <td>0.977718</td>\n",
       "      <td>0.831173</td>\n",
       "      <td>0.992222</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.973291</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE9692</th>\n",
       "      <td>0.989477</td>\n",
       "      <td>0.989268</td>\n",
       "      <td>0.995098</td>\n",
       "      <td>0.976543</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977564</td>\n",
       "      <td>0.958769</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE13904</th>\n",
       "      <td>0.975128</td>\n",
       "      <td>0.968780</td>\n",
       "      <td>0.974153</td>\n",
       "      <td>0.969753</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE26378</th>\n",
       "      <td>0.998406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988272</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.840812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSE28750</th>\n",
       "      <td>0.997768</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.821581</td>\n",
       "      <td>0.990708</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GSE26440  GSE57065  GSE95233   GSE4607   GSE8121   GSE9692  \\\n",
       "GSE26440  0.998406  1.000000  0.998217  0.986420  0.981111  0.997778   \n",
       "GSE57065  0.999362  1.000000  1.000000  0.989506  0.908889  0.902222   \n",
       "GSE95233  0.994898  0.999512  1.000000  0.987037  0.917778  0.966667   \n",
       "GSE4607   0.997130  0.998049  0.996881  0.987654  0.991111  0.971111   \n",
       "GSE8121   0.825574  0.947805  0.977718  0.831173  0.992222  0.982222   \n",
       "GSE9692   0.989477  0.989268  0.995098  0.976543  0.985556  1.000000   \n",
       "GSE13904  0.975128  0.968780  0.974153  0.969753  0.985556  1.000000   \n",
       "GSE26378  0.998406  1.000000  1.000000  0.988272  0.932222  0.966667   \n",
       "GSE28750  0.997768  0.999512  0.998663  0.983333  0.860000  0.906667   \n",
       "\n",
       "          GSE13904  GSE26378  GSE28750  \n",
       "GSE26440  0.961538  0.992451     1.000  \n",
       "GSE57065  0.858974  0.998258     1.000  \n",
       "GSE95233  0.920940  0.997677     1.000  \n",
       "GSE4607   0.935897  0.984321     1.000  \n",
       "GSE8121   0.973291  0.878049     0.840  \n",
       "GSE9692   0.977564  0.958769     1.000  \n",
       "GSE13904  1.000000  0.926829     0.965  \n",
       "GSE26378  0.840812  1.000000     1.000  \n",
       "GSE28750  0.821581  0.990708     1.000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df__ = pd.read_csv('../figures/data/rotatingTest.csv',index_col=0)\n",
    "df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896f4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACMkAAABICAYAAADm6TA9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFOElEQVR4nO3dPWqUURzF4TMSsEgnSZ1NuAeX4wrciDsS3EBKG6t0VmY+roVdsHAgL2/+h+cpQwj3x30no+HAHNZaAQAAAAAAAACAZu/2PgAAAAAAAAAAAGzNSAYAAAAAAAAAgHpGMgAAAAAAAAAA1DOSAQAAAAAAAACgnpEMAAAAAAAAAAD1jGQAAAAAAAAAAKh3c803392+Xw8fbrc6y/7W3gfYWHPfao6rz0v3w5n6vOa+1f7ia89zf7MV31//s9ndV55XH1j9+mtuS/ndJfXv6+3319xXnPZXeWDzs5nUX191oGdztvI8fYM1tyX6ptM3V3Nb0t/3M3laa92//PpVI5mHD7f59vnT653qjVmny95H2NTl1PuYr+N57yNsahXfXZJczt2vvfb7a/7d2dyWJJdjed+p+73hUv7edzme9j7CZprbkuRc3ld/f7+Pex9hU83357U3W/v7+qn832Wn597n81T+bJ7Ln81z+f21/25pvr9j8e/NJDmX/z3pVP633O7/EXX3NbclyfPeB9hY+/3pm6u5Lenv+5L8+NfXfdwSAAAAAAAAAAD1jGQAAAAAAAAAAKhnJAMAAAAAAAAAQD0jGQAAAAAAAAAA6hnJAAAAAAAAAABQz0gGAAAAAAAAAIB6RjIAAAAAAAAAANQzkgEAAAAAAAAAoJ6RDAAAAAAAAAAA9YxkAAAAAAAAAACoZyQDAAAAAAAAAEA9IxkAAAAAAAAAAOoZyQAAAAAAAAAAUM9IBgAAAAAAAACAekYyAAAAAAAAAADUM5IBAAAAAAAAAKCekQwAAAAAAAAAAPWMZAAAAAAAAAAAqGckAwAAAAAAAABAPSMZAAAAAAAAAADqGckAAAAAAAAAAFDPSAYAAAAAAAAAgHpGMgAAAAAAAAAA1DOSAQAAAAAAAACgnpEMAAAAAAAAAAD1jGQAAAAAAAAAAKhnJAMAAAAAAAAAQD0jGQAAAAAAAAAA6hnJAAAAAAAAAABQz0gGAAAAAAAAAIB6RjIAAAAAAAAAANQzkgEAAAAAAAAAoJ6RDAAAAAAAAAAA9YxkAAAAAAAAAACoZyQDAAAAAAAAAEA9IxkAAAAAAAAAAOoZyQAAAAAAAAAAUM9IBgAAAAAAAACAekYyAAAAAAAAAADUM5IBAAAAAAAAAKCekQwAAAAAAAAAAPWMZAAAAAAAAAAAqGckAwAAAAAAAABAPSMZAAAAAAAAAADqGckAAAAAAAAAAFDPSAYAAAAAAAAAgHpGMgAAAAAAAAAA1DOSAQAAAAAAAACgnpEMAAAAAAAAAAD1jGQAAAAAAAAAAKhnJAMAAAAAAAAAQD0jGQAAAAAAAAAA6h3WWv//zYfDrySP2x1nd3dJnvY+xEaa2xJ90+mbq7kt0Tedvrma2xJ90+mbq7kt0Tedvrma2xJ90+mbq7kt0Tedvrma2xJ90+mbq7kt0Tfdw1rr/uUXb678IY9rrY+vdKA353A4fG/ta25L9E2nb67mtkTfdPrmam5L9E2nb67mtkTfdPrmam5L9E2nb67mtkTfdPrmam5L9E2nb67mtkRfKx+3BAAAAAAAAABAPSMZAAAAAAAAAADqXTuS+brJKd6O5r7mtkTfdPrmam5L9E2nb67mtkTfdPrmam5L9E2nb67mtkTfdPrmam5L9E2nb67mtkTfdPrmam5L9FU6rLX2PgMAAAAAAAAAAGzKxy0BAAAAAAAAAFDPSAYAAAAAAAAAgHpGMgAAAAAAAAAA1DOSAQAAAAAAAACgnpEMAAAAAAAAAAD1/gCF9Z1yEVlKKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2880x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.palplot(sns.color_palette(\"OrRd_r\", 20)) \n",
    "new_c=sns.color_palette(\"OrRd\", 80)[40:80]\n",
    "sns.palplot(new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b78008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAFHCAYAAACRTSroAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAACpwUlEQVR4nOydd3yV1f3435+b5IbsRRZhZDBkBhWQIVvQ4qjKEK3FAfq11VaxVnFgtXVVa7E/26pIrbsiIAgKygYHyN5hJCRgSMi+hOx1fn+cJ+Em997kJgGC+Lxfr/u6957nOedzznnG58zPR5RSmJiYmJiYnC8sbZ0BExMTE5OfF6biMTExMTE5r5iKx8TExMTkvGIqHhMTExOT84qpeExMTExMzium4jExMTExOa/8JBSPiCg3PqMugHw+LSInRKRGRN5t6/z8nDHuiQfOsYxHm7rvRORdN+7dd1uZj0Ei8kxr0jgbiEiEiDwjIrENwkcZ5ezTRllzWUdGfnPbIEutRkRijXq97hzKsBp11P9sput5NhM7hwyx++0DrAWeA760Cz9wXnPUABEZADwLPAGsB7LbMj8m54VHgX+ir7cr/gK8aff/BSAY+K1dWE4r8zEI+BPwTCvTaS0RRj7WA2ltmhNHLpQ6+qlhRddbGrDrbCX6k1A8SqnNtb9FxN/4mWIfbo+IeAAeSqmK85E/g0uM738ppQpbk5CI+CilSs9CnkzOAc25PkqpFCDFLm4+YHF175pcPLTRe+isISI+5yxxpdRP6gP4Awq40y7sXWAbcCOwH6gEhgPRwDvAUaAUOIzuKVnt4sYa6U0B3gJOAeno3ovF7ryOwKfonkwp+mXyFzv5qsFnlHEs1Eg3CygDvgeuaFAmBTwMvIZu/SY3Un5f4P8BJ430tgLjG5yzHlgI3AYkA4XACqCjG/XbH1gDlAAFwEdAZHPryzi3D7pXetr4LACi3MhDP2AZYAOKgC3AOLvjccASo1ynjXO7OqnTB9E9jBzjuv0L8G5heX8FvG/kaTW6Bej0mjdRtoXA+ubUE+AF/A04DpQDGcBidGv0Tif5WN9EHh4AjhhpJQMzGxx/BsgFLgU2G3WzExjeSJqxTvKhjGOjauvHKFsR+pn8rZN0rgQ2GDLzgLeBADfqdQqw1yjTj8DzgKdxzGUdNaeswAz0+6UcOAY82uD4uzh5DzWS5xHAOqM+TqGf20vP0bM4BvgB/c7IAv4N+Nsdr71GVwNLjTz9x9k1BWLdfV+7LHtrEzjfH1wrnly0YrkdGIdWFH3RD+yNwEjgHuAE8JaTi5cGvGrEfan2gtqdtxbYZKQ1CrgbeNk4loAeUlHAaGAwEAh4AzvQD9k04Brgc/TLxf7FooBMYL5xzoRGyv+REf93wC+Az4wb/Eq7c9ajH77vgV8CU42bbXkTdRuOfrHWlvN240beg6Gsm1FfXY0HYY2R1kT0cOhWQBrJwyVG+bYZ+R4HPA7cbRz3NurzEHCLke4+47qGNqjT48a9cTXwR6AKu5dFM8ubiVZc49AP8aVG3HnG9R4MBLpx/9ZTPO7UE/C0If8O9MtqilEuH6MMfzPyWJuPXo3Iv8c491VgPPAiUAPMsjvnGfTLbg9wF/o+24x+xnxdpOuNbugo9DDiYGBwg5faEeApow7fMcIG2aUxDP1Snw9MAH5tXNeFTdTpeCOt99DPz6NGOm/aXWendeRuWY37pxKt0MYBswwZDzT1HnKR51FGeiuNa34N+h1y3Tl4FnsBFejGzbXAfUbaXzXIjzJk/AV9jw9Fv8+UEVZbd96NXQ+33uPnSkGcqw+uFY8C+jcR1xP9cJQ5uXjvNzh3F/CJ3f8i4PpG0r7TSMe+FTHduODdGuQhBXjFLkwBO90oe0/0S+IOuzAL+sX7tV3YevTLLMQu7CFDjk8j6b9k3JCBdmGDjHi3NrO+PkArB/veZTegGri2kTz8z7j5nebTeGiqgHi7sI5GPT/eoE43Noi7BNjcwvIudpKXXOCZZt6/DRVPk/UEfAG82kiaD2D0LpqQbUG/yP/bIPzfxv3Szvj/jFHmMXbn9DfCrmkk/T446flx5qX2Z7swL3RP9CW7sG+AdQ3ijjHi9mlE7mYn8R416rBjY3XkTlnRjcgi4E8N4v4ZPfLgYfx/FzfeQ8a5m9CNK6eNsGbem009i5+glb6HXdgUI+6QBtdoToO0HN63Z+Pzk1jV5iYnlFK77ANE85CIHBCRUnQL4yN066xzg/grG/w/gH6h1bILeFFE7hSRhnFdcRWwHUgVEU8RqZ1T2wAMaHDulzTNQEDQwxUAKKVqjP9XNjh3q1KqwO5/7eKLmEbSHwSsVHZzVEqpLegWVcP0m6qvq9DDQTV2ZU810mpYdnvGAPOV6zmUQcAOpdRRuzymA9+1II/NKa8716cluFNPu4A7jVV0/UREWiirI9ABu/vHYD765drXLqyS+osmau8f+/prLnXXQylViX4ZdgQQEV/0IqJPa+vBqItvjbxc7ixBYx7lMpyXyUL9hUmuaKqsQwA/YEGDvK0FIqlfJw7vISd59gOuAN5TxtvdCWfzWRyEbjhV24UtQjfgztd9Xo+LSfFkOQl7CN0FXYwechoE3G8ca9fgXFuD/xUNzrkF3UKZAxwTkV0iMraJPLVHd00rG3zuAjq5kf+GRANFSqkSJ3F9RcTbLszW4JzaCc6G5W6YvrN8ZKHnquxxlr592u2Bx3AsezyOZbcnDD2sdD7y2Jy03Lk+LcGdenoOPcz3W2A38KOIPNgCWdHGd8Oy1P63L3Oh0agBQJ2ZIG/s/mkKW4P/9tcjBPBA977s66Ec3Ttydc+0N467UyZXNFXW9sZ37bxN7WedEW6fN3fukxB0A7LN7nNDCeU5Setc3ef1+EmsanMTZy2HycACpdSTtQEi0qtFiSt1At3qtKAV2DPAUhHprJTKcxEtH62sfuPkWHlDEW5kIxPwFxHfBsonEihRSjVMs7lkopfENiQS3XNrDvlohT/PybHG9k3kceYF6YxMoLeT8EhDZnNoTnnduT4tocl6UkqVoed5nhaRbujhxtdE5JBS6qtmyKp90TUsc6RdXtoKG7qOnwGWOzme4SJeLloJnMsy1aZxHc5fzIfsfrtznxSgh8ybus/P1rPokJbRUwzDsX7O1X1ej4upx+MMHxxf8L9qTYJKqRqll8I+i15h1qWR09egJ4+PK6W2NfjsbYH4regbY1JtgDHsMgk9JNFafgCuFpEAu/QHoseSm5v+GvSY/3YnZU9rIt4UEXHVsv4BuFxE4uzyGIOeCG1uHltb3oYty5bQrHpSSh0BHkHf17WNqAoj703lJR39Ap/cIHwKeoVgS+5Je1rcK1JKFaPnano4qYdtSimnisdouW/HeZlq0HMpdXlzo46csQm9krWDi7ydbk5iRll/AKY1Mmx6Np/FH4CbDGVTy83ojkdTaZ2Nnq4DF1OPxxmrgN+LyA/oCf1foRVBsxCRIOBr9HLaw+g5oj+gJxaTGon6Prp1ul5E/oZejRWG7jGdVErNaU4+lFJJIvI/4J8iEoheCnsPeiWYs15Vc/m7kc7XIvJX9MTiS+gX0qJmpvUMehn0lyLyDrplGoNeefOuUmq9i3jPohXsRhF5Fd0DuhTIU0q9g57AfQxYISJPoyeQnzHSf6uZeWxteQ8C14rIV+jJ50PNfQnhRj2JyGL0y3Un+gU4Cf3sbrTLB8CDIrIWPXRk3woHdKPJ2L3/lojkoZ+Pkeg6eMLoWbWG40b+7hCRU0ClUmpbM+I/CqwRkRr0IozT6LnYa4EnlVKHXcT7E/oa/hc9kd4XvQrrbWP+D9ysI2copWxGvf1DRLqg690CdAdGK6VuakYZa5mFXpa/QkTmAsXouaRtSqkvOLvP4nPoe2eJiLyBnv/5K3pB0qbGIiqlKkQkFd0Y3IdemLVHtXZv0tlcqXA+PjSyj8fFuf9Fdyfz0cMZ12G3SoYzK0OuaxC3Lk20onkb3aUuQb8cvgD62p1/Jw1WtRnhQcA/0MubK9Ctzs+AYXbnKOyWZTZRfl/gdXSXvxw9lHd1g3PW02AJKmdWrbhcHWScdyl60rQEPfzxMc73DrisL7uwS9AvkHz0CykZrRwa3U+E3seznDP7Wn4Axtodj0evUDuNfuF/gd3KQVd1iqGgzkZ5jWOXo1vpxbRuH0+j9YReyrsNvfKstj5+aRdfgJfRvZmahuk7ycMDhowKdGPI6T4eJ/GavE/RjbvDRtqqsXvPxX16BfAVugdWjJ4o/zsQ1ITcW9Av5dpnrG4fT2N11Jyyopc0bzeuUYFxHR5u7BloIs8j0Uqs9t5bh92KuJbem87yAYzlzD6ebFzv43F4P6CXq+8x4irOwj6e2n0CJiYmJiYm54WLfY7HxMTExOQCw1Q8JiYmJiZ1iMg7IpJtzOnUhoWKyCoROWJ8h9gde1xEkkXkkIhc7Y4MU/GYmJiYmNjzLtqEjz2zgDVKqW7olZizoG57ylT0FodrgH83WD3nFFPxmJiYmJjUoZTaiOP+nl+ibeFhfN9oF/6JUqpcKZWKXrQyqCkZF/ty6jah+rXbzRUb5wPPNrh9vdrokSlt7UrnFhLmzsb/c0BeW+5lPb94PPRhS00g1dGcd47nzI/+D7jXLmiuUmpuE9EilVKZAEqpTBGp3ZAag17ZWUs6jZvl0nlwN7MmJiYmJj99DCXTlKJxF2dKs0klaA61mZiYmJg0RZaIRAMY37UeltOpb6uuI67NG9VhKh4TExMTk6ZYivYHhfH9uV34VBHxNsxYdUNb4mgUc6jNxMTExKQOwyzXKKC9iKSjTRK9hHZZMR1tGmkygFJqv4h8irYwUQXcr+q7X3CKqXhMTExMTOpQSt3q4pBTNzBKqefRJorcxhxqMzExMTE5r5iKx8TExMTkvHLeh9pEJBLtxXMw2sJrBdpq7NdoC9D90Ev0bGif50UiUk19XyGfKKVeEpGP0O6BK9ETWv+ntEtdRGQU8BraO2GuUmqkXR480NZ+TyilrmuQv0eAV4BwpVSuEfY4MB1tgv/3SqmvW1L2D/acZMGBXBSKyT3DmZYYxcHcEp7dmEZJZQ0xAVZevioBf6vjxt/3dp9kYVIOgtA9zIfnR8fh7em83fDkulQ2pNkI9fFi6dQ+ANjKqvjDqhROnC4nJsCbv49PIMhbX/65OzJYlJSLhwhPXNmZKzsHOaTZWPy2LKuD3F2ZLNifhQIm945kWv9oknKKeXbdUcqra/C0CLNHxtEvKsAhbmF5FU+vSeFIXgkiwnNjE+gf7XieU7k7TrBg70ktt28U0y6LISm7iGdXJ5+RO6Yr/Zyk9+TXh9lwNJ9QXy+W3uHUw7NzmW1Vx1uOsWBnOkopJl/akWlXxALw4dZjfLz1OB4WYWS3cB4Z26NevMxTpTy+dC+5RRWIwJTLOvHrQY25szo75c0sKufxNankllRqub3C+XW/KJdyLoTn52LnvPZ4DKdHS4CNSql4pdTlaHMLHYEHgSylVF+lVB/0i77SiFqqlOpv93nJCP8IbVK+L9rp2wxDTjDa7PcNSqneODqJehAnfnREpBPaD8pxu7AWmYRoyJG8EhYcyGX+xJ4sntKH9cdOkWYr4+n1qTw8uCOf39KHsXEhvLPL0RtuVlEFH+7NYsGk3iyd2odqpVie7HqD3U092jP3uu71wubtzGRwTCBf3daPwTGBzNuh5STnl7IiOZ9lU/sw97ru/OWbY1TXOC7DdxW/rcvqIHd/FvOn9GXxrYmsTy0gzVbKq98d47eDOrL41kQeuKITr35/3Gn8FzemcWWXYL789aV8dms/4kN93JObW8yCvSeZf1t/Fv/6MtYfzSetoJRXv0nlt0M6s/jXl/HAkC68+k2q0/g39Y5k7s193JJVr6xtUcfZp1mwM535dw9m8b1DWX8kh7T8Yn5Iy2PtoWyW3DuMZfddyV2DYx3ielosPHrVJXzxmyv55K7BfLztOMk5Ree8vJ4iPDq0E1/c2pdPbu7Fx/uySc4vdSmrrZ+fnwPne6htDFChlHqzNkApdUwp9TraDewJu/BDqglXzkqp5coA3ePpaBy6DfhMKXXcOK92zTki0hHtWMqZq+E5aGdU9ndOi0xCNCTFVkZipB8+Xh54WoSBHQJYk1pAqq2MAUYreGinQFYeLXAav7pGUVZVQ5XxHeHn5VLWgA4BDq2ptak2buwRBsCNPcJYk2rT4WkF/KJrKFYPCx0Dvekc5M3e7GKHNF3Fb+uy1pObX0piVMAZuTGBrEnJRwSKK/RCm6KKaqfpFVVUsS2jkIm99IZsq4eFQDdbpCn5JSRG28ntGMSa5FwEe7lVRPhZncYf0DGIoHbNa/22WR3nFpMYE2TItTCwSyhrDmbzyfYfmTE0HqvRawrz83aIGx7gTa/oQAD8vD2Jb+9H9mn3LDK0przhflZ6hftpuVYP4kN8yC527cesrZ+fnwPnW/H0Bna4OPYO8JiIbBKR5wzf8rX4iMguu88t9hFFxAv4NdqBFGjPgCEisl5EtovINLvTX0Mrl5oGadyAHnrb3SBfMWgnbrW4ZRKiId1CfdiWeRpbWRWlldVsPG4js6iCbqE+rE2zAfB1SgEnixwfiEh/K3f1j2LsB7sZ+d4u/K0eDOvk2J1vjLzSSsKNF1+4n5X8Ut2ZzC6uJMr/zAsx0s9KlpOH0lX8C6ms3cJ82JZRiK20Uss9VkBmUQWzhsfyynfHGPPf7bzybRoPDXEc3vnxVDmh7Tx5cnUKN/9vN7PXpFBS2eSqUEOuH9vS7eSm5pN5upxZoxJ4ZWMqY+b+wCsbUnloeKxb6bkls63qOMKfbccLsJVUaLnJOWQWlpGWX8L2Hwu45Z3NTHt/C3szTjWazglbKUknT9MvJvicl7ee3MJyknJL6Bfp75bcWs7n89MiPD3d/1wAtGkuRORfwJXoXtBAEYlHe7u7CtgqIkOUUkkYQ22NJPVv9PDdN8Z/T7R3yLHoIbhNIrIZrZCylVLbjTmg2nz4Ak8ash2y6STMoS8tIvdi2D96Y/Ig7hnard7xhBAfZlwazfRlh/D1stAjzBdPi/Dc6Dhe+PY4b2zLYHRsMF4WR3GnyqtYm2pj1e39CLB6MHNlCksP53JD9/aNVIl7OPMD2FrDUW1V1oRQX2Zc1oHpnydpue398LQIn+zNYtbwWMZ3DWPFkVxmr0nhnZt61YtbXaM4kFPMEyPjSIwK4IWNqczbfoLfD+7ctNwwX2YM7Mj0RXvx9fKgR7ghd3cms0bGM757e1YcymH2yiO8M6mv+xXZmMy2quP2/swYEsf0j7fh6+VJj8gAPC1CdY2isKyST+66gr0Zp3h40W5WPjAcPbpen+KKKh5cuIvHx1+Cv5u9ytaUt05uZTUPfp3M48M6OZ33agnn4vn5OXC+Fc9+YGLtH6XU/SLSHj3Rj1KqCO0W+jPD7/oEnMzF2CMifwLCgf+zC05HLygoBopFZCOQCFwG3CAiE4B2QKCIfIj2Px4H7DYelI7ADhEZhJsmIeztH7ky2DexZzgTe4YDMGdzOlH+VuJDfJh3vZ6ETbOVsfG4Y0txU3ohMYHehPro4ZBx8SHsOlnULMUT5uNFTnEF4X5Wcoor6tKK9Peq10rMKq5wOiTkKr4r2qqsE3tHMrF3pJb7/XGi/K3M2XScJ0bEAnBN1zCeXnPUIV6kv5VIf28SjUUH4xPCmLf9hMN5LuX2jWJiXz1hPefbNC332zSeGB2v5XZvz9Orjridnlsy26qOL+3IxEv1qPactYeJCmzH0dwixvWIREToFxOMRaCgpJLQBvdSZXUNDy3cxXV9ohl3SeR5KW+d3K+Tua57GOPim2/49Hw/Pxc753uobS3QTkR+YxfmCyAiw2qdC4mIFegFHGssMRGZAVwN3KqUsh86+xwYLiKeRm/mCiBJKfW4UqqjUioWvWBgrVLqdqXUXqVUhFIq1jiWDlymlDpJC01COCOvRHevM06Xszq1gAndQuvCapTize0ZTOkV7hAv2t/K7qwiSiurUUqxOb2Q+BD3Jr5rGR0bzJJDeQAsOZTHmLhgIzyEFcn5VFTXkF5YzjFbOX0j/NyOf6GVtZ7clDwmdG9PhJ+VrScKAdicXkiX4HYO8cL9rET5W0ktKDXOO0WCm4sLtFz98skoLGP1kVwmXBJOhL+Vren6Rbj5Rxtdgpt3zZqW2UZ1XKynXjNOlbL6UDYTekczpkckP6Tp+yMtr5jKakWIb/2Xq1KK2V/sJ769H3c6WXxwrsqrlGL2+jTig324M9H1arbGON/Pz8WOKGd9xXMpUBuYm4NWBjlAMfAm4A08gu6pWoAvgceUUsrJcuqvlFKzRKQKrZxOG+GfKaX+bMj5I3AXei5nnlLqtQb5GAU80nA5tXEsDRhgt5z6SeButEmIh5RSKxoro6sez+2Lk7CVV+FlER4d2pkhHQP5YM9JPt6n1z6Miw9h5hUdERGyiyuYvT6Nt67Vq2te33KCr1Ly8RChZ7gvfxkVi9XDebvhkVUpbMnQ4+FhPp48MDCGsXEhzFyZTGZRBdH+VuaM70qwMaH95vYMFh/Uy0FnDevEiC7BAMxel8otvSPoE+GHrazKZfw2K6uT8erbF+7DVmbIHR7LkE5BbM8o5MWNaVTXKKyeFp4eFUfvCH+yiyqYvTaFt27oCUBSTjFPr02hslrRMdCb56/q6jjp78Itwu3zd2MrrcTLYuHRUXEM6RzC9hOneHHd0TNyxybQOzKA7KJyZq88wlvGSrZHvjzIlnQbttIqwny9eGBIl7reUx1O3CKclzp24hbh9vd+MMoqPDruEobEhVFRXcNTy/ZxMOs0Xh7CH8f2YHBcGNmny5j9xX7euvVyth8v4Nfvb6F7hH/dENxDo7sxsqujsnDmFqGl5d2eeZpfLzlI91Afakf+HrqiIyON+7wh5/v5OStuEf55p9svco8H3m3z0cDzrnh+Dpj+eM4Tpj+ec4/pj+ec83NUPKblAhMTExOT84qpeExMTExMzium4jExMTExOa+YisfExMTE5LxiKh4TExMTk/OKqXhMTExMfup4ebr/aQIReVBE9onIfhF5yAjrLyKbDZNl24zN9S3GVDwmJiYmJgCISB/gHrQh5ETgOsNu5svAs4bpsqeN/y3mwrAYZ2LyE0G6xrd1Fs4v/u75IzrbqE0/tIlcE3oCm5VSJQAisgG4CW2fMtA4JwgnZsOag6l4TExMTH5G2Bs0Nphr2JoE2Ac8LyJhQCnaXuY24CHgaxH5G3qkbGhr8mAqHhMTE5OfEfYGjZ0cSxKRvwKrgCJgN9pU2G+AmUqpRSIyBfgP2otAizDneExMTExM6lBK/UcpdZlSagSQDxwB7kB7DgBYQAucYdpjKh4TExMTkzpEJML47gzcDPwPPacz0jhlDFoZtRhzqM3ExMTExJ5FxhxPJXC/UqpARO4B/iEinkAZ9eeImo2peExMTExM6lBKDXcS9i3aq/NZwRxqMzExMTE5r5z3Ho+IRKIdwQ0GCoAK9Gakr4G3gX5oZ3A24BqlVJETR3CfKKVeEpF30eOOtf5u71RK7TKcwP3KCPNEr00PV0rli8g1wD8AD7SDuJfs8vY74AH0Ko4vlVKPikgs2v32IeO0zUqp+1pS9g/2nGTBgVwUisk9w5mWGMXB3BKe3ZhGSWUNMQFWXr4qwak/eGdxXfHkulQ2pNkI9fFi6VTtbMxWVsUfVqVw4nQ5MQHe/H18AkGGv/u5OzJYlKQdWT1xZWeu7BzkkGZj8dtKptM63pXJgv1ZKGBy70im9Y/mYE4xz64/SkllNTEB7Xj56q74Wx3T+eZYgXYYpxSTekVyz4CYRmXZ8/7aAyz47oi+PsO6c8eYXtiKy3n4Pxs4kVdETJg/c2aMJMjX262451JmZn4xs977ltzCUsQCU4Z1Z5qbMgHe/WoXCzccQIDuncJ4YcZY3v5iOws2HCA0QHsyfWjyYEYmxjrm+evdLFi/X1+fkb2445r+bsttzfPz3u6TLEzKQRC6h/nw/Og4vD2dt7svlHv5Yua89nhEux1cAmxUSsUrpS5Hu6DuCDwIZCml+iql+gDT0WOMAKVKqf52n5fskv2jXfguAKXUK7VhwOPABkPpeAD/An6Bdq19q4j0MvI2Gvgl0E8p1Rv4m52MFDsZLVI6R/JKWHAgl/kTe7J4Sh/WHztFmq2Mp9en8vDgjnx+Sx/GxoXwzq5Mt+O64qYe7Zl7Xfd6YfN2ZjI4JpCvbuvH4JhA5u3QcpLzS1mRnM+yqX2Ye113/vLNMaprHH1KuYrfljKd1tP+LOZP6cviWxNZn1pAmq2Up9em8PDQznx+W3/GJoTyzg7HvW/VNYrn1qfy1g09Wfar/iw/nEtyfkmj8mo5nFHAgu+O8Olj17LkiRtYvzedtOxC3v56L0N6RPP1szczpEc0b3+9z+2451Kmh4fw6MQBfPmnG5n/x2v5eOMhkjNtbpU1K7+ID1fuZuGzU1j24m3U1CiW/6Dnme+4OpHFz01l8XNTnSqdw+l5LFi/n0+fmcyS56ayflcaaSfdk9ua5yerqIIP92axYFJvlk7tQ7VSLE927WjuQriXm43V6v7nAuB8D7WNASqUUm/WBiiljimlXgeigRN24YeUUuVnQeat6FUZoJcAJiuljiqlKoBP0MoG9Dr1l2plKqWyz4LsOlJsZSRG+uHj5YGnRRjYIYA1qQWk2soYEK13hw/tFMjKowVux3XFgA4BDq2ptak2buwRBsCNPcJYk2rT4WkF/KJrKFYPCx0Dvekc5M3e7GKHNF3Fb0uZDUnJLyUxKuBMPcUEsiYln9SCMgZ00Juuh3YKYqWTl87erCI6B7ejU1A7rB4WftG9PWudXAtnHD15isS4cHysnnh6WBjYLZLVu46zds+P/HJwAgC/HJzAmt3H3Y57LmVGBPnSu7OuV792XiREBZFlc0/JglbSZRVVVFXXUFpeSUSwn1vxjmYUkNg1Ch9vL53nS2JYvf2oW3Fb8/zU5bmqhirjO8LPy6WsC+Fevtg534qnN7DDxbF3gMdEZJOIPGfYB6rFxzBOV/u5xe7Y8yKyR0TmiEi9MQUR8QWuARYZQTHAj3anpBthAN2B4SLyg4hsEJGBdufFichOI9xh4s0duoX6sC1T+3Evraxm43EbmUUVdAv1YW2aDYCvUwo4WVThdtzmkFdaSbifbu2E+1nJL9WdyeziSqL8z7SCIv2sZBU7pu0q/oUks1uYD9syCrGVVup6Olag6zjMh7WGov46OY+TRY7tmaziCqL8z9w+Uf5Wsp2c51RudDDbkrMoKCqjtKKKjftPcLKgmLzTpUQE+QL6ZZ9/2rGX6iruuZRpz4m8IpJ+zCcxtr1bZY0M9eeuX1zK2JnvMeL37xDg682wvp0B+Gj1Xn755P948u01nCp2UtaYULYdPEHB6VJKyyvZuDuNk3mn3ZLbmucn0t/KXf2jGPvBbka+twt/qwfDOjkOhzVGWzw/FzNtOsgoIv8CrkT3ggaKSDwwHr0jdquIDFFKJWEMtTlJ4nHgJGBF78R9DPiz3fHrge+UUrVNXGe+xmv7xZ5ACHruaSDwqZGfTKCzUipPRC4HlohIb6VUvfEQezMUb0wexD1D7fUmJIT4MOPSaKYvO4Svl4UeYb54WoTnRsfxwrfHeWNbBqNjg/GyOGbRVdyzgXLiqf1cO2Q/VzITQn2ZcVkHpn+epOupvZ+u47FdeWFjKm9sSWd0XAheHo7tLWd5QtzLVUJ0MDPG9WH666vw9fbkkpgQPDzObdzWyKyluKyS389dx6xJA/H3cW8I5lRxGWt3HGXVq9MI8LUy859fsfS7Q0wd25ff3DgQQfh/izbz8sff8fw9Y+vnOSaUGdddzvSXl+LbzotLOrfHw8m1cFreVjw/p8qrWJtqY9Xt/QiwejBzZQpLD+dyQ3f3lG1jtMXzczFwvhXPfmBi7R+l1P0i0h5tCwilVBF6d+xnIlKDthOU5CoxpVTtQGm5iPwXeKTBKVM5M8wGuofTye5/R84Yu0sHPlNKKWCLIb+9UioHqB1+2y4iKeje0bYGeakzQ1H92u3OXmNM7BnOxJ7hAMzZnE6Uv5X4EB/mXd8DgDRbGRuPn3IW1Wnc5hDm40VOcQXhflZyiisI9dFDDZH+XvVaiVnFFUT4OabtKv6FJnNi70gm9o4EYM73x3Udh/ow70Y9eZ5WUMrGNMfhmCh/a72e0Mki53lyxaRh3Zg0TDc25ny+g8hgX8ICfMg+VUJEkC/Zp0oIDWjndtxzLbOyuoYH317P9YPiGX9pF7fLuWl/OjHhgYQG6kUEVw1IYOeRTG4Y1qPunMmjenPf379wnueRvZg0Ul+LOQs2ERni77bslj4/m9ILiQn0rrt/xsWHsOtkUbMUT1vcyxcz53uobS3QTkR+YxfmCyAiw0QkxPhtRU/+H2ssMRGJNr4FuBFt4K72WBB6xdvndlG2At1EJM6QMRVYahxbgp6DQkS6o3tRuSISbixKwOgBdQPcG5huQF6J7l5nnC5ndWoBE7qF1oXVKMWb2zOY0ivc7bjNYXRsMEsO5QGw5FAeY+KCjfAQViTnU1FdQ3phOcds5fSNcByzdxX/QpNZr55S8pjQvX39Ot6azpS+jisC+0T6c8xWRvqpMiqqa1hxOJfRcSFNyquTe7pUy80vYtWuY1w7MI4x/Trx+eYUAD7fnMKYfp3cjnsuZSqleOqD74iPCuLOsb3dLiNAdJg/u1OyKC2vRCnF5v0/ktAhhGzbmeHBVduP0q1jmPM8F+q5pIzc06zalsK1Q7o5Pc9p3BY+P9H+VnZnFVFaWa3znF5IfIiP23Khbe7lixlRTscYzqFArSzmAFcAOUAx8Cbgje6xCFohfgk8ppRSTpZTf6WUmiUia4FwI84u4D6j14SI3Ilejj21gfwJwGvo5dTvKKWeN8Kt6Hmm/ugl3o8opdaKyET08F0VUA38SSm1rLEyuurx3L44CVt5FV4W4dGhnRnSMZAP9pzk4316HcO4+BBmXtERESG7uILZ69N469ruLuO64pFVKWzJ0OPhYT6ePDAwhrFxIcxcmUxmUQXR/lbmjO9KcDvd4X1zewaLD+rloLOGdWJEl2AAZq9L5ZbeEfSJ8MNWVuUyflvJxNOxw377wn3Yyox6Gh7LkE5BfLArk4/3njTqOJSZQzvrOi6qYPbaFN66oScAG9IKeOmbNGpqFDf1iuC+gR0d0pee3R3CAG5/dQW24nI8PSw8NnEgQy6JpqCojIf/s4GM/GI6hPoxZ8Yogv28ybaV8NRH3zP3/qtcxnWHlsrcnpzF7X//iu4dQrAYTc+HbriMkX0cy+vMLcLrn/3Aih+O4GGx0LNLOM9NH8NT/1nLweM5iAgx7QN45q7RRAT7kV1QxFP/WcfcR67XeX5uEbaiMp3n265kSG/nytiZW4TWPD+vbznBVyn5eIjQM9yXv4yKxepimO9838seD33Y6tG56v/+1u0Xucdd/27z0cDzrnh+DrhSPCZnGSeK51zjSvFctJj+eM45P0fFY1ouMDExMTE5r5iKx8TExMTkvGIqHhMTExOT88rP11iQiYmJycVCG8x3tgazx2NiYmJicl4xFY+JiYmJSR0i8qCI7BOR/SLykF3470TkkBH+cmtk/LT6ZyYmJiYm5wwR6QPcgzaoXAF8JSJfoq281FrvL691j91STMVjYmJiYlJLT7TPsRIAEdkA3AQM4Cxa7zcVj4lJc6iubhOx6sRZ9t/iJhLeekOaJhcW9gaNDeYatiZBmx17XkTCgFK0vcxtnLHe/zxQhrbssrWleTAVj4mJicnPCHuDxk6OJYnIX4FVQBGwG20uzKn1ftVC0zfm4gITExMTkzqUUv9RSl2mlBoB5ANHsLPer5TaAtQALe4Omz0eExMTE5M6RCRCKZUtIp2Bm4EhaEUzBlhvb72/pTJMxWNiYmJiYs8iY46nErhfKVUgIu8A74jIPvRqtztaOswGbioew/3Ab5VSB50c6w68qZQa09JMmJiYmJhcGCilhjsJqwBuP1sy3O3xjAJcOYAJBEacldyYmJiYmDQbuYhN5jh0qwznaWOAk2ctRyYmJiYmFzUu1aSI/Al42virgM3aw7RTXnFXoIhEoj2QDgYK0OOFLwNfA28D/dAeRW1oD6JFTjyQfqKUeklExgB/Q090bQemK6WqRGQU2uV1qnH+Z0qpP4tIJ+B9IAo9WTZXKfUPI19/Qe/MrQGygTuVUhkiMogzSw8FeEYptdjd8trzwZ6TLDiQi0IxuWc40xKjOJhbwrMb0yiprCEmwMrLVyXgb/VwiHvVh7vx8/LAIuBpERZMcu2y+Ml1qWxIsxHq48XSqX0AsJVV8YdVKZw4XU5MgDd/H59AkLe+/HN3ZLAoSXtQfOLKzlzZOcghzcbit5VMp3W8K5MF+7NQwOTekUzrH01STjHPrjtKeXUNnhZh9sg4+kXVd3CWWlDKw18drvuffqqc3w3uxLT+7nkDfX/9QRZ8fwSlYPLQrtwxuidf7TzGP5fv4WjWKT595Bf06ezcHfS7a5NYuCkZEegeHcwLtw/F28vxHnAo69bjLNidocua2IFpAzsD8OG2H/l4RzoeFmFkQhiPjK7vXjo1r5iHP6/zEk+6rZTfDY+vi99kWTceZsEPKbqsg+O5Y0QPXlm2i3X7M/DytNApzJ8Xpg4i0MfqEPfJT7awPimDUH9vlv3xF27JqytvK56f93afZGFSDoLQPcyH50fH4e3pvN19odzLFzON9XiWA78HHkS/cP9u/Lf/3AeMUkrNckeYaM21BNiolIpXSl0OTEWbY3gQyFJK9VVK9QGmoye3AEqVUv3tPi+JiAV4D5hqnH8MuMNO3Dd25//ZCKsC/qCU6olWfPeLSC/j2CtKqX5Kqf7AF5xRuvuAAUb4NcBbItLsO+ZIXgkLDuQyf2JPFk/pw/pjp0izlfH0+lQeHtyRz2/pw9i4EN7Z5Xqj4Ls39GDxlD6NKh2Am3q0Z+519T1lztuZyeCYQL66rR+DYwKZt0PLSc4vZUVyPsum9mHudd35yzfHqK5xnDN0Fb8tZTbkSF4JC/ZnMX9KXxbfmsj61ALSbKW8+t0xfjuoI4tvTeSBKzrx6vfHHeLGhfiw+NZEFt+ayMJb+tHOy8LY+NBG5dVyOMPGgu+P8Okjv2DJrGtZv+8EadmFdIsO5vUZIxiQ4Nq6SJathA83HGThH3/Bsieup0Yplm9Pa1LmkZwiFuzOYP4dA1l89yDWJ+eSll/CD8fyWXskhyV3X8GyGYO5a1AXx7KG+bH47itYfPcVLLxzEO28PBjbPdy9smbaWPBDCp8+OI4lf7ia9QcyScs5zdDuUSz94zV8/sg1xIYHMHdNktP4Nw6MZe49zR+Zb83zk1VUwYd7s1gwqTdLp/ahWimWJ+e7lHUh3MsXOy4Vj1Jqq1LqX8Bb6Jfwa0qpfzX4vK2U+qYZ8sYAFUqpN+3kHFNKvQ5EAyfswg/VmmdwQRhQrpSqbaauAiY2JlwplamU2mH8Pg0kATHG/0K7U/0whhaVUiVKqSojvB1OhhzdIcVWRmKkHz5eHnhahIEdAliTWkCqrYwB0br1PbRTICuPFrQk+XoM6BDg0Jpam2rjxh66xX1jjzDWpNp0eFoBv+gaitXDQsdAbzoHebM3u9ghTVfx21JmQ1LyS0mMCjhTxzGBrEnJRwSKK7TFgaKKaiL8vBpNZ3P6KToHtSMm0LvR82o5mnWKxNj2+Fg98fSwMLBbBKv3/EhCVBBxkY6t34ZU1yjKKqupqq6htKKaiCCfJuOk5BWT2CHIKKuFgZ1DWHM4h092nmDGkFisRms+zM+x11GvrMfy6RzsQ4wbMgGOZp8msXPYmbImhLN6bzrDekTh6aFlJnYJI8tW4jT+wIQIgn3dq1d7Wvv8VNcoyqpqqDK+G7sHLoR7+WLHnTmeamA2cMlZkNcb2OHi2DvAYyKySUSeExH78QEfEdll97kFvYbcS0QGGOdMAjrZxRkiIrtFZIWIOHQRRCQWuBT4wS7seRH5EfgVZ3o8iMgVIrIfPdx3n50icptuoT5syzyNrayK0spqNh63kVlUQbdQH9am2QD4OqWAk0UVTuMLMOOLw0xasJ9PDzTfTFJeaSXhxkso3M9KfqnuTGYXVxLlf+blFOlnJavYMQ+u4l9IMruF+bAtoxBbaaWu42MFZBZVMGt4LK98d4wx/93OK9+m8dAQx16APcsP5zKhm/NhMadyo4PZlpxNQXE5pRVVbNyfwckC5y/ehkQG+3LX2F6MfXoxI55aRICPF8N6dmhaZnt/tv1YcKasKblkFpaRll/C9h9t3PLeVqZ9tJ29mYWNprP8QBYTekW6lVeAblFBbDuac6asSZmcbKBkPtuSyvCe7g1Rui23Fc9PpL+Vu/pHMfaD3Yx8bxf+Vg+GdWq6QWBPWzw/FzNNDhkppWpE5Ajg/t3pJiLyL+BKdC9ooIjEA+OBq4CtIjJEKZWEMdTmJP5UYI6IeAMr0UNpoJVbF2N+aAJ6eK+bXTx/YBHwkH1PRyn1JPCkiDwOPAD8yQj/AegtIj2B90RkhVKqrEFe6uwfvTF5EPcMrT+unhDiw4xLo5m+7BC+XhZ6hPniaRGeGx3HC98e541tGYyODcbL4nwe7aObehLhZyWvpJIZXxwiPtiHAR0CnJ7bHJytxHc5k3eWOFcyE0J9mXFZB6Z/nqTruL0fnhbhk71ZzBoey/iuYaw4ksvsNSm8c1Mvp2lUVNewLrWAmUPdm+8ASIgKYsa43kz/52p8vb24JCYEDxfXsSGnSspZu+dHVj1zIwG+Vmb+ZyNLtx7lhoHxjcts78eMwbFM/2Qnvl4e9IgIwNMiVNcoCssq+WTaAPZmFvLwkr2svG8ozuZnK6prWJecy8xRCe6XNTKQGWN6Mv2t9bqsHYLx8DjTfn1z9QE8LML1lzWu3JtLa56fU+VVrE21ser2fgRYPZi5MoWlh3O5oXvr7dC1xfNzMeDuXMWTwF9FZK9Sam+TZ7tmP3bDYUqp+0WkPdoIHUqpIuAz4DMRqUEbqHM+WKzP3wQMBxCR8WhDdjRQJstF5N8i0l4plSsiXmil85FS6jMXSX8MfImheOzSShKRYqBPbZ7tjtXZP6p+7Xanw3ETe4YzsaceS5+zOZ0ofyvxIT7Mu74HAGm2MjYeP+U0QxFGaynM14uxcSHsyS5qluIJ8/Eip7iCcD8rOcUVhProoYZIf696rcSs4oo6We7Ev9BkTuwdycTeuo005/vjRPlbmbPpOE+MiAXgmq5hPL3mqMv43xyz0Svcj/a+jQ9RNWTSkK5MGtJVy126k8hgX7fibTp0kpgwf0ID2gFwVWJndh7NbVLxAExM7MDERN07mrMhmaiAdhzNK2Zc9whEhH4dgrCIUFBaSaiT8nyTkkevyADa+zVv6GvSFfFMukLnb87yPUQaw3RLtqay/kAG/71vlFNF11pa+vxsSi8kJtC77v4ZFx/CrpNFzVI8bXEvX8y4u5z6KfScyi4ROS4iW0Vki/3HzXTWAu1E5Dd2Yb4AIjJMREKM31agF3rBgEtqfUIYPZ7HgDeN/1HGQgaMVWkWIM8I+w+QpJT6e4O07LsoNwAHjfC42sUEItIF6AGkuVneeuSV6O51xulyVqcWMKFbaF1YjVK8uT2DKb0cJ3lLKqvr5ihKKqv5/sdTdAt178VWy+jYYJYcygNgyaE8xsQFG+EhrEjOp6K6hvTCco7Zyukb4ed2/AtNZr06TsljQvf2RPhZ2XpCt0U2pxfSJbidy/jLD+cyoQUt4bzTugOckV/Mqt0/cu2AWLfiRYf4sTstl9KKKpRSbD58koQoV1vmGsg0hnQyTpWx+lAOE3pFMqZ7OD8c0xPnafklVFbXEOLiJbc86WSzhtnq5NaWtaCYVXvSufbSLnxzMJN56w7y77uvxMd6blZrtfT5ifa3sjuriNLKal3H6YXEh7g3p1VLW9zLFzPijtUDEflvU+cope5yS6BINHo59RVADlCMVhjewCPonqoF3eN4TCmlnCyn/kopNUtEXgGuM85/Qyn1miHjAeA36KG3UuBhpdT3InIl8I2RVo2R1hNGr2gRWqnUoBXefUqpEyLya2AWeoVdDfBnpdSSxsroqsdz++IkbOVVeFmER4d2ZkjHQD7Yc5KP9+k5m3HxIcy8oiMiQnZxBbPXp/HWtd35sbCM33+VDEBVjeLabmHcd7nreYBHVqWwJUOPh4f5ePLAwBjGxoUwc2UymUUVRPtbmTO+K8Ht9Avize0ZLD6ol4POGtaJEV2CAZi9LpVbekfQJ8IPW1mVy/htJdOZn/nbF+7DVmbU8fBYhnQKYntGIS9uTKO6RmH1tPD0qDh6R/iTXVTB7LUpvHVDTwBKK6sZ8+4OVk67lAAXS12lu/NhqdvnfI2tpAJPi/DYzZczpEc0q3Yf5/mF28gvKiPQx8olMSHMu38s2adKeOrjzcz9jTb28fqXu1mx4xgeHkLPjqE8d+tgrA2WUztzi3D7h9uwlVbiZbHw6NhuDIkNpaK6hqeWJ3Ew6zReHhb+OLorg2NDyT5dzuwVSbw1pf+Zsv7rW1beN4yAdq4VhTO3CLf/c82Zst5wKUO6R3L1C19SUVVNsNF7SuwSxjOTBpB9qpSnPt1at5LtDx9sYktKNrbicsIC2vHA1X3qek/1ypvs2Ctt6fMD8PqWE3yVko+HCD3DffnLqFisHs7b3ef7XvZ46MNWdw9r/vew24ueLLf+vc1HA91SPCbNw5XiMTnLtMFubVeK51zzc/PH40zxXKycFcWz8FH3Fc+kl9tc8TT7yTXmZEKAfKVU3tnPkomJiYnJxYzbJnNE5BYRSQKy0PMf2SKSJCKTz1nuTExMTEwuOty1Tn0r8BGwAngRrXwigVuAT0TEQyn1yTnLpYmJiYnJRUNzllPPVUrd1yD8fRF5E73qzVQ8JiYmJiZN4u5QW1f03hdnLDKOm5iYmJj8xBGRB0Vkn4jsF5GHGhx7RESUMdffYtxVPFnAABfHBhjHTUxMTEx+wohIH+AeYBCQCFxXu8fRsO4/DnC0sttM3FU8/wWeEZGnROQSEQkRkR4i8hR6d/87rc2IiYmJiUmb0xPYbGcceQNwk3FsDvAoLTSUbI+7czx/BrzQGymftQsvRfvD+bOzSCYmFxvqwKG2ERzknjWDs05Vs+3hnh3awqNmW5X1PGNvV9JgrmHyC7QbmOdFJAz9fp8AbBORG4ATSqndZ8MckltXVylVgzae+Te0nbJoIBPYp5RqvR1/ExMTE5Pzgr1dSSfHkkTkr2g3M0XAbrQFmCfRBpzPCs1qVhhKpjn+d0xMTExMfkIopf6DtmmJiLyAnsP/FVDb2+kI7BCRQUqpky2R4bbiEZF2wAhDaEMri0op9UZLMmBiYmJi0krO4tCkiEQopbJFpDNwMzBEKfUPu+NpaK/MuS2V4e4G0ivR7gpcLaFTgKl4TExMTH76LDLmeCqB+8/FdIq7avL/ASnopXQHlFI/b/d5JiYmJhcpSqnhTRyPba0MdxVPD+BmpdTu1go0MTExMfl54+4+nj1A1LnMiImJiYnJzwN3ezy/Ad4VkTSl1IZzkRERiURvUBoMFAAVwMvA18DbQD+0kzgbcI1SqsiJg7hPlFIv2aX5OnCXUsrfLmwU8Bp6X1KuUmqkEX4N8A/AA5hXm46IzEf3+ACCAZtSqn9LyvjBnpMsOJCLQjG5ZzjTEqM4mFvCsxvTKKmsISbAystXJeBvre8ELLWglIdXpdT9Ty8s53cDY5iW2HRboKUyAd7bfZKFSTkIQvcwH54fHYe3p3ttlbYoK8AHuzJZsD8LBUzuHcm0/tEk5RTz7LqjlFfX4GkRZo+Mo1+Uo9vw93ZmsPBANgJ0D/Pl+au6nvPyAjy5LpUNaTZCfbxYOrWPW/IAPth6nAW7M3RZEzswbWBnHl6yl9T8EgBOl1UR0M6TxXdf4SjzywNsSMkl1NfK0hmD3ZYJ8P63R1iwJQ2lFJMHxXHH8G784+v9rD2QgUWEUH9vXpwygIhARy+fhaUVzF64gyNZpxCE5yZfzqVdwtwrbyuuLUB1jWLy/D1E+lt54/qeLuU4ux62sir+sCqFE6fLiQnw5u/jEwgynAXO3ZHBoiTtCO6JKztzZecghzQbi/9zxGXJRSSH+jtU/YC1IlIJFDY8XykV0dJMGC6plwDvKaVuM8K6oF1QPwhkKaX6GuE90JNeAKWulICIDEArCvuwYODfaMV13M51tgfwL/QcVjqwVUSWKqUOKKVusYv/KuDo1N0NjuSVsOBALvMn9sTLw8K9XxxmRJdgnl6fyh+HdmJgh0AWJeXwzq5Mfj+oY724cSE+LJ6iH4DqGsWo93cxNj7knMrMKqrgw71ZLJval3aeFmauTGZ5cj43XdK0iaa2KGud3P1ZzJ/SV8v9PIkRscG8+t0xfjuoIyNiQ9iQVsCr3x/nvZt7NyhvOR/uOcmyXyXSztODmSsOs/xILjf1bPq2bk15AW7q0Z5f9Ylg1ppUt8oJcCSniAW7M5h/x0C8PIR75+9iREJ7/n5j37pz/rrmCAHejooO4Ka+0fzq8o7M+uKA2zIBDp88xYItaXz6wGi8PCzc8863jOwZxfSR3Xnwal2nH3yXzL9XJ/HMzZc5xH9h6W6u7BHJP349mIqqGsoq3du02ZprW8sHuzNJCPWhyHAj7wpn12PezkwGxwRyz2XRvL0jk3k7MvnDkE4k55eyIjmfZVP7kF1cyfRlh1h+a188LPU3WbqK/3Olsebcvxp8XkZbKHjRybF/tTIfY4AKpdSbtQFKqWNKqdfRm1VP2IUfUkqVN5aYoUheQZt3sOc24DOl1HEjrWwjfBCQrJQ6qpSqQFva/mWDNAWYAvyvBeUjxVZGYqQfPl4eeFqEgR0CWJNaQKqtjAHRuoU2tFMgK482voBk84lCOge1IybA+5zLrK5RlFXVUGV8R/h5XbBlBUjJLyUxKuCM3JhA1qTkIwLFxsumqKLaZTnql7eaCD/reSnvgA4BzW79puQVk9ghyJBpYWDnENYczqk7rpTi64NZTOjlvKc4oHMIQe3cu572HM0+TWLnUHysnnh6WBgYF87qfRn426VVWlGlxyYaUFRWybbUXCYNjAXA6mkh0MfNOm7ltT1ZVM6GtAIm9opsUpaz67E21caNPXTP7MYeYaxJtenwtAJ+0TUUq4eFjoHedA7yZm92sUOaruL/XHF5tyulnjmP+egN7HBx7B1gpYhMAtage0VHjGM+IrLL7twXlVLzgQeApUqpzAbmHboDXiKyHggA/qGUeh+IAX60Oy8daDg+MRzd8zpCC+gW6sM/fkjHVlaFt4ew8biN3uF+dAv1YW2ajbFxIXydUsDJoopG01menM+ErqHnXGakv5W7+kcx9oPdtPO0MLRTIMM6OQ4hXChlBegW5sM/Nh/HVlqJt6eFjccK6B3hz6zhsdzzeRKvfHeMGqX4aFJfh7iR/t7cdWkHxr67g3YeFoZ2DmZY5+DzWt7m0K29P//YkHKmrCm59I46Y1Zn+482wvysxIb6njWZAN0iA3nt6/0UFJfTzsuDjYdO0qej7pG+9tU+Pt9xHP92Xrx37wiHuD/mFxPq580TC7ZzKNNGr5gQnrghEV9r00q3NdcW4KWNaTwyrEudkmoueaWVhBsNkXA/K/mletAlu7iSfpF+dedF+lnJKna8zq7i/1xpVjNLRKxAXyAUyAf2Gj2Es4qI/Au4Et0LGigi8WhzDVehh8GGKKWScDLUJiIdgMnAKCdJewKXA2MBH2CTiGzGafvMwRDerTTS27G3f/TG5EHcM7RbveMJIT7MuDSa6csO4etloUeYL54W4bnRcbzw7XHe2JbB6NhgvCyu7SBVVNewLs3GzCsch2uc0RqZp8qrWJtqY9Xt/QiwejBzZQpLD+dyQ/emh9raoqwACaG+zLisA9M/T9Jy2/vhaRE+2ZvFrOGxjO8axoojucxek8I7N/WqX96yKtam5rPqjst0eVccZunBHG64JPy8lLe5JLT3Y8bgWKZ/shNfLw96RATgaZf+l0lZTOjZdOu+2XIjA5kxsjvT532Lr7cnl0QH1Q0rPXRNHx66pg9z1x3ko+9T+N34+nVcXaM4kGHjyV/2J7FzKC8s3cXb6w7VDdE1KrcV13Z9agGhvl70jvBnS3qLRspdopyYyzx7V/nipTmWCx4FHgcCOVO3p0TkBaXUK63Mx35gYu0fpdT9hr+Hbcb/IvQG1s9EpAZtuC7JRVqXov0DJRu9HV8RSVZKdUX3ZHKVUsVAsYhsRJv+TgfsB1w7Ahm1f0TEE72D93JXBbC3f1T92u1OrbdO7BnOxJ76RTZnczpR/lbiQ3yYd71eu5BmK2PjcdcPxjfHT9GrvS/tfd0fImmpzE3phcQEehPqo2WNiw9h18kitxRPW5UVYGLvSCb21i/cOd8fJ8rfypxNx3liRCwA13QN4+k1Rx3ibfrxVP3yJoSx6+RptxQPtL68LWFiYgcmJnbQMjckExWgDYpU1dSw+lA2C+4cdFbl1TJpUByTBsVpuV/tIzKo/iKCa/t34r7/fu+geCKDfIgM8iGxs+7Fju/bkbfXu290taXXdkdmIeuOFrAxbQfl1TUUV1Tz6MojvDy+m8O5rgjz8SKnuIJwPys5xRV190mkv1e9nmxWcYXTIVpX8X+uuLVkx3AG9CLwMTAabTp7lPH/RRH5fSvzsRZoJyK/sQvzNWQPE5EQ47cV6AUcc5WQUupLpVSUUirW2OhUYigdgM+B4SLiKSK+6OG0JGAr0E1E4gwZU4GldsleBRxUSqW3ppB5Jbp7nXG6nNWpBUzoFloXVqMUb27PYEov1y+65cn5TOjm/tBTa2RG+1vZnVVEaWU1Sik2pxcSH+K4Sulsy62lJWV1kJuSx4Tu7Ynws7L1hF4Pszm9kC7BDS0+QXSAld0n7ct76ryWtyXkGUM6GafKWH0ohwnG/MWmtALiwvyICnQs51mRW1Sm5RaUsGrfCa5N7ERa7um64+sOZBIf7riyLDygHdFBPqTm6HM3J2fTNcL5CjSnclt4bR8e2oV1d1/O6jsv49Wru3FFx8BmKR2A0bHBLDmUB8CSQ3mMiQs2wkNYkZxPRXUN6YXlHLOV0zfCz+34Zw1PT/c/FwDu5uJ+4CWl1JN2YYeAjSJiA36Ptm7QIpRSSkRuBOYYPascoBh4DEgA3jAm9y3Al5zxhtpwjucrpdSsRuQkichX6H1JNehl0/sAROQB9NJtD+AdpdR+u6hTaeGiAnse/DoZW3kVXhbhqeFdCPL25IM9J/l4n17jMC4+hJuNVWPZxRXMXp/GW9d2B6C0sprvfzzFMyO6nBeZiZH+jI8PZdLCA3iI0DPct1kvzrYoK8CDyw9hKzPkjoonqJ0nz46J58WNaVTXKKyeFp4dE6/lFlUwe20Kb93Qk8SoAMYnhDHpkz14WISe4X5M6eP+UFVryvvIqhS2ZJzGVlbF6Pd38cDAmLreU6MyF+/BVlqJl8XCU+N71C0WWHEgq04J1ZJ9upzZK5J4a0p/LfPzfWw5XoCttJLR//qWB66Mr+s9NSn3g83YSirw9LAw+8ZLCfK1MnvRdlJzirAIdAjx5Zmb9Iq27MJSnlq4nbl3XwnAk7/szx//t4XK6ho6hfrx/GRX/iWdyG3htW0uzq7HPZdFM3NlMosO5hDtb2XOeN2W7Rbqw9UJoVz/yT48RHhqeOe6ocfZ61K5pXcEfSL8XMb/uSLK2SBlw5NEyoDrlFKrnRwbByxTSp2b5tVPEFdDbSZnmZ+Tz5Y28scjIcFtIlelZzR90tmmja6tx0MftnpaqOaLp91+51iu+3ObT0O5a7ngOK59MZwVV6gmJiYmJj8PmmMk9P+JSCiwEO2fIQK9euxO9FCbiYmJiYlJk7jrgfSfIlIO/Am4G73UWNArv+5TSs07d1k0MTExMbmYcHuQXCn1tojMQy81rnV9na7cmSQyMTExMTExaK7ra4Xe4f9jU+eamJiYmJg4w919PO8YVpqdHfuf0RMyMTExMfmJIyIPisg+Edlv7OFERF4RkYMiskdEFhsGl1uMu6vaxqEXFThjEa5XvJmYmJiY/EQQkT7APWjDyYnAdSLSDVgF9FFK9QMOo63YtBh3h9rC0bbZnFGAXuFmYiBjR7eN4H37mz7nHKAKHbxknBdksKOfmXONWndO3FE1TXFJm4hVFWfdFKNbSP9+51+o39k1qPoTpSewWSlVAiAiG4CblFIv252zGZjUGiHu9niOAY7mZjUj0LbOTExMTEzaAquX2x8RuVdEttl97rVLaR8wQkTCDLNiE6hvxxL0yuYVrcmuuz2ed4E/iUg22i1BkYj4A9PQPm+ebU0mTExMTEzOD/YGjZ0cSxKRv6KH1oqA3UCdSQcRedL4/1Fr8uCu4vkr2mba6+iNpMVoj6SCLsBfW5MJExMTE5MLA6XUf4D/AIjICxgjWiJyB3AdMLa122jc3UBaA8wQkVfQ1qnDgDxgrVLqcGsyYGJiYmJy4SAiEUqpbBHpjHYHM0RErkEbbR5ZO//TGpq7j+cQ2iq1iYmJicnFySIRCQMqgfuVUgUi8k/AG1hl+DnbrJS6r6UCLgznDCYmJiYmFwRKqeFOws6qHwd3V7WZmJiYmJicFS6YHo+IRAJzgMHovUEVwMto52xvA/3QixlswDXGyrpqYK9dMp8opV4SkbHAK2jFWgTcqZRKFpFLgP8ClwFPKqX+ZsjuBLwPRKEdxM1VSv3DODYZeAa9vn2QUmpbS8v47rKtLFyzBxGhe+f2vHD/BP7fJ9+wblsKXp4edIoK5oX7f0Ggn6Nro8LiMma/8RVHjuciAs/99hdc2iOmSZnvb05lwfbjKGDyZZ25Y0hc3bF3vkvhlVUH+f6P4whx4q733U1HWbjjRwToHhnIC7/sh7eXh1tl/WDHCRbsPanl9o1i2mUxPPxFEqkFpQCcLq8iwNuTxb++zCHue9tPsHDfSS23vR/PX90db0/32kjvfrGNhWv3IgLdO4Xzwm+v4c3PNrN2WzIWEUKDfHnxt78gItTfIe6T//6K9TtSCA3yZdmrd7klr668e06y4EAuCsXknuFMS4ziYG4Jz25Mo6SyhpgAKy9flYC/tX79ZRaV8/iaVHJLKhGBKb3C+XW/KPdk7spkwf4sXce9I5nWP5qknGKeXXeU8uoaPC3C7JFx9Iuq7+Uz83Q5j69KPiOzdyS/7h/tfllbeG3Lq2qYNn83FdWKKqUY3609vxvqvrO/d1fuYeE3B/V90TGUF+4exaz/rCPtpHYpXlhSTqCvN4ufcdxi4iyut5d7r793v9zBwnV7EYzn9r7xeFt13HeWbeOVj77h+7n3ERLo6LH2m11pvPDeempqapg0pg/3/PLcuCP/qXFBKB7Du+gS9FLt24ywLsANwINAllKqrxHeAz32CFCqlOrvJMk3gF8aSwN/CzyFdt+Qj3bhcGOD86uAPyildohIALBdRFYppQ6g17XfDLzVmjJm5Z3mwxU7+GLO3bTz9mLmq5+z/LskhvaLZeavRuLpYeFvH6xn7mebeeTXoxziv/DOGq7sH8c/HrmRispqyioqHc5pyOGs0yzYfpxP77kSLw/hng+3MLJ7BLFhfmSeKuX7o7lEBzl375xVWMaHP6Txxf0jaeflwcxPd7B8XwY3XdpwSb8jR3KLWbD3JPNv64+Xh4V7P9vHiLhQ/n7dGW+Qf91wlACroxLLOl3OhztPsOyOy7XcL5JYfiiHm3o37Q00K7+2ju+indWLmX9fyvLvDzL9hoE8OFV7wPxg+Q7+vXATz9w7ziH+jaN6c9s1lzLrX8ublFWvvHklLDiQy/yJPXV5vzjMiC7BPL0+lT8O7cTADoEsSsrhnV2Z/H5Qx3pxPUV4dGgneoX7UVxRzaSF+xnSMYiuoY273T6SV8KC/VnMn9JXy/w8iRGxwbz63TF+O6gjI2JD2JBWwKvfH+e9m3vXl2kRHr2yC70i/LXM+XsY0jmIrqFNb6BszbW1egjvTO6Hn9WDyuoabp+/hxGxISR2aNrJXVZBMR+u2ccXf5lCO6snM99YxfIfUphz35nr+Nf5m/D3cWxAuYp705U9mpabX8SHX+3ki1fv0HFf+4Ll3x/iplG9ycw9zfd7jxPd3rn77uqaGv7yzlr+8+TNRIYFMOWJjxl9eQJdO4Y1Kfdi50IZahsDVCil3qwNUEodU0q9jraEfcIu/JBSqryJ9BRQezcHod03oJTKVkpt5Yziqk0zUym1w/h9GkgCYoz/ScaiilZTXV1DWUUVVdU1lJZXEhHiz7D+cXh66MuQ2L0DWXmnHeIVlZSzLSmdSWP1bm6rl4fTXlFDjuYWkdgxBB+rB54eFgbGhrE66SQAL311gEfG9aQxV4TVNYqyymqd38pqIgLcczKbkl9CYnQAPl4eeFqEgR2DWJOcW3dcKcXXh3KYcIlzgxfVNYqyqhqqahRllTVEOOmNNZrn2jquqCIixB9/X++646Xllbgq9MBenQj2b74j3RRbGYmRfmfK2yGANakFpNrKGBCtX0pDOwWy8miBQ9xwPyu9wv0A8LN6EB/iQ3Zx09YCUvJLSYyyq+OYQNak5CMCxRXVABRVVBPh5+VcZoR/fZlF7lkoaM21FRH8DIVUVaOoqqlxeS2cUe/5qagiIviMolRK8dXWFK69wvlURGNxmyW3XN9TAC+9v55HfjUccVGIPckn6RwVTKfIYKyeHkwY2oO121LcL/BFjFs9HhF5upHDNUAhsFsp1VJ7Ir2BHS6OvQOsFJFJwBp0r+iIccxHRHbZnfuiUmo+MANYLiKlRt4Gu5sREYkFLgV+aFYJmiAyLIC7bhjI2N+8ibfVk2H9YhnWP67eOZ+t3csvhl3iEPfHLBuhgT488a8VHErLpldCJE/cNRbfdo2/kLtF+PPamkMUlFTQztODjUey6dMhiLUHs4gMbMclUa5bmpGB7bhraDxj56zF28uDYQntGdY13K2ydgvz4x/fHsNWWom3p4WNqfn0jjwztLX9RCFhflZiQxxb9ZEB3tw1oCNj522hnaeFoV1CGBYb4pbcyNAA7rp+AGN/M1fXcWIswxJjAXjtf9/w+cYD+Ptaee9Pt7iVnrt0C/XhHz+kYyurwttD2HjcRu9wP7qF+rA2zcbYuBC+TingZBMv9xOF5STlltAv0nEY0EFmmA//2Hz8TB0fK6B3hD+zhsdyz+dJvPLdMWqU4qNJfZuQWUZSTjH9opqWqeW2/NqCbhhM+mgnx22l3JbYgcRo91x6R4b4cdfViYx99CO8vTwZ1rsjw/qc6X1vO5xJWKAPsZFBzY7bqNxQf+667nLG3j/PeG67MCyxC2u3pRAZ6s8lXVw/E9n5RUSFBdRLa0/ySbfkXuy42+P5HfBH9FzHM8Ajdr8fQ28gXSciO4y5mlYhIv8Skd0islUptQuIR8/ZhAJbRaS2X1+qlOpv96m1oD0TmKCU6oie0/m7m3L90UZPH1JKNcsAmb0ZirkLHfXvqaIy1m5NZtW//o8Nc39LaXklSzeesa325qJNeHhYuH54L4e41dU1HDiaxdTx/fnsb3fi623l7cVN68WE8ABmXBnP9Pd/4J4Pt3BJZCAeFgtvfZPM70Z3bzTuqdJK1h7MYtVDo9nwh7GUVlSzdLd7lpESwnyZMbAj0xft5d7P9tEj3A9Py5lW4ZcHs5nQw/kDe6qskrUpeayaPpD1915BaWUNSw9kuyX3TB3fw4a37qO0rJKlGw8A8NCtw1n3xv9x/ZW9+OirnW6l5y4JIT7MuDSa6csOce+Xh+kR5ounRXhudBz/25fNpAX7Ka6oxsviunlfXFnNg18n8/iwTg7zQE5lhvoy47IOTP88iXuXJtGjva7jT/ZmMWt4LGvvupzHhscye43rFnZxRTUPLj/M48Nj8be6N+remmsL4GERFv/6MtbdcwV7T57mSG6xW3JPFZezdlcaq/56GxtevZ3S8iqWbjqzhfDLLa57O03FbVRuURlrtx9l1et3s+GNeygtr2TJxgO8tXgLv5sytNG4znZYGkuRzz4eHu5/LgDcVTwT0I7fbgF8lFKBgA8w1Qi/Cm2zLRx4tQX52I+e8AdAKXU/MNZID6VUkVLqM6XUb4EPjfw4RUTCgUSlVO2beT7Q+B2i43mhlc5HSqnPmlsApdRcpdQApdSAeyeNdDi+aU8aMRFBhAb54uXpwVVXdGfnIT2CuGT9PtZvT+GVB69zemNGhgUQGRZAYvcOAIwf3J0DqVlu5WvSZZ357L7hfHj3EIJ8vIgJ9iG9oIQb3/iGsXPWklVYxsS3viHndFn9/B7NJSbEh1A/b7w8LFzVM4qdPzoOFbliYt8oFt1+GR/ckkhQOy+6BOsWcFWNYnVyHr9w8XLadNxGTGA7Qn2teHlYGNctjF2Z7rUBNu09pus4sLaOu7Hz8Il651x75SWs/OHs73me2DOcRZN788GNPQny9qRLUDviQ3yYd30PFk7uzbXdwugc5HwYr7K6hoe+Tua67mGMiw91X2bvSBZN7ccHE/vUyfz8YA7jEnQa13QNY29WkWuZKw5xXY/2jOvavDmHll5bewLbeTKwUxDfpLl3T206kE5M+wBCA3z0tb08jp3J+hmoqq5h9Y5UfjEwodlxm5S77zgx4YFn7qlBXVm8fj/pOae48dEPGfvAf8jKP83Exz8ix1ZfiUaG+nPSbug8K7+IiBA/t+Re7LireP4JvKSUWlA7v6KUKldKfYru7byulPoWeA64ugX5WAu0E5Hf2IX5AojIMBEJMX5bgV5oo6WuKACCRKS2ST8OPWfjEmNxw3+AJKWUW72j5hLdPpDdhzMoLa9EKcXmvcdIiAnjm51HmbfkB/792M34eDuOxwOEh/gTHRZI6ok8ADbvPeb2BGVekZ4Oy7CVsirpJL9M7Mh3j45jzcwxrJk5hsjAdiz6v+GEN5i/iQ5qx+50G6UV1Tq/qbkkhLs3HAOQV6KHlTIKy1h9JJcJl+iX0aZjBcSF+BAV4O00XnSAN7tPnqa00pB73EZ8ExPtdXHbB7L7SKZDHadlnnm5rduWQnwH91/u7pJXoqcNM06Xszq1gAndQuvCapTize0ZTOnl+EJWSjF7fRrxwT7cmejeajanMlPymNC9PRF+Vrae0Ip6c3ohXYIdlZ1SitlrUogP8eHOSzs0S6aW27Jrm19SQWGZNvtVVlnNpuZc2zB/dh/NPnNtk06Q0EEPwW46kE5cVDBRTlYqNhW3abkB7E62u6f2HWfcoK58N/c+1vxzOmv+OZ3I0AAWvfgrwoPrK5W+CVEcO1lAevYpKqqqWf79IUZfHu+W3Isdd1e19QNcDU5mopcaAxwEnC/xaASllBKRG4E5IvIokAMUo4fxEoA3DOVgAb5E90zAcY7nK6XULBG5B737tgatiO4GEJEoYBt64UGN4eSol1G+XwN77dJ7Qim1XERuQtuoCwe+FJFdSqlmK9fE7h24ekgPJv7xPTw8LPSMi2DKuESun/kOFZXVTP/Lp/q8btE8839Xk51/mqfe+Jq5T+qloU9OH8sf//EFlVU1dIoM4vn7XXb66vHgp9uxlVTi6SHMvrYPQT7OlRtAdmEZTy3dw9zbB5HYMYSre0Uz8a1v8LAIPaODmHJ5Z7fL++CyJGyllXhZLDw1NoGgdlruCicTz9lF5cxeeYS3bu5DYnQg47u1Z9KHO7XcCH+m9HVvqW9it2iuHtydiY99gIeH0DM2kilX9eORf3xJamY+FhE6tA+sW9GWnV/EU299zdzHJwLwh9e+YMuBH7GdLmXUfW/ywJRhTBrT+BxJXXm/TsZWXoWXRXhqeBeCvD35YM9JPt6nhwnHxYdw8yXttdziCmavT+Ota7uz42QRSw/n0T3Uh5s+3QfAQ1d0ZGSX4KZlLj+ErcyQOSqeoHaePDsmnhc3plFdo7B6Wnh2TLxRxxXMXpvCWzf0ZEfmaZYeyqV7mC83/W+3ljmkMyPdnEtr6bXNKa7k8a8OUaMUNQqu6d6eUfHuNaAS4yO5+vI4Jv75M31fdG7PlBH6tbPcyTBbdkExT723gbkPTWg0bpNyu0Vz9RXdmPj4R3hYLPSMDWfKWNf3RHZ+EU/NXcXcWTfh6WHhqbvGMOOFz6ipUdw8ujfdOrV3S+7Fjrhj601EdqMVz/VKqQq7cG/gCyBcKdVfRG4BXlZKub84/yKkZu9/WmVAr8WY/njOOW3mj8ezjXY+uLnX5WwjvR3nOs85beSPx3Lpfa2e+KlZ84Lb7xzL2CfO0UST+7h7Vz2I7mmki8gqdI8kHD2M5ceZOZdLgWbPj5iYmJiY/Hxw1zr1esP96UxgAHohwEm0n57XlFK1+2RmnaN8mpiYmJhcJLjdjzaUyx/PYV5MTExMTH4GXCiWC0xMTExMfia4a7nACz3PczPQEXBYo6mUcm7/xMTExMTExA53h9rmAP+HXsG2Dm052sTExMTkIkNEHgTuQVvSe1sp9ZqIhKI348cCacAUpZT7O8ob4K7imQzMUkq1xCqBiYmJicm55CyZwhGRPmilMwjdwfhKRL40wtYYbmdmAbPQ+yxbhLuKR4A9LRXyc0Nt+Kats3B+qapqE7Fq81m14+oebbWfpo3quK328ajUtPMvNC///MsEuLTFHqTPBT3Rbq1LAERkA3AT8EtglHHOe8B6WqF43F1c8DZwa0uFmJiYmJhcGNgbNDY+99od3geMEJEwEfFF79HsBEQqpTJBu5EBWjWn725zJgv4lYisA1ahvYDao5RSb7QmIyYmJiYm5x6l1FxgrotjSSLyV/R7vgjYjXaUeVZxV/G8Znx3BhxNL2sL4KbiMTExMfmJo5T6D9poMiLyApAOZIlItFIqU0SiAfd8lbjAraE2pZSlic+F4eTBxMTExKRViEiE8d0ZvYXmf8BS4A7jlDuAz1sjo41mSk1MTExMLlAWiUgYUAncr5QqEJGXgE9FZDpwHL3SucW4VDwi0gtIUUqVG78bRSl1oDUZMTExMTFpe5RSw52E5aGdc54VGuvx7AMGA1uM367MbotxzBxuMzExMTFpksYUz2jggN3vc4qIRKItJAxGO2+rAF4GvkYv5+6HVnI24BqlVJGIVAN77ZL5xNjgNAb4G2AFtgPTlVJVhpxR6MUSXkCuUmqkEe6wW9cIfwW43shPCnCXUsrWkjJ+sCuTBfuzUMDk3pFM6x9NUk4xz647Snl1DZ4WYfbIOPpFOfrScxb3QpUJ8MGekyw4kItCMblnONMSoziYW8KzG9MoqawhJsDKy1cl4G91bK9c9eFu/Lw8sAh4WoQFk3q7L3fHCRbsPanz3DeKaZfF8PAXSaQWlAJwuryKAG9PFv/6snrxUvNLePjLg3X/00+V8buhXZh2WYx7cltRz4XlVTy9JoUjeSWICM+NTaB/tHN/ik+uS2VDmo1QHy+WTu0DgK2sij+sSuHE6XJiArz5+/gEgrz1oz13RwaLknLxEOGJKztzZecghzQbi++0rC2sY4D3tp9g4b6TCNC9vR/PX90db0/3dnV8sOUYC3amo5Ri8qUdmXZFLP/ckMzCXemE+FoBeGh0N0Z2dfT06iyuKy6EOr7YcVlypdQGZ7/PBYZ30SXAe0qp24ywLsANaBtxWUqpvkZ4D/TYI0CpUqp/g7Qs6A1OY5VSh0Xkz+jJsP+ISDDwb7TiOm43ieZ0t65S6gh6WeHjSqkqY5nh47Rg49SRvBIW7M9i/pS+eHlYuPfzJEbEBvPqd8f47aCOjIgNYUNaAa9+f5z3bu7tVtzY4MbdBreFzLq4B3KZP7GnjvvFYUZ0Cebp9an8cWgnBnYIZFFSDu/syuT3gzo6TePdG3oQ0oi3VKdyc4tZsPck82/rr+V+to8RcaH8/boz3ib/uuEoAU6UXVyob92LsrpGMWruD4zt6p53zNbUM8CLG9O4skswr03oQUV1DWVVNS5l3dSjPb/qE8GsNal1YfN2ZjI4JpB7Lovm7R2ZzNuRyR+GdCI5v5QVyfksm9qH7OJKpi87xPJb++Jhqe8HzFV8p2VtRR1nnS7nw50nWHbH5bTz8mDmF0ksP5TDTb0jm67j7NMs2JnO/LsH4+Uh3PvxdkZ00wpm2qAu3D0krtlxY0P9nJ7f1nX8c6DZ1qlFxFNEfBt+WpmPMUCFUurN2gCl1DGl1OtANHDCLvyQUqq8kbTCgHKl1GHj/ypgovH7NuAzpdRxI63aJYF1u3WNnlHtbl2UUitre0vAZrSR1GaTkl9KYlQAPl4eeFqEgTGBrEnJRwSKK6oBKKqoJsLP8WXrKu6FKBMgxVZGYqTfmbgdAliTWkCqrYwBRkt+aKdAVh5tsakn53LzS0iMtstzxyDWJOfWHVdK8bUT98wN2XzcRudgH2ICHWzhupDb8nouqqhiW0YhE3vpPFk9LAQ20hIe0CHAoaW8NtXGjT20kryxRxhrUm06PK2AX3QNxephoWOgN52DvNmbXeyQpqv4zsvaujqurlGUVdVQVaMoq6whws/qUlY9ubnFJMYEGXItDOwSypqD7q3obW7ctq7jFmGxuP+5AHArFyISKCL/FJEMoAw47eTTGnoDO1wcewd4TEQ2ichzhkO6WnxEZJfd5xYgF/ASkQHGOZPQO28BugMhIrJeRLaLyDQj3NVu3YbcDaxoSQG7hfmwLaMQW2klpZXVbDxWQGZRBbOGx/LKd8cY89/tvPJtGg8NcfQa7iruhSgToFuoD9syT2Mrq9Jxj9vILKqgW6gPa9NsAHydUsBJF+kJMOOLw0xasJ9PD7i/XaBbmB/b0u3ynJpP5ukzbZTtJwoJ87MSG9J4r235oRwm9HAcrnEtt+X1/OOpckLbefLk6hRu/t9uZq9JoaSy2m3ZAHmllYQbL/BwPyv5pXpAILu4kij/My/2SD8rWcWOde4qvvOytryOIwO8uWtAR8bO28LItzbj7+3BsNgQt8rYLcKfbccLsJVUaLnJOWQWlgHw8bbj3Dj3O55cto9TTvLeWFx3OZ91/HPA3UHGt4DrgHnoeZ9zap1aRP4FXInuBQ0UkXhgPHAVsFVEhiilknAy1GbEnwrMERFvYCVndt56ApejV2f4AJtEZLM7u3VF5Ekj7CMXeb4XuBfgjalDuGdY93rHE0J9mXFZB6Z/noSvl4Ue7f3wtAif7M1i1vBYxncNY8WRXGavSeGdm3q5Fbcp2kImQEKIDzMujWb6skM6bpgvnhbhudFxvPDtcd7YlsHo2GC8XKT30U09ifCzkldSyYwvDhEf7MOADs7nPOrJDfNlxsCOTF+0F18vD3qE18/zlwezm1QoFdU1rEvJY+aVsW6VFVpXz9U1igM5xTwxMo7EqABe2JjKvO0n+P3gzm7Ld4VyshzIvSvomtbU8amyStam5LFq+kACvD2Z+cVBlh7I5oZeTVtfSWjvz4whcUz/eBu+Xp70iAzA0yJMvbwTvxmegAj8v/XJvLz6EM9f38etuGeDc1HHPwfcVTxXAzOVUvPOUT72c2Y4DKXU/SLSHthm/C8CPgM+E5EadI8kyVViSqlNwHAAERmP7umA3oGbq5QqBopFZCOQCBx2sVsX4/8daMU7Vilnt1p9MxTV/7zT6TkTe0cy0RjPnvP9caL8rczZdJwnRsQCcE3XMJ5ec9RpmZzFdYe2kAkwsWc4E3vqF9CczelE+VuJD/Fh3vU9AEizlbHx+CmncWuHX8J8vRgbF8Ke7CK3FA/AxL5RTOwbpeV+m1aX56oaxerkPBb86tJG43+TWkCvSH/auzkEVCe3hfUc6W8l0t+bRGPRwfiEMOZtP+FwXmOE+XiRU1xBuJ+VnOIKQo25sUh/r3q9yqziCqdDW67iuyxrC+t403EbMYHtCDUWAozrFsauzEK3FA/AxEs7MvFSPdI9Z+1hogLb0d7fu+745Es78pv5zgdOnMVtDue7ji923B3wK8buRXwOWAu0E5Hf2IX5AojIMBEJMX5bgV7AscYSs1s04I1eCFA7d/Q5MLx2ngq4AkOBuditi4hcY6RxQ63F1paSV6K71xmny1mdkseE7u2J8LOy9UQhAJvTC+kS7PyBcBb3QpXpEDe1gAndQuvCapTize0ZTOnl2DIuqayumxcpqazm+x9P0S3U/SnEvBL9EsgoLGP1kVwmXKJlbDpWQFyID1EB3o1FZ/mhpntFzuW2rJ7D/axE+VvrVoRtTj9FQmjTCzjsGR0bzJJDeQAsOZTHmLhgIzyEFcn5VFTXkF5YzjFbOX0jHCfUXcV3XdaW1XF0gDe7T56mtLIapRSbj9uIb0ZZ84r1kF7GqVJWH8pmQu9ocuyG+VYfyqJbuL/bcZvD+a7jix13ezyvAr8VkZVKKddLblqIUkqJyI3o4bFHgRy0snsMSADeMFa+WYAvgUVGVB8R2WWX1FdKqVnAH0XkOuP8N5RSaw05SSLyFdrFQw0wTym1z4jrsFvXCP8n4A2s0llgs1KqRXbMH1x+CFtZFV4W4alR8QS18+TZMfG8uDGN6hqF1dPCs2PiAcguqmD22hTeuqGny7gXqkyAB79OxlZuxB3ehSBvTz7Yc5KP9+k5m3HxIdx8iVZk2cUVzF6fxlvXdievtJLff5UM6Bb0td3CGO5keapLucuSsJVW4mWx8NTYBILa6ZblCicT3tlF5cxeeYS3btZDM6WV1Xx/zMYzV3VzSLdJua2o5ydHxvHoyiNUVis6Bnrz/FVdXcp5ZFUKWzL0/Nno93fxwMAY7rksmpkrk1l0MIdofytzxuv43UJ9uDohlOs/2YeHCE8N71y32mr2ulRu6R1Bnwg/l/HPdh0nRgcyvlt7Jn24Ew+L0DPCnyl93VcADy7cZcgVnrqmJ0E+Xjy2ZA8Hs04jAjFBPjwzQa8azD5dxuwv9vPWrZe7jHsh1/HFjrgYOap/kt7LMgU9t7MO59apW+yb4WLD1VDbRUtb+Yrxad5wyVmhso3K+nOqYwDf1i6UbQFt5I/H46EPWz0tVLPxFbffOZYRf2zzaSh3m7CT0D0ET2Cck+OKVjgFMjExMTH5+eCW4lFKud6dZWJiYmJi0gwujN1EJiYmJiY/GxqzTj0B+FYpVWj8bhSl1PKzmjMTExMTk4uSxobavuCMdeov0PM4rialTOvUJiYmJm2F5af1+m1M8cQBmXa/TUxMTEwuckRkJjAD3aHYC9wFXILeD9kObcHlt0qpLS2V0Zh16mPOfpuYmJiYXJyISAzwe6CXUqpURD4FpqINLD+rlFphTL28DIxqqZxmOYQQEU+gM1rr1cP0QGqHVxv52bA2z8zLWaPinJruc01blLet9vG0FaXNM6Z5tpCYDuddpmqrvVIXHp7ozfmVaAsyGejeT6BxPMgIa5WAJhERL+D/of3auLI58tMaZDQxMTH5GWJv0NhgrmFrEqXUCRH5G3AcKAVWKqVWisiPwNfGMQswtDV5cHc59dNoI5nT0QsMHkCP+60B0tAeOk1MTExMLnCUUnOVUgPsPnNrjxl2MX+JntfvAPiJyO3Ab9CGojsBMzEMKrcUdxXPFOAZ4FPj/xal1PtKqfHAt0ZGTUxMTEx+2lwFpCqlcpRSlWivAEPRo12fGecsQHtrbjHuKp5OaNcB1WhHcPbemz7CzqWBiYmJiclPluPAYMOztKB9lyWh53RGGueMAY60Roi7s+CZQLDxOxUYAaw2/ie0JgMmJiYmJhcGSqkfRGQh2iN0FbAT7WdsJ/APY4FZGfXniJqNu4pnPdqx2jLgbeBvItIVKAduwfBdY2JiYmLy00Yp9SfgTw2Cv0V7bz4ruKt4ngTaG5l6zeiCTUK7j34d+PPZypCJiYmJSTPx+GmZ3WxS8RhLqRPQQ2wAKKXmAHNaIlBEIo24g4ECtI+fl4Gv0b2pfuiVczbgGqVUkYhUo3fQ1vKJUuolEXkAeMjIX7hSKteQ8UvgL2hXDlXAQ0qpb41jDwL3GDLeVkq9ZoSHAvOBWPRKvSl2zuBqPZMeAJ5RSv2tJWX/YMcJFuw9iQIm941i2mUxPPxFUp33ydPlVQR4e7L415c5xL1q3hb8vDywWARPizTpwrlO5tbjLNidoWUmdmDawM4AfLjtRz7ekY6HRRiZEMYjox2dn7mKe67LClBdo5j80U4i/b1546be7st1kueHl+wlNV87jz1dVkVAO08W332FQ9xvjubx4urDVNcoJiV24J4hse7L3ZXJgv1ZWm7vSKb1jyYpp5hn1x2lvLoGT4swe2Qc/aIcXXgXllfx9JoUjuSVICI8NzaB/tHOXX0/uS6VDWk2Qn28WDpVO7CzlVXxh1UpnDhdTkyAN38fn0CQt3605+7IYFFSLh4iPHFlZ6504lSvsfhtLdee9zceZsEPKSgFkwfHc8eIHryybBfr9mfg5WmhU5g/L0wdRKBP/f1dqdmFPPzBprr/P+YV8btr+nDHiB4uZdnTmmfoqn9/h5+3BxYxnts7WzUnf9HgTo+nGu2aegKt3DRk9JSWAO8ppW4zwroANwAPAllKqb5GeA+0N1CAUqVUfydJfoe2I7e+QfgaYKnh2bQfejXeJSLSB610BqEV3lci8qVS6ggwC1hjKLRZxn97H0NzgBUtLfuR3GIW7D3J/Nv64+Vh4d7P9jEiLpS/X9ez7py/bjhKgNX1dqh3p/QjpBm+2o/kFLFgdwbz7xiIl4dw7/xdjEhoT9bpMtYeyWHJ3Vdg9bSQV+y4AdRV3Fg33FCfjbJ+sPMECaG+FBlusFtT3r/f2PeM3DVHCPB2lFtdo3hu5SHmTb2UyABvbnl3K6O7tadre+eulOvJzSthwf4s5k/pq8v7eRIjYoN59btj/HZQR0bEhrAhrYBXvz/Oezc7KtEXN6ZxZZdgXpvQg4rqGsqqXDv5valHe37VJ4JZa+ragczbmcngmEDuuSyat3dkMm9HJn8Y0onk/FJWJOezbGofsosrmb7sEMtv7VvnIbOp+BeC3FoOZ9pY8EMKnz44Di8PC/e8vZGRPTswtHsUMyf0w9PDwt++2M3cNUk8cl1ivbhxEYEs/sPVAFTX1DDqz8u4qk9Hl3VsT2ueoVrevfUyQnzbaHP3BUqT/TPD1fURIPIsyBsDVCil3rRL/5hS6nUgGjhhF35IKVXuJA37vO1USqU5CS9SZ1yr+qF33QL0RLuuLlFKVQEbgJuMY78E3jN+vwfcWJue4Zb7KLDfvWI6kpJfQmJ0AD5eHnhahIEdg1iTnGufZ7524jq4NaTkFZPYIciQaWFg5xDWHM7hk50nmDEkFqunvvxhfo4Phau4bsltZVlPni5nw9F8JvaNOivlrSf3YBYTejmmuzezkM4hPnQK9sHqYeEXvSJZeyTX4Tzn5S0lMcquvDGBrEnJRwSKDcVZVFFNhJ9jo6GoooptGYVM7KXrwuphIbCRVv+ADgEOvYK1qTZu7BEGwI09wliTatPhaQX8omsoVg8LHQO96Rzkzd7sYoc0XcW/EOTWcjT7NImdw/CxeuLpYWFgQjir96YzrEcUnsYwU2KXMLJsJS7TANh8JJtOYX7EhPo1el4trXmGTFzj7sDgk8DTItK3yTMbpzd6tYQz3gEeE5FNIvKciNj3W31EZJfd55amBInITSJyEPgSuNsI3geMEJEwEfFF9+Jqm1iRSqlMAOM7wkjHD93zebZ5Ra1PtzA/tqUXYiutpLSymo2p+WSePqNXt58oJMzPSmyIj/PyADMW7WXShzv5dE+m03McZLb3Z9uPBWdkpuSSWVhGWn4J23+0cct7W5n20Xb2Zha6Hfd8lPWl9Sk8MiIOSzMd9DaV5+0/2rRcJ722rNNlRAWcsQQVFeBN9ulG2z1n5Ib5sC3DrrzHCsgsqmDW8Fhe+e4YY/67nVe+TeOhIV0c4v54qpzQdp48uTqFm/+3m9lrUiipdL+XB5BXWkm48eIL97OSX6oHCrKLK4nyP/NCjPSzkuWkZe4q/oUkt1tUENuO5lBQXE5pRRUbkzI52UDJfLYlleE9oxvN8/Kdx7n2Usfr4FJuK54hABGYMX8Xk/67hU93nXB6zs+RxvzxjAB2KKWKgKeAMGCXiJwAsjjTiwBAKdXswUsR+RdwJboXNFBE4oHx6E1MW0VkiFIqCddDbS5RSi0GFhvl+AtwlVIqSUT+CqwCioDd6DmgxngWmGPMNTVWljozFG/8ahj3DL+k3vGEMF9mDOzI9EV78fXyoEe4H552b9YvD2YzoUe4y/Q/mppIhL83eSUVzFi4j/hQXwZ0dBw3ryezvR8zBscy/ZOdWmZEAJ4WobpGUVhWySfTBrA3s5CHl+xl5X1DsS+fq7ju0Jqyrj+aR6ivld6RAWz50eaWPHfz/GVSFhN6Ou+4u+2w3pncUF9mXNaB6Z8n4etloUd7Xd5P9mYxa3gs47uGseJILrPXpPDOTb3qxa2uURzIKeaJkXEkRgXwwsZU5m0/we8Huz+f5grlpFDN1OUXjNyEyEBmjOnJ9LfW4+vtxSUdgvGwm1B/c/UBPCzC9Ze5VioVVdWs3X+Cmdf2c19uK54hgI9uH0BEgDd5xRXM+GSnfm47h7iQ9vOhsTmedcAQtD+efcantezHbrOpUup+EWkPbDP+F6F3x34mIjXoHklSawQqpTaKSIKItFdK5Sql/oNh7kFEXgDSjVOzRCRaKZUpItFAthF+BTBJRF5G72WqEZEypdQ/G8iZi17vTvVbM5y+xyb2jaobPprzbVpdq7CqRrE6Oa/RBQMR/tpEXpivlbFdw9hz8nSTigdgYmIHJiZqg4tzNiQTFdCOo3nFjOsegYjQr0MQFhEKSisJbTAO7Syuu7S0rDtOFLIuJY+NqfmUV9VQXFHNo8sP8vKES5ye7055tdwaVh/Kdjm5GxXQjpOnz/SOTp4uJyLAlVlCJ3J7RzKxt1Zqc74/TpS/lTmbjvPEiFgArukaxtNrjjrEi/S3EunvTaKx6GB8QhjztjevZRzm40VOcQXhflZyiisINeYBI/29OFl0pqeRVVxBhJMhIVfxLzS5k66IZ9IV8QDMWb6HyCDdY16yNZX1BzL4732jHF789nxz8CS9OobQvhn3MbTuGaq9h8L8rIztHs6ezEJT8dD4UFvdFVRK3dXUx015a4F2IvIbuzBfABEZZtgJQkSsQC+gRe4YRKSrsZABEbkMsAJ5xv/aIbTOwM2c2YO0FG0WAuP7c6Psw5VSsUqpWOA14IWGSsdd8kr0w5hRWMbqI7lMuES3+jcdKyAuxIcoFy+6kspqiiuq6n5/f6yAbmFNT/IDdZOeGafKWH0ohwm9IhnTPZwfjuUDkJZfQmV1jdNFC87inuuyPjw8jnX3XsHqGYN49dpLuKJTsNtKp7E8b0orIC7Mj6hA5y+dPtEBHMsvId1WSkV1DSsOZDG6a/tmlFcPE2WcLmd1Sh4Turcnws/K1hN6CGZzeiFdgh1lh/tZifK31q3225x+ioRQ50OQrhgdG8ySQ3kALDmUx5i4YCM8hBXJ+VRU15BeWM4xWzl9IxznNlzFv9Dk5hkNg4yCYlbtSefaS7vwzcFM5q07yL/vvhIfa+Nrpb7ceYxrL21+T7Klz1BJRTXF5VV1v79Py6dbeNOLVX4OnFf7/cYqsxuBOSLyKJADFKPnUBKANwyFYUHPzSwyovqIyC67pL5SSs0Skd8DjwJRwB4RWa6UmoHuVU0zzHqXArfYLTZYJCJh6BVz99stmX4J+FREpqPNRkw+2+V/cFkSttJKvCwWnhqbQFA7faOucDLRnl1UzuyVR3jr5j7kFVfw+6W641elFNdeEs7wuFD3ZC7ec0bm+B4EtfPi5n4deGp5EjfM24yXh4UXru2FiJB9upzZK5J4a0p/l3HPdVlbi6s8rziQ5aA47cvrabHw5Pge3DN/JzUKbuoX3ayXxIPLD2Erq8LLIjw1Kp6gdp48OyaeFzemUV2jsHpaeHZMvFHeCmavTeGtG/QqvydHxvHoyiNUVis6Bnrz/FVdXcp5ZFUKWzJOYyurYvT7u3hgYAz3XBbNzJXJLDqYQ7S/lTnjdfxuoT5cnRDK9Z/sw0OEp4Z3rltZNntdKrf0jqBPhJ/L+BeC3Hp1/N532Eoq9NL0my8nyNfKc5/toKKqmulvbQD0AoNnJg0g+1QpT326lbn3jACgtKKK7w9n8eykAW5f0zq5LXyG8koq+P2iPYDx3PaKZHh8WLPlX4yIcjYgCxhDXX9Gr+ZqEqXU+2cxXz9pXA21nXNMfzznnuLGV02dM35mvmKka/x5l6ly3FvFeLbxuOvfrZ56q9n0mtvvHMuQh87HVF+jNNXjedrNdBRgKh4TExMTkyZpSvGMxpj4NzExMTG5QLH8tPxwNqV4SpVSjju/TExMTExMWshPy7KciYmJiclPHlPxmJiYmJicV1wOtSmlTKVkYmJiYnLWMZWLiYmJiUkdIjJTRPaLyD4R+Z+ItDPCfycih4xjL7dGxnndQPqzodQ9Y5oXjdy2ovL8722Rjh3Ou0wAVWBrE7nS3327ZmcTteHbNpH7c0dEYoDfA72UUqUi8ikwVUSOoS3491NKlddagGkpZo/HxMTExMQeT7S1GE+0SbMM4DfAS7WuapRS2Y3EbxJT8ZiYmJj8jBCRe0Vkm93n3tpjSqkTwN/QZsMygVNKqZVAd2C4iPwgIhtEZGBr8mAOtZmYmJj8jLC3pN8Qw1DzL4E4wAYsEJHb0boiBBgMDETbtYxXrmyuNYHZ4zExMTExqeUqIFUplaOUqkS7qRmKdh/zmdJsAWoA9823N8Ds8ZiYmJj81PE4ayZzjgODDQ/NpcBYtNm0PcAYYL2IdEe7mmmxVVVT8ZiYmJiYAKCU+kFEFgI70N6Zd6KH5RTwjojsAyqAO1o6zAam4jExMTExsUMp9SfgT04O3X62ZJx3xSMikcAc9CRVAVp7vgx8DbwN9EN7P7UB1yilikSkGthrl8wnSqmXROQjYADaqdsW4P+McUlEZBTaY6gXkKuUGmlshNoIeKPLvtCoZERkPtDDSD8YsCml+ouIFzAPuMyI875S6sWWlP2DPSdZcCAXhWJyz3CmJUZxMLeEZzemUVJZQ0yAlZevSsDf6thtfm/3SRYm5SAI3cN8eH50HN6ezqfonlyXyoY0G6E+Xiydqp2r2cqq+MOqFE6cLicmwJu/j08gyFtf/rk7MliUlIuHCE9c2ZkrOzu61G4sflvJdFrHuzJZsD8LBUzuHcm0/tEk5RTz7LqjlFfXaCdiI+PoZ7iarlfHOzNYeCAbAbqH+fL8VV1d1nFD3v/2CAu2pKGUYvKgOO4Y3o1/fL2ftQcysIgQ6u/Ni1MGEBFY37topq2EWfO3kXu6DBGYckUc067s5pbMD7YeZ8HuDF3WxA5MG6i9a3647Uc+3pGOh0UYmRDGI6Prp5eaV8zDn5/xZJ9uK+V3w+Pr4jfFu1/uYOG6vfpe7NyeF+4bj7fh/fOdZdt45aNv+H7ufYQEOnpSffLNlazfcZTQQF+W/W1ao3La6p66UO7li5nzurjA8C66BNiolIpXSl0OTAU6Ag8CWUqpvkqpPsB0tEIBbSW7v93nJSP8I+ASoC/gA8ww5AQD/wZuUEr15ow30XJgjFIqEegPXCMigwGUUrfUpo/2fPqZEWcy4K2U6gtcDvyfiMQ2t+xH8kpYcCCX+RN7snhKH9YfO0WarYyn16fy8OCOfH5LH8bGhfDOrkyHuFlFFXy4N4sFk3qzdGofqpVieXK+S1k39WjP3Ou61wubtzOTwTGBfHVbPwbHBDJvh5aTnF/KiuR8lk3tw9zruvOXb45RXePYg3YVvy1lNuRIXgkL9mcxf0pfFt+ayPrUAtJspbz63TF+O6gji29N5IErOvHq98cd4mYVlfPhnpMsuKUvS3/Vn2oFy4+4N4R9+OQpFmxJ49MHRrPkoatYfzCTtNzTTB/Znc9njmPxQ1cxqmc0/16d5BDXwyI8el1fvnxkPPMfGM3Hm46SnFXYpMwjOUUs2J3B/DsGsvjuQaxPziUtv4QfjuWz9kgOS+6+gmUzBnPXoC4OcePC/Fh89xUsvvsKFt45iHZeHoztHu5WWbPyi/jwq50sfOFXLPvbNGpqalj+/SEAMnNP8/3e40S3d1Tqtdw4shdzH7/JLVltdU9dCPfyxc75XtU2BqhQSr1ZG6CUOqaUeh2IBk7YhR+q3azkCqXUcmOVhUL3eDoah25Dr8A4bpyXbXwrpVSRcY6X8al3lxjKcQrwv1oxgJ+xmcoH3UNr+s3QgBRbGYmRfvh4eeBpEQZ2CGBNagGptjIGROsHdWinQFYeLXAav7pGUVZVQ5XxHeHn2g31gA4BDq2ptak2buyh3e7e2COMNak2HZ5WwC+6hmL1sNAx0JvOQd7szXb0hOEqflvKbEhKfimJUQFn6jgmkDUp+YhAcUU1AEUV1S7rrn4dVxPh556H06PZp0nsHIqP1RNPDwsD48JZvS8DfztX4aUVVbof34CIQB96x4QA4OftRUJEAFmnSpuUmZJXTGKHIKOsFgZ2DmHN4Rw+2XmCGUNisRo9tbAmyrD5WD6dg32ICXLsnbiiurqGsooqqqprKC2vIiJEuwh/6f31PPKr4YizghoM7NmRYL92bslpq3vqQriXL3bOt+LpjZ60csY7wGMisklEnhMR+/EBHxHZZfe5xT6iMRz2a+ArI6g7ECIi60Vku4hMszvXQ0R2AdnAKqXUDw3yMRzd8zpi/F8IFKM3Ux0H/qaUct3dcEG3UB+2ZWqf9aWV1Ww8biOzqIJuoT6sTbMB8HVKASeLHN1IR/pbuat/FGM/2M3I93bhb/VgWCfH7nxj5JVWEm68hML9rOSX6s5kdnElUf5nXk6Rflayih3z4Cr+hSSzW5gP2zIKsZVW6jo+VkBmUQWzhsfyynfHGPPf7bzybRoPDXHsBUT6e3PXpR0Y++4ORv5nG/5WT4Z1Dm6yjADdIgPZlppLQXE5pRVVbDx0kpOG8njtq32MfmE5y3b+yO/H9W40nRP5xSSdsJHYObRpme392fZjwZmypuSSWVhGWn4J23+0cct7W5n20Xb2ZjbeRlp+IIsJvSLdKidAZKg/d113OWPvn8eI++YS4OvNsMQurN2WQmSoP5d0ca/n1FLa4j5uS7kXK226j0dE/iUiu0Vkq1JqFxAPvAKEAltFpKdxasOhtvkNkvo3evjuG+O/J3pY7FrgamC2sQQQpVS1MZzWERgkIn0apHUrZ3o7AIOAaqADelPVH0TEwSG8/W7gt78/0vAwCSE+zLg0munLDnHvl4fpEeaLp0V4bnQc/9uXzaQF+ymuqMbL4thaPFVexdpUG6tu78f6aYmUVtaw9PDZ8Q/vbF3KuXbIfq5kJoT6MuOyDkz/PIl7lybRo70fnhbhk71ZzBoey9q7Luex4bHMXpPiEPdUWRVrU/NZdcdlrL/7ckorq1l6MMc9uZGBzBjZnenzvuWed77jkuggPIzr+NA1fVj3xASuv7QTH33vKLeW4vIqfv/hZmbdkFivp+RSZns/ZgyOZfonO7l3/i56RATgaRGqaxSFZZV8Mm0Aj4zuysNL9uJq8VFFdQ3rknO5+hL3zW6dKipj7fajrHr9bja8cQ+l5ZUs2XiAtxZv4XdThrqdztmmLe7jtpT7U+d8K5796El6AJRS96PXiYcb/4uUUp8ppX4LfAhMaCpBEfmTEf9hu+B04CulVLFSKhe9oCDRPp5SygasB66xS8sTuBmwV2y3GWlVGkN236EXNNRDKTVXKTVAKTXgnqHOJ4cn9gxn0eTefHBjT4K8PekS1I74EB/mXd+DhZN7c223MDoHOQ5DbEovJCbQm1AfL7w8LIyLD2HXySInElwT5uNFjtESyymuINRHv9wi/b3q9bKyiiucDjG5in+hyZzYO5JFU/vxwcQ+dXX8+cEcxiXoXsQ1XcPYm+VYd5t+PFW/jhPC2HXydJPyapk0KI7PHhzLh/eNJMjXSpf2/vWOX9u/Eyv3nXAat7K6hgc/2MT1/Tsxvk+M2zInJnZg0V2D+OD2ywny8aRLqC9RAd6M6x6BiNCvQxAWEQpctK6/ScmjV2QA7f283Za5ad9xYsIDCQ30xcvTg6sGdWXx+v2k55zixkc/ZOwD/yEr/zQTH/+IHNvZd17cFvdUW8q9WDnfimct0E5EfmMX5gsgIsMMcw2IiBXoBRxrLDERmYHu0dyqlKqxO/Q52q6Qp7ER6gogSUTCjYUHiIgPepfuQbt4VwEHlVLpdmHHgTGi8UOvxrOP4zZ5JfoFkHG6nNWpBUzoFloXVqMUb27PYEovx6GKaH8ru7OKKK2sRinF5vRC4kPcH5MHGB0bzJJDeQAsOZTHmLhgIzyEFcn5VFTXkF5YzjFbOX0j/NyOf6HJrFfHKXlM6N6eCD8rW0/oIafN6YV0CXZU7tEBVnaftK/jU82q47wibRk8o6CEVftOcG1iJ9JyzyiudQcyiQ93nHRXSvHUwu3ERwRy54juDscblWm8yDJOlbH6UA4TekUypns4PxzTI8Fp+SVUVtcQ4uIltzzpZLOG2QCiwwLYnZxJaXmlrqd9xxk3qCvfzb2PNf+czpp/TicyNIBFL/6K8GDHa9pa2uKeaku5FyvSij1ALRMoEo1eTn0FkIOeP3kTvcT5EXRP1QJ8CTymlFJOllN/pZSaJSJVaOVU+4R/ppT6syHnj8BdaNMO85RSr4lIP+A9wMOQ8Wnt+Uacd4HN9osfRMQf+C9aEQrwX6XUK42Vsfq1251W6u2Lk7CVV+FlER4d2pkhHQP5YM9JPt6nDb2Oiw9h5hUdERGyiyuYvT6Nt67VL6PXt5zgq5R8PEToGe7LX0bFYvVw3m54ZFUKWzL0fFKYjycPDIxhbFwIM1cmk1lUQbS/lTnjuxLcTk+gvrk9g8UH9XLQWcM6MaJLMACz16VyS+8I+kT4YSurchm/rWTi6bgc9faF+7CVGXU8PJYhnYLYnlHIixvTqK5RWD0tPD0qjt4R/mQX/f/2zjvMiiLrw+9vBgYHhjiSgwRBERVUWEXWBOaAiTXw+ZnDGta0plXMrrquyrqGVQyrn1kw4YooSjCsKEGiIHFA0iBhgIGBSef7o3rgcucODjB9W+bW+zz3mb7Vt/rXNV3dp6vq1KlC7hw5l+f6uh7dJ8f+zPDZK0hPE50b1+H+Ph3K/Y8rWhbhvH+NJm9DITXS07j15P3puWcTrn31W+b/kk+aoEXD2txz+oE0rZ/J8rUFDBgygUEX/54J81dw3rNj6NSsHmkq657rwhF7N9/q+ImWRTjvtfHkFRRRMy2NW/p0pGfbRhSWlDJg2Axm5q6jZnoaNx+1J4e0bcTydZu485MZPHdWNwAKikro/fTXfPbHXtTdrWK33kTLIjw5+L988u0s0tPS6Ny2MQ9ccQwZNbcco881LzLkwf40rJfJ8lX5DBg0gkG3OU+2P/9zGN//+DN56zaSXb821/TrSb/e8b3dblmESOoUya/L6de/ttO9c6Xjn6n0gzyt+1WR9wYm3fCkAhUZHk8Vk8DwhI1fjyc5pNJ6PFVieH54tvKG54A/Rm54fJBQj8fj8SQVb3g8Ho/Hk1S84fF4PB5PUvGGx+PxeDxJxRsej8fj8SQVb3g8Ho/Hk1S84fF4PB7PZiTdIGm6pGmS3gyWkynbd5Mkk7TDy16DNzwej8fjCZDUErgW6B4sT5OOW7oGSa2BY3DRXHaK1F2JyOPZEZo3//XfhIDqZv36j8KgRkQxxSKYHExxcfI1f5vUwK0IUIQLabYkSB8I3IILSbZT+BaPx+PxpBCxkfSDz+Vl+8xsMfAorlWzFFhjZp9J6gssNrPJVXEOvsXj8Xg8uzpp6ZX+qZkNAgYl2hcEaj4VtwRMHjA4WM/sauDYnT7PAN/i8Xg8Hk8ZRwPzzewXMysC3sMFW24HTJaUg1vLbKKkZjsq4ls8Ho/H4yljIXBIsJxMAW69tPfM7KiyHwTGp3uw1tkO4Vs8Ho/H4wHAzL4DhgATcUvRpFFBt9zO4Fs8Ho/H49mMmd0N3L2N/W13VsO3eDwej8eTVJLe4pHUFOcPfgiwGigEHgE+BZ4H9set9JkHHG9m+QlWIH3LzB6W9DrQHSgCvgeuMLMiSfWB14A2uDI+amb/lrQX8HbMcdoDdwWrk94DXIZbFRXgdjMbFpzzX4BLgBLgWjP7dEfK/uqUZQz+cQWG8YfOjTm/azNmrtjAvV/msKGolJZ1M3jk6A5kZZT3UHll8jKGzPgFITplZ/LXo9pRq0bi94Y7Rs1nTE4ejTJrMvQct7pj3sZi/jxiLovXbaJl3Vo8fmwH6tdyl3/QxCW8O8OtoHj779vw+zb1yx1zW/mruqyJ8laWVyctZfD0XAz4Q5emnN+tOTN+Wc+9o+axqaSUGmniziPasX+zrZeh3lRcyvnvTqOwxCg249gO2fzpkNaV1n15+CSGjPkRAZ1aZ/PgpX2olVGD1z6bzOufTyU9PY0juu7Bzef0Kpf3qykLePC1rygtNfodsQ+XnXJQpTT/b+SPDP5mtvs/9erEBb33IW/9Jm58cQyLV+bTMjuLgZceQf3atbbKNz93DTe+OGbz959X5POnk7txQe99KlfWj8Yx5IspSKJTm9158OoT+edbXzFq/Fxq1kindbMGPHj1CdSrs/US40tXrOW2Jz9mRd56JHHWMV05/6TuldKExNd25i/ruXf0PDYUldCy7m48ctyeZGWUr5d3fD6HMTmr3T3xP922qfNbuH+qO0lt8UgS8AHwpZm1N7ODcLNiWwHXAblmtl8wY/YSnEEBKDCzbjGfh4P014G9gf2ATODSIP1q4Ecz6wocCTwmKcPMfio7BnAQsAF4P+YUB8ZolBmdfYJz7AIcDzwjqfK+iwGzV25g8I8rePvMzrx/1r6MXrCGnLyN3DV6Pjce0ooPz96XPu0a8tKkpeXy5uYX8trUXAb368LQc/alxIxhc1ZVqHX6Xrsz6OROW6W98MNSDmlZj+H99+eQlvV4YaLTmbOqgE/mrOKjc/Zl0MmduP+rBZSUll/MsKL8VV3WivJWhtkrNzB4ei5vn7Uf75/bldHzV5OTV8Bj3yzgqt+14v1zu3LNwa157L/lJ15npIuXTu/C+/278t45+/P1wjwmL1uXQKU8uavyee2zyQy59yw+eqg/paXGsO9m892Pi/hi4nw+/Ou5/Oeh/lx84gHl8paUlnL//41h0E2n8NHD/fl47CzmLK742pYxa8lqBn8zm3duPYkPbu/L6KmLyFm+luc/nUrPvZrz6b1n0HOv5jz/6bRyeds1rc/7t/fl/dv7MuS2k8nMSOform0qV9aV63jtk4kM+dv5fDTwYlfWb2Zw6P5tGTrwYj58/CLaNm/IoPfGlsubnp7GLRccxcdPXMrbD53HG8N/YM7PlRufruja3jVyLjce2oYP+3ejT4dGvDRxScL8p3duwqBgifNfI+r7JxVIdldbb6DQzJ4tSzCzBWb2JNAcWByT/pOZbdrWwcxsmAXgWjytynYBdQNDlwWsAuKnJfcB5prZgl8551NxLaxNZjYfmAP87tcKGs/cvI10bVqHzJrp1EgTPVrU5Yv5q5mft5Huzd3b96Gt6/HZvNUJ85eUGhuLSykO/japU/GM8u4t6pZ7mxo5P4/T9soG4LS9svlifp5Lz1nNCXs2IiM9jVb1atGmfi2mLl9f7pgV5a/qslaUtzLMXVVA12Z1t+RtWY8v5q5CgvWFJQDkF5Yk/N9Jok7Q+iouNYoTPDy2RUmpsbGwmOKSUgo2FdGkQR3eGjmNy04+iIya7rjZ9WqXyzdlbi5tmtSndZP6ZNRI58RDOjJy4rxf1Zu3bA1d2zUmM6MGNdLT6NGxKZ9PWsjIKT9z6iEdADj1kA58MXnb0U3GzlxK693r0jK78pERSkpKty5rwyx6dWtHjXT3OOnaqQW5K8sb7SYNs+jS3rVe62TWokPLbHJX5VdKs6JrO3/1Rrq3qAfAoa3r81kFL2TdW9aj/m6Va2FEff+kAsk2PF1w3hKJeAm4VdK3kh6Q1DFmX6akSTGfs2MzSqoJ/C8wPEh6CuiMC/UwFbjOzErj9M4B3oxLu0bSFEkvBROpAFoCP8f8ZlGQtl10bJTJ+KXryNtYTEFRCV8uzGNpfiEdG2UyMicPgE/nrmZZfmG5vE2zMrioWzP6vDqZI16ZRFZGOr1al2/Ob4uVBUU0rpMBQOM6GawqcI3J5euLaJaVsUWrTga568ufQ0X5q7qsFeWtDB2zMxm/ZC15BUUu74LVLM0v5LbD2vL3bxbQ+98T+PvXOVzfc4+E+UtKjdPfnMzvXxzPoa3r0zWuO64imjbK4qITDqDPDa9w+LUvUbd2LXrt14acZXlMmLWEs+8ZzP/+9T2mzsstl3f56vU0y6671bFyV5d/cJUra/MGjJ+Ty+r8jRQUFvPl9MUsW72elesKaFLfGbgm9Wuzat22W4vDJuRwUvd2lSonQNPsulzUtwd9rnyWwy972pW129b53xs5lcMObL/N4yxevoYZObl07Vi5EEQVXduO2ZmMDF5MPp2zkmX523xX3WGSef+kApE6F0h6WtJkSePMbBJuzOXvQCNgnKSytnF8V9vbcYd6Btd991Xw/ThgEtAC6AY8JalejG4G0BcYHHOMfwEdgt8vBR4r+3mCUy/3OhwbhuL5/84ul6FDw0wuPaA5l3z0E5d/PIu9smtTI008cFQ73py2nH6Dp7O+sISaaeXl1mwqZuT8PEactz+jz+9KQVEpQ2ftsAv91gVJ8GKfqMDbw86UtaK8ldJtVJtLD2zBJR/O4PKhM9hr9zrUSBNvTc3ltsPaMvKig7j1sLbc+cXchPnT08T753Zl1EUHMTU3n9krN1RKd836jYycOI8Rj53PmCcuomBTEUO/+YniklLWrt/EW3f34+ZzenHDU8OxuH94onZVZUrboXkDLj1mXy55cgSXPTWCvVs2JD19+65cYXEJI6f8zHEHtq10njX5Gxk5bg4jnr6CMYOucmX9cvrm/c+++y3p6WmccljF40XrCwq59tEPuO3CPmTFjT9VREXX9oE+e/LmlGX0e2uKq1PpyX2khXH/pALJHt2aDpxZ9sXMrg7Ca48PvufjZsq+J6kUOBGYsa0DSrobaAxcEZN8EfBw0AU3R9J83FjQ98H+E4CJZrb5FTR2W9LzwH+Cr4uA2FHmVmwJmreZ2DAUJf84L2E/zZmdG3Nm58YADBy7iGZZGbRvmMkLp+wFQE7eRr5cuKZcvm8XraVlvVo0ynRdRMe0b8ikZfn07VT5yOTZmTX5ZX0hjetk8Mv6ws3HappVc6uWR+76QprUyah0/orY0bJWlLeynNmlKWd2aery/nchzbIyGPjtQm4/vC0Ax++ZzV1fbLsrq16tGvRoWY+vFuTRMbt891g8305fRMvG9WhULxOAo7t34IfZS2nWKItjurdHEvt3aEpamli9buPm3wE0bViHZTHdUrmr8mnSsE6lytqvV0f69XIdAwM/nEjTBrXJrpvJ8jUbaFK/NsvXbKBR3d0qzP/V9MXs07oRu8ecz6+WdUoOLZvUp1HQqjr64E788NNi+h7ehQ9GT2P0hLn8++6zcb3c5SkqLuG6Rz/glMP24dhDOiX8TUUkurbtG2XywmnOyOWsLuDLnMp1y24vyb5/tpu0XctBOdlnOxLYTdKVMWm1AST1KuveClok+wDbHH+RdCmudXNuXFfaQtwYTpkX3V5A7NPmXOK62STFtvlPB8pGZYcC50iqJakd0JEtBmy7WLnBNa+XrNvE5/NXc2LHRpvTSs14dsISztqncbl8zbMymJybT0FRCWbG2EVrad+w8g8LgKPaNuCDn1YC8MFPK+ndrkGQ3pBP5qyisKSURWs3sSBvE/s1Kf/gqyh/VZe1oryVZau8c1dyYqfdaVIng3GL1wIwdtFa9mhQ/mG8qqCItZvcMODG4hK+/XlNpf/HzbOzmDw3l4JNRe76TP+ZDi0a0ueg9oz90Q1bzl+6mqLiUhrGGYL92jdlQe4aFv2ylsLiEoaNnc1RB1Su62vlugJX1lX5jJi0gJN6tKP3/q35cKxr0X04di6996/YM+/j8fM5qUflu9kAmu9ej8mzlmwp69QFdGiZzVc/zOOFD77jmVvPILNW4oeqmTHgmeG0b5XNhaf02C5dSHxtt6pT4xZx1n47HMVlmyT7/qnuKL7pH7qge8APBA7GuS6vB54FagE34VqqacDHwK1mZgncqYeb2W2SinHGqeyV8T0zu09SC+BlnMOCcK2f1wL92rgxm/ZmtvmVW9KruG42A3JwrtlLg313ABfjHBSuN7NPtlXGilo8570/g7xNxdRME7cc2oaererx6pRlvDFtOeBaMjcc3ApJLF9fyJ2jc3juJPdW+OT3ixk+dxXpEp0b1+b+I9uSUUG3wk0j5vL9EjdOkp1Zg2t6tKRPu4bc8NkcluYX0jwrg4HH7kmDYLD12QlLeH+mcwe9rVdrDt+jAQB3jprP2V2asG+TOuRtLK4wf1WXNVHehCQInX/ekGnkbQzyHtaWnq3rM2HJWh76MoeSUiOjRhp3HdmOLk2yWJ5fyJ0j5/Jc3878tGI9fxkxh1JzD7HjO2Zz1e/KP7TVI7Gr85Pvfccn380mPS2Nzns05oFLeoNgwAtfMGPBCmrWSOeWc3txyD6tWL46nwEvjmLQTacAMGZyDg+99hWlZpxx+D78sW8CF+P88oP15z32CXnrN1EjPY1bz+xBz72bszp/Ize+OIYlq9bTolEdBl56JA3q1GJ53gYGvP5fBl19NAAFhcUcdccQRtx3BnUzt9GibNK0fFnf/ppPvplJenoands14YErj+eUG16isKiEBnWdse7asTn3XHEcy1etY8C/PmXQHf2YMGMR5935Bp3aNCYt6D69vv9hHHFgh3IaNuarcmmJru2rk5byxtRlABzTvhE3HNrG1amYawtw0/BZfL94bXBP1OSag1ttbj1tJlgWIdn3T/r1r+1071zp1Bcr/SBP2++SyHsDk254UoGKDI+niolgzZaKDE/oJDA8SSGB4UkGiQxP6ES0Hk8qGp5dq2PQ4/F4PLs83vB4PB6PJ6l4w+PxeDyepOINj8fj8XiSijc8Ho/H40kq3vB4PB6PJ6l4w+PxeDyepOLn8fzGkHR5EH7H61YjTa9bvXWjKuuuim/x/Pa43OtWS02vW711oyrrLok3PB6Px+NJKt7weDwejyepeMPz2yOqfuJU0k2lsnrd6qu5y+KdCzwej8eTVHyLx+PxeDxJxRsej8fj8SQVb3g8Ho/Hk1S84fF4PB5PUvGGJ2LkOFjSGZJOD7aTtkKgpCxJB0pqkAStNElpwXZGoNsoZM2JkgZIKr++ckRI2ubS6Tt57HqSHpL0qqT+cfueCUs3wXlclSSdNmV1V1JbSf0k7ZsE3Ujv212d5K8d7NmMpGOBZ4DZwOIguRWwp6SrzOyzEDSfMbOrgu3fA28AcwPNK8xsWFVrBlqnAc8BpZL+CNwOrAc6SbrSzD4KQxdoCDQARklaBrwJvG1mS0LSA0DSgRXtArqFKP1vXH16F7hY0plAfzPbBBwShqCkG+OTgL9I2g3AzB4PSfc24Apgk6RHgZuAb4B7Jb0Yom7S79vqhnenjhBJM4ATzCwnLr0dMMzMOoegOdHMDgy2RwF/NrOJktoD75hZ96rWDLR+AE4AMoHJQA8z+0nSHsC7IerGlvcw4FzgDGAG8GZY8bUklQBjcA/heA4xs8yQdCeZWbeY73cAJwJ9gRFl/4sq1lwHDAOms6W81wP/ADCze6taM9CdDnQHagM5QHsz+0VSHeA7Mwul5RPFfVvd8C2eaKkBLEqQvhiomQT9emY2EcDM5klKD1PMzJYBSFpoZj8FaQvKut/Cxsy+Ar6S9CfgGOBswpv4NwO4wsxmx++Q9HNImgC1JKWZWSmAmf1V0iLgSyArJM0uwONAHeBeM9sg6YKwDE4MJWZWIKkQKABWApjZ+pB7vaK+b3d5vOGJlpeAcZLeAsoeRm1wD8QXQ9LcW9IU3JtpW0kNzWx18PAP9aaJeSBeHJOWDmSEKDsrPsHMSoDhwScs7qHiMdQ/haj7EdAb+LwswcxekZQLPBmGoJktBPpJOhUYIWlgGDoJmCjpDZzB+wJ4RdJwXPl/DFE30X3bGjiH8O7baoXvaosYSZ2BU4GWOGOwCBhqZqHcOEHXVixLzaxQ0u7A4Wb2Xki6PYCpZrYxLr0t8Hszey0MXU9yCbq57gEONrPDQ9aqAfwBMGAI8DugP7AQeNrM1oeondT7trrhDc9vDElNzGx5kjWzzWxlMjWTiaS92fKQMGAJ7iExIwm6LXHjDfkx6cebWWitrcCD73TcW3gxbhD8TTNbE5amx7M9eHfqCJHUKP4DfC+pYVhuxpIeDlo3SOouaR7wnaQFko4IQzPQaibpX5KelpQt6R5JUyW9I6l5iLq3Am/h3kq/B8YF228GXlFh6V4LfIjrVpsWdEOV8WCIutcBzwK7AT1wzhytgW8lHRmSZv2gXs2UtErSSkkzgrQGYWgGupG4yks6Pma7vqQXJE2R9Iakpsk8l10V3+KJEEmlwIK45Fa4ZruZWfsQNKea2X7B9ijgFjMbJ6kT8EaI3mXDgY9x/fH9gddxrs2nAkeb2anbyL4zurOALmZWFJeeAUw3s44h6U4FeppZftCdOAR41cyekPSDmR0Qom43MyuRVBvnZXWkpDbAh2HoSvoUGAm8EuNA0gy4AHdtj6lqzUBjPs5t/Cwgma7ysZ6SLwTaz+O8JY8ws9PC1K8O+BZPtNwC/AT0NbN2ZtYOWBRsV7nRCagZ9I0DZJrZOAAzmwXUCkkToKmZPWlmDwMNzOxvZrbQzJ4E4sedqpJSoEWC9ObBvrBIL+teC9xujwROkPQ4iV2sq5Ky61sLqBucw0LCcx5pG1zPZWUJZrbMzP6Gc5YJi9VmdpOZtQH+DHTEORyMkpSsFUG7m9kAM1tgZgOBtknS3aXxXm0RYmaPBp4xAwMX27txYxBh8jQwTNLDwHBJ/wDeA/oAk0LUjX3J+b9t7Ktqrge+kDSbrT0H9wSuCVF3maRuZjYJIGj5nIzziNovRN0XcB5XY4HDgb8BSGoMrApJc4GkW3AtntxArylwIVv+56GSZFf5JnKTZgXUkyTb0nXkX+Yrge9q+40g6RTgDtzbY7OQtY4ErgQ6sWVOwgfAS/FdUlWoeR/wSOwge5C+J/CwmfULQzfQSMN5PMV6II0L3KrD0mwFFMe2AmL29TKzb0LU7gJ0BqaZ2cywdGL0GgK34bpNy8Y4lgFDgb+ZWSgGT9JbZnZOGMf+Fd2745KeCSauNsPV8fOTfU67Gt7w/IaQlAl0MLNpUZ9LdSUwdF2BGVG5vkrKijfAIWpFXl6PJx7fLPwNYWYFuHGfUJG0t6RbJf1T0hPBduhhPgLdPpKy4tKPryhPFWiOivHi+19caJcTgLeDbpkoCM0ARFVeSR0k3RTUp8ck/VFS/bD0YnR/JzdHDEn7SLpR0okha14btGg9O4hv8USIpKHxScBROA8hzKxvCJq34uKVvcWWsB+tcLOu3woG/6ucwL34alwomW7AdWb2YbBvs5dQCLrTymJ2SRoHHG9mKwOPr7Fmtn9IuvGBMzfvAu4ws7Dc5ZNe3uDanoKLTXcibqxwNW4u0VVmNrqqNQPdu3FGtQYwAjgYGA0cDXxqZn8NSXcNLsDtXJwn3WAz+yUMreqKdy6Illa4t98XcE4FwgU9fCxEzUtI7F78OC7IYyiGB7gMOCjWvVhSWzN7gnC9vIoktTSzxUA+7oEBsAkIMzbdg8DfcRM44wmzpyGK8l7GFhfux9niwv0cbi5TKK7jQD/cS0wt3JhSKzNbK+nvwHdAKIYHmAcchDNwZ+OiYU/AGaH3zGxdSLrVBm94oqU7cB3OqeBmM5skqcDMxoSoWeZeHD9/KKnuxYGDwxC5ED5hGp4bgM8kvYszrCODOUWH4ZYQCIuJwAdmNiF+h6RLQ9SNqrw1gBLiXLglhRn/rzhwENkgaa6ZrQ10C4I5cmFhQczBz3D/65q4lte5wKNA4xC1qwXe8ERIUHkHShoc/M0l/GtyPSnkXmxmoyUdipu0WheYgHv7/1PIHl8XUbH7ciiTdCGy8kbhwg1QKKm2mW3AtUAIdOsT7kvUVi9KQe/BUGBo4CDk+RX8GM9vCEknAb3M7PaQdVLKvdgTPsl24Q40a5lb4C4+fXeguZlNDUm3UzDh2rODeMPzGyIZrq+SGphZXhjH3l4kNQprjsev6M4ys04ha7QHBuACkj4MDAR64pwrbra4RcSqUDcNN3HzDLYOEvpsWIP8FZxH0q9tMl3HJdUws+JgOwvYG5gXRX3eFfHu1BESkevrCkmfS7pEIQZwjEfSgJjtfeRiqE2QlCPp4BB110laG/xdJ7daZoey9LB0gZdxAUnzgbHATNy1HY7rXgyLF3Fdpw8Do3Dx8V4EBoRVpyT1kgsKOl3SwZJGAOMl/SypZxiagW5UruMXArmSZkk6AZiC616cLOncsHSrFWbmPxF9cN0SZdvjgOxguzYwJSTNqcDJuCCdK3FeR+fg4raFWdaJMdsf45YOBtfl998QdZ/EhehpGpM2PwnX9oeY7YUV7QtBd0rc97HB31q4lkAYmt/jxul6Aitw6ysBHAh8E2JZk37/BMefCuwOtAPW4iZ9g4vaEJpudfr4Fk+0FElqGWwny/W1yMz+Y2b/g3Pnfh0X3XeR3GqOyaCFmX0CYGbf40L3h4KZ/Ql4ArcMwrVBV1Qy+pdLJXUKJjfWltQdNncHhenGXaRgmQBJBwKFAObGQsIqd00zm2pm3wK/mNnXgeZEQry2RHP/gFtye4WZzQfyzWwugAVx6jy/jvdqi5YoXF83e+SYi5TwDvBO4Al0WkiaAO2DCbMCWsV4I0HIS26b2QRJR+O89sbg1qoJm1twy1CX4v6vf5HUFagHhBk5+WZglKSNuP/rObDZw+w/IWnGvsD+JW5fmMuaR+U6vlDSQzivwZmSHsMF2j0aWBqibrXBOxdETPDA78/WATs/tJA8gyTdZGaPhnHsX9GNX2RugjmX6qZAPzN7Oknn0Rw4wMyGJUMvTnt3XCj/0LwHAx3hup1WhKkTo9cX+DzmRaIsvQNwppk9EqJ2Uu+fQLMeLgqHAU8Bx+Hc5xcAD5iZNz6/gjc8nmqNpFvKHnyS/mBmg2P2PWghua6nmq7Hsz34MZ4IkZQu6QpJ9weT/mL3Dago305q7h+zXVNu6eChkh6Ui+cVCpLSJF0k6T+SJkuaIOkthbQccwyxYfPju4FCC06agroJkRTWmjiR3D8JdHslS7c64Q1PtDwHHIHzLntSLs5VGWeEpPlyzPbDuIgFj+EGgZ8NSROcS+8eJNHNN0AVbCf67nV3RFBqVMEnGxc0NCyiuH/idf+ZRN1qg3cuiJbfWRAtWNJTwDOS3sPFfArr4RR73D5ADzMrkvQlMDkkTXABQi8Ktr+WNNbM7gp0J+HcnsPAKthO9N3r7hi/4MY3YutWWdDbJiFpQjT3T5S61QZveKJls8ePuVnQl0u6C7csQlaFuXaO+pJOx7V2a1kQpdrMTFKYD8QiSR3MbG68m2/Iul2DiaICMmMmjYpwvdtSSXce0MfMFsbvkFvSPSyiuH+i1K02eMMTLeMlHW9mw8sSzOw+SUuAf4WkOQYoW+dnrKSmZpYrt2xvmF5QUbj5YmZhzufwuo5/AA2BcoYHCM2jjWjunyh1qw3eq82TNJLt5hto1sZNmi0Kvu+FG3fIMbP3va7Hk3y8c0GESLolZvsPcfserC6aZbrmWJFMXVxstLaBzp7At0B74BpJYS16l1K6UdapVNKtVkQdsyeVP2wdv2xiRft2dc2IdafGbN8PPB1sZ8Tu87q75LVNKd3q9PEtnmiJwuU2Zdx8A2L7knsDIwDMrJBwFwtLJd1Uq1NR6VYbvHNBtETh+ppKbr4AUyQ9CizGzVn6DNy6RCFqpppuqtWpqHSrDd65IEIkleAi6go3gbMs1pWA3cysyoNnRqEZsW4mcB3QHHjJzCYH6T2BPc3sVa+705qpVqci0a1O+BZPhFgErq9RaEapCxwLrDOzhwEkfQc0Dvbd6nV3nlSrUxHW5WqDH+OJEEm1JdWM+b6XpBuCCZ7VRjNKXdzyBENjvtcCegBHAn/0ujtPqtWpCOtytcEbnmiJwuU2Zdx8AzLMLHb2/NdmttLcLPs6XrdKSLU6FZVutcGP8USIpKlmtl+wfT/QyMyulpSBW69mv+qgGbHuHDPbs4J9c82sg9fdac1Uq1OR6FYnfIsnWqJwfU0lN1+A7yRdFp8o6Qrge69bJaRanYpKt9rgnQuiJQrX11Ry8wW3PPIHkvoDE4O0g3BjH6d53Soh1epUVLrVBt/VFiERub6mjJtvnH5voEvwdbqZjQxTL5V0U61ORV2XqwO+xRMtUbjcpoybbyzBgzcpD/0U1E21OhVpXa4O+DGeaInC5TZl3Hw9SSPV6pSvyzuJb/FES0LXV2ClpLBcX6PQjFLXEz6pVqd8Xd5JfIsnWhrGfjGza2K+NiYcotCMUtcTPqlWp3xd3km84YmWKFxfU8nN15McUq1O+bq8k3ivtgiR1AT4ANhEAtdXM8utDppR6nrCJ9XqlK/LO483PL8BonC5TQU3X09ySbU65evyjuMNj8fj8XiSih/j8Xg8Hk9S8YbH4/F4PEnFGx5PtUCSVeJz5E5qXC7ptCo54crpvSxpfMgax0q6PkwNjyceP4HUU13oGbOdiQsX8wDwcUz6jzupcTkwDefRVF04FugH/CPi8/CkEN7weKoFZja2bFtSVrA5NzbdswW5FTR9CH9PJPiuNk/KIOlSSdMlbZK0QNItcfu7SBouaZWk9ZJmSLo62DcaN1fjgpiuuwu3oZUp6ZFAZ5Ok+ZIeitmfLukeSQuD/dODpQwSHesYSVOCc/paUpe4/bUl/VPSMkkbJY2TdGzcb0ZLGhJ0F84FNgKDgD8De8SU6eXt+Jd6PDuEb/F4UgJJNwMPAo8Ao3FG5H5JG8zsqeBnQ4GZwHm4yYF7AfWCfVcB7wLzgPuDtLkVaAn4ENf9dz8wAWgJHBbzs/twwSbvBcYBZwKvSzIzezPmd22AvwN/BQqAR4F3JO1rW+ZCPA/0BW4H5gCXAR9LOsrMvo45Vi+gAy6C8gZct+FuuMXMTg9+80uiMnk8VYqZ+Y//VKsPkIVbJfLC4Hs9IB+4O+539wHLgHRg9yDPfts47njg5UroHxccq28F+xsB6xOczzDgp5jvLwPFQMeYtNOCY+8dfO+M6zK7IOY3aTij8mlM2mic4WoWp/kokBP1NfOf1Pr4rjZPKtATqAMMllSj7INzQGgKtAJWAT8Dz0o6OwiLsqP0BlaZ2dAK9u8L1AYGx6W/DXSK084xs9kx38scJFoFf3sAij2WmZUG338fd/wJZras0qXweELCGx5PKrB78Hc6UBTzGRWktw4e1sfiWkAvAcskfSXpgB3QywaWbmN/8+BvfEyvsu+x0Y/z4n5TGPzdLeZY+Wa2IcGxakuqleD4Hk+k+DEeTyqwKvh7Mokfvj8BmNlM4MzA4+sw4G+4sZJWgWGqLCvZYlwSUWaUmgS/LaNp3PlWhqVAlqTaccanKbDBzDbFpPn4WJ7fBL7F40kFvsWNb7Qws/EJPutif2xmReYCPj6OMyANgl2FbGlpbIsvgEaSTq5g/zTc4P4f4tLPAmaZ2fYM8I/DGZR+ZQmBc0M/4OuKMsVQ2TJ5PFWGb/F4qj1mlifpHuAJSXsAX+JeujoBR5nZ6ZL2xw20v43zXGuI8/6abGZlLZCZwHGSjsO1VOabW3kynhHAp8Abku7Dhc5vDhxuZleY2SpJ/wAGSCrGOS2cAZwInLudZZsh6U3gKUn12OLVtjdwZSUOMRNoGriGTwNWmFnO9pyDx7O9eMPjSQnM7BFJS4AbcHNXNgKzcIYG3NhOLnAH0AI3tjIKZ3zKeADn3vwOzlPuIpznWbyWSTod50p9PW5VyiXAGzE/uwvnsXYlrltsDnCemb21A8W7DNcteCeudTYVONm2dqWuiHeAo3Bu5o2BV4ALd+AcPJ5K45dF8Hg8Hk9S8WM8Ho/H40kq3vB4PB6PJ6l4w+PxeDyepOINj8fj8XiSijc8Ho/H40kq3vB4PB6PJ6l4w+PxeDyepOINj8fj8XiSyv8DOM41lr5zNd8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hm_plot = sns.heatmap(df__*100, annot=True, fmt=\".1f\", cmap=new_c)\n",
    "hm_plot.set_xlabel('Test cohort', fontsize=15)\n",
    "hm_plot.set_ylabel('Training cohort', fontsize=15)\n",
    "hm_plot.set_title('Transfer on one cohort Test on the other cohort', fontsize = 15)\n",
    "fig = hm_plot.get_figure()\n",
    "fig.savefig('../figures/rotate_test.png', bbox_inches='tight',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1dbda8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEmCAYAAACTYry7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAACoLklEQVR4nOydd1hUR9uH72EXFBsKUhQLir1hVEyM3dgitliiMUVjS9TYEytqTII9lhh7N3YsWDB2EXvvMbFiRUCkSBPZne+PsyC4CyxKXPN+576uvWDnnGd+Z2b37HOmPkJKiYqKioqKSkZYWfoCVFRUVFTefVRnoaKioqKSKaqzUFFRUVHJFNVZqKioqKhkiuosVFRUVFQyRXUWKioqKiqZojoLFRUVlf84QoilQohQIcSVVGn2Qoi9Qogbhr8FUh0bKYS4KYT4RwjRzBwN1VmoqKio/PdZDjR/JW0EsF9KWRrYb3iPEKIC0BmoaLCZK4TQZCagOgsVFRWV/zhSykDg6SvJbYAVhv9XAG1Tpa+TUj6XUt4BbgI1M9PQZs+l/g8QG2GZpezCQv5a6i0jGxP59kVfPH/7moDI72QRXf2lQxbRtSpf6+2L5rB9+5oAuezEG+cRF2X2b47Inf8boHeqpIVSyoWZmDlLKYMBpJTBQojkL6QrcCLVeQ8MaRmiOgsVFRUVS5CFrZYMjiEz52AuphxdphejdkOpqKioWASZhddrESKEKARg+BtqSH8AFE11XhHgUWaZqc5CRUVFxRJIaf7r9dgGdDX83xXYmiq9sxAihxCiBFAaOJVZZmo3lIqKioolyMZxQyHEWqABUFAI8QAYB0wCNgghegD3gI4AUsqrQogNwF9AEtBPSqnLTEN1FioqKiqWIBvDQ0gpP0vn0EfpnO8D+GRFQ3UWKioqKpbgPxZLSHUWKioqKhbhf9BZCCGcgRnAB0AEkAhMAXYDi4AqKNOxIoHmUsoYIYQOuJwqm3VSyklCiNVADeAFyqDKN1LKFwadBsBMwBp4IqWsn+oaNMAZ4KGUsuUr1/c9MBVwlFI+MaSNBHoAOmCAlHK3WTXyCivWrMd3y1aklHT8pA3dPu/M39dvMM5nMnHx8bgWcmGaz0/kyZPbyHb5qrX4+m1DCEGZUu5M/NGbHDlymNQZ+ePPBAQewcG+ADs2rgMgMiqKwcNH8/BRMK6FCzFzygTs8uUDYMGS5Wzcug0rKyu8hw2l7ofGc9wzsrdkWV9lpa8fvjv+VHRbfkzXTz/h2o1b/PjrbJ4nJqLRaBg3+DuqVChrZBv9LAbvKTO5cScIgcBnxGDeq1TBPN1N2/HduUfR9WpK1/atuXbzNj/OnMfzxBdoNFaMG/gtVcqVMbIdNfU3Ak6cwSG/HduXzDZLDwx17LfNUMet6dbFUMcTphAXF4dr4UJM+2W86TpevRZfv+0v63jcaPPreM8RfANPK7r1a9K1aR0AVu07yur9x9FYWVHfoxw/fNoijV1weCQjFm/gSdQzhBB8Wr8mXxlszSrv+o34bt2h6LZpSbfOHfn7xk3GTf5V+U65uDDtpzHkyZ22vMEhoQwb78OT8KdYWVnxadtWdO3UIV2dd+H+yTL/LV+R+WwoIYQA/IBAKWVJKWV1lKXiRYCBQIiUsrKUshLKj/MLg2m8lLJqqtckQ/pqoBxQGbAFehp08gNzgdZSyooYBmNSMRC4ZuL6igJNUAZwktNeazn7q1y/eQvfLVvxXbmUrev+IODwEYLu3WP0TxMYOqAv2zespnHDBixeucrINiQ0lJXrNrBp1TJ2+K5Bp9fjv3tvulrtWnmxeM6sNGkLl62gVk1P9mzbRK2anixcpizGvHnrNv679+C/cR2L58xi/MQp6HTG41Pp2Vu6rGl0bwfhu+NPNiyYhd/SeQQcP0nQ/YdMnbeEft0+x2/pXAZ0/5Kp8xebtPf5bT5136/On6sW47dsLu7Fi5mne+cuvjv3sGHONPwWzSLgxGmCHjxi6sIV9PuyM34LZzKgWxemLjRdZ580+4hFE8eZpZWiefMWvn7b8F2xhK1rVxJw+ChB9+4z+ueJDO3fx1DH9TOoY182/bGUHRtWo9Pp8N+9zzzdB4/xDTzNhjH98PtpIAEX/ybo8RNOXrvF/vPX2PrTIHb4DKF783pGthqNFcM6eeE/YSjrvfux5sAJbj4MMU/31m18t+7Ad+l8tv6xhIAjxwm694DRE6YwtO83bF+9nMYN6rJ41ToTuhpGDOjHn+v/YP3ieazZuIWbd4LS1bL0/fNa/PuzobIVc6bONgISpZTzkxOklHellLOBQsDDVOn/SCkzXC4rpdwpDaC0LIoYDnUBNksp7xnOS54TjBCiCOAFmPrFmAEMI62ffq3l7K9y604QHpUrYmubE61Wi2f1auw9cIg7d+/iWe09AGp/UJM9+w+atNfpdCQ8f05SUhIJ8Qk4OTqmq+VZvRp2dmmfWvYHBNK2lRcAbVt5se/goZR0r2ZNsbGxoairK8WLFuHSlatGeaZnb+mypub23Xt4VCiHbc6caLUaPKtWZt/hYwgBMbFxADyLjcWpoIORbUxsLGcuXqaDl7Iljo21Nfny5jFP994DPMqXwTZnDrQaDZ5VKrHvyAlFNy5ZNw4nB3uT9p5VKmKXzzytZG7dCcKjUqo6rvYeew++Usfv12TPgQCT9mnqOCEBJ8eC5pU1OBSPkkWxzWGjlLVsCfadu8q6gyfo1aI+NtZKB4ODifI45c9HRTdlcW9u2xy4F3IkJDLavPIG3cWjYgXDZ6vFs5oHew8FcufufTzf81DKW9OTPSa+l04FHahoaNHlyZ2Lkm7FCQkNS1fL0vfPayH15r/eAcxxFhWBc+kcWwoMF0IcF0L8IoQoneqYrRDiQqpXp9SGQghr4EtglyGpDFBACBEghDgrhPgq1ekzURyC/pU8WqN0S1185bpcgfup3pu1nP1VyriX5My5C0RERhEfn0DgkWM8DgmhjLs7+w8dBmDXvv0Eh4Qa2To7OdH9y89p2KItdZq2JE/e3NSp9X6W9MPDn6b8IDg5FuTp0wgAQsLCcHFxTqNl6kZKz/5dKmvpEm6cvniFiKho4hMSOHTiNMGhYYzq/y1T5y2mQfsvmDJ3MUN6f21ke//RY+zz2zFy4q980qMf3pNnEBefYJ6uWzFOX/rLoPucQyfPEhz2hFF9ezJ14XIadO7OlPnLGNLzS7PyM4cypdw5cz5VHR89bqjjkqnq+ED6dfxFFxp6fUKdZq3IkyeP+XXs6sKZ60FExMQS/zyRwEv/8PhpJEGPn3D2ehCdfp7Dl5MWcPn2/QzzefjkKdfuPcKjZNEMz0spb8kSnLlwkYioKOITEgg8doLHIaGUcS/B/sNHlfLuP0hwqHF5U/PgUTDXrt/Aw8zuxWTe5v3zWvwPtizSIISYI4S4KIQ4LaW8AJREGS+wB04LIcobTn21G2r9K1nNRenaOmx4rwWqo7QgmgFjhBBlhBAtgVAp5dlXriMXMBoYa+oyTaQZ1bgQorcQ4owQ4szCpcuNDNxLlqBnty/p3rc/Pb8bRNkypdFotPiMG82aDRtp16UrsbFxKU9mqYmKjmZ/QCD7d2zm8O4dxMcnsNX/TxOXlXWkiS+P0lv4+liqrO5uxejVpSM9hoyk1/felHMviVajYe3WHYz47hsCNq1i5Hff4D15hpFtkk7HXzdu8lnblmxZMgfbnDlZtPrVr1k6usWL0qtzO3oMG0evET9Szt0NrcaKtdv/ZESfHgSsW8rIvj3wnmb+eESmmiXc6Nn1C7r3HUDP/oMpW6YUGo0Gn7GjWbNhE+0+70ZsXAZ1fOgw+7dv4vCu7Uod79xlQsWEbmEneraoT4+pS+g1fSnlihZCo7EiSa8nOi6edd59+eHTFgyet8bkdwsgNuE5A35fzYjPWpHHNqf55f2yC937D6XnoB8oW7oUGq0Wn9HDWbNxC+269iI2Lh4brXW6ecTGxTFg5FhGDepvNK7xuvwb989rXkkWXpbHnAHuq0D75DdSyn5CiIIog81IKWOAzcBmIYQeaIGJsYXUCCHGAY7AN6mSH6AMascCsUKIQMADqAa0FkK0AHIC+YQQq4DJQAngouGDLgKcE0LUxMzl7Gn2W0lnI8GObVvTsW1rAKbPnoezsyPuJdxYOvc3AO7cvUfAkWNGdsdOnqaIa2HsCyhbyDdt1IDzly7TxuvjjKomDQ4O9oSGPcHJsSChYU+wt1fycnFy4vHjl/3GIaGhJrsk0rNPD0uVtUPL5nRoqXQlTV+4DBfHgkxfuIzRA/oA0LxhXbynzDSyc3EsiLNjQTwqlAOgWYO6ZjsLgA4tmtChRRNFd/EfuDg6MH3JH4zu10vRrV8b719/Nzs/c0hTx7/Pw9nJyVDHSn+7UsdHjeyUOi6Uqo7rc/7iZdq0eHVXatN0qOdJh3qeAMzYuAtneztuPwqjSfWKCCGoUrIoVkIQ8SwW+1e6o14k6Rj4+ypa1apK0xqVslbe1l50bK105UyftxBnR0fc3Yqz9LdflfLeu0/AseMmbV8kJTFg5FhaNWtM04bG4ymZ8bbvnyzzjrQYzMWclsUBIKcQok+qtFwAQojayQE1hBA2QAXgbkaZCSF6orQcPpMyTWfcVqCuEEJraDW8D1yTUo6UUhaRUrqhDFofkFJ+IaW8LKV0klK6GY49AKpJKR/zmsvZTRH+VNn191HwY/YcDKBl86YpaXq9nnmLl9G5/SdGdoVdnLl4+Qrx8QlIKTl+6gzuJdyypN2ofj38tvsD4Lfdn48aKDdMowZ18d+9h8TERO4/fEjQvftUqVTRbPt3razhEZGKbkgoewOP4tW4AU4ODpy6cAmAE+cuULxIYSM7Rwd7Cjk5cvue0n1y/Ox53N3MG+BOqxvG3iPH8WpUDycHe05dVOLHnDh/ieKuxrpvQpo6PhBAy+ZN0tbxkvTq2IWLl6++fh1Hxyi64ZHsPXsVr/c9+KhaBU5cuwXAncdhvEjSUSBv2qd3KSXeyzZSsrAT3ZrVfY3yKl03jx6HsCfgMC2bNk5J0+v1zFu2ks6ftDayk1Iy2mcyJd2K83WXTkbHzeFt3z9ZRUpp9utdQJhzIYZNqGag/ICHAbHAfCAH8D1Kt48V4A8Ml1JKE1Nnd0kpRwghklAcyjND+mYp5U8GnR+Ar1HGJhZLKWe+ch0NgO9fnTprOBYE1Eg1dXY00B1lOfsgKWXG/SLptCy6dP+GyKgotFotI4cMpNb7nqxYs541GzYC0KRRA4b274sQgpCwMLx/msCi2UqXyW/zFrFz7z60Gg3ly5bBZ+wobGxsXrlwxV8PGeHNqbNniYiMxMHegf7f9qJxw/oMGj6K4OAQChVyZtaUieS3swNg3uKlbNq6HY1Gw6jvh1C/zocAjB7/C507tKNyxQpEREama29q0OxfLyumtyj//LuhREY9Q6vVMOK73tSq/h5nL13B57f56HQ6ctjYMHbId1QqW5qQJ+GMmTyThVN/BuDajVt4T5nJixcvKFq4EBNGDsEub960AulsUf75wJFERkej1WoZ0ac7tap5cPbyX/jMWWzQtWbswG+pVKaUovvrHBZOVHo9h/wyLWWsxaFAfvp3/SyllZLy0ZrYorxLj29T1fEAatU01LHvJqWOGzZgaP8+L+v454ks+m26UsfzF7Fzzz60Wq1Sx2NGmqxjU1uUfzFhPpGxcWg1Vgzv3JJaFUqRmJSE95KNXLsfjLVGw7BOLfigQilCI6LxXraJhUO+5uz1IL6YOJ8yRVywMnTVDGrfjPoe5Yw0TG1R3uWb74iMUup45MB+1PKszor1G1mzcYtS3gb1GNq3t6G8T/CeMIVFM6Zw5sIlPv+2P2XcS2JlZbhH+vSi/ocfpBUwbFH+1u+fbNiiXIbdNX+LcsfilugnS3sN74rXsjhqPIu3I6vGs/jXUeNZvAWyw1mE3DHfWTiXsLizUFdwq6ioqFiE/9aDuuosVFRUVCzBf6xXR3UWKioqKhZBdRYqKioqKpmhtixUVFRUVDLlHdnGw1zUsKoqKioqliAbF3ALIQYKIa4IIa4KIQYZ0qoKIU4Ytls6Y1iw/NqozkJFRUXFEmTT3lBCiEpAL5TNUj2AloZ9+qYA46WUVVG2RZryJperdkMlY6n1DpbCQuUVmrf/lXsxtu9b1wRIio6ziO6J/TctotvwzhWL6P53ybYxi/LACSllHIAQ4hDwiUEgeSteO0xseZQVVGehoqKiYgmyMMAthOgN9E6VtNCwtx3AFcBHCOEAxKPsz3cGGATsFkJMQ+lF+vBNLld1FioqKiqWIAvOIs2mp8bHrgkhJgN7gRjgIso2R32AwVLKTUKIT4ElQOPXvdz/Z30vKioqKu8I2Rj8SEq5REpZTUpZD3gK3AC6ouwIDuDLawSAS43qLFRUVFQsQTY6CyGEk+FvMaAdsBZljKK+4ZRGKA7ktVG7oVRUVFQsQfYuyttkGLN4AfSTUkYIIXoBs4QQWiCBtGMeWUZ1FioqKiqWQJ99i/KklEbBRqSUR1Cij2YLqrNQUVFRsQT/i9t9CCGcUYIffQBEAIkoCzx2A4uAKigBkCKB5lLKGBPBj9ZJKScJIZaj9KNFGdK7SSkvGAIffZ7qusoDjlLKp0KI5sAsQIMSFGlSqmvrD3yHMvrvL6UcJoRwQwnt+o/htBNSym/Nq5K0rFizDt/Nfkgp6diuLd0+/4y//7nOOJ9JxMXH41q4ENN8fiJPnjxm2abHyB9/JiDwCA72BdixcR0AkVFRDB4+moePgnEtXIiZUyZgl0+ZNr1gyXI2bt2GlZUV3sOGUvdD41gCGdlbStNkHW/YjO+2nUo9tW5Bt07t+fvGLcZNnanUcSEXpo0baTIGc+CJU/jMnIter6djq4/p/WX6dfwqVo3aYFWnOQiB/sgu9Pv9IFceNL1GIhyckeEh6BZNhLgY82zNQNO8PdpGLUEIkg7sQPfnRsidF5uBPyIKuiCfPCZx1jiITasp7B2x7jsakd8epJ6k/dvR7dpkdlmLfNOLwp9/hpSS2Gt/8/fAIRQb0I/CX3QhMVyJ1HfbZxJP9x8wtu3Vg0JfdEEIwaNVa3iwcLHZuivWrMd3y1bls/2kDd0+78zf128wzmfyy8/W5yfy5DH+bJevWouv3zaEEJQp5c7EH73JkSOHSZ135bucJf7XtvsQSoBrPyBQSllSSlkdJbxpEWAgECKlrCylrAT0QOkzA4iXUlZN9ZqUKtsfUqVfAJBSTk1OA0YChwyOQgPMAT5GCdv6mRCiguHaGgJtgCpSyorAtFQat1JpvJajuH7zFr6b/fD9Yzlb168mIPAIQXfvMfonH4YO+I7tvmtp3LABi1esMts2Pdq18mLxnFlp0hYuW0Gtmp7s2baJWjU9WbhsBQA3b93Gf/ce/DeuY/GcWYyfOAWdTmeUZ3r2ltQ0qqfbd/DdthPfxb+zdcVCAo6dIOj+A0ZP+pWhfXqy/Y/FNK5Xm8WrNxjZ6nQ6fvp1Not/nYD/6iXs2HeQm3cyjOr7ksLFsarTnKSJg0j6uS+ick1wKoxV80+Rf18gaWxP5N8XsGr+qdm2mSGKlEDbqCXPvb/l+fAeaN6rhXBxRdvmc/RXzvJ8iPJX2/pzI1up1/Fi1Ryef/8Vz8f0Qdv0E4RrcbOKauPiQpGe3TnTtAWn63+E0GhwatsGgPsLFnGmUVPONGpq0lHkLleWQl904WxzL043bIJD08bYlihhlu71m7fw3bIV35VL2bruDwIOHyHo3j1G/zSBoQP6sn3DauX+WWl8/4SEhrJy3QY2rVrGDt816PR6/HfvTVfrXfguZxm9zvzXO4A5s6EaAYlSyvnJCVLKu1LK2UAh4GGq9H+klNkRluwzlNF8UKZ73ZRS3pZSJgLrUBwEKPOIJyVrSilDs0E7hVt37uBRuRK2tjnRarV4Vq/G3oMB3Ll7D8/q7wFQ+4P32bP/oNm26eFZvRp2dmmfWvYHBNK2lRLsvm0rL/YdPJSS7tWsKTY2NhR1daV40SJcunLVKM/07C2p+Sq3gu7hUbE8tjlzotVq8Kzqwd7Ao9y59wDPqlUAqO1ZnT2HDhvZXrr2D8WLFKaoa2FsrK3x+qgB+w8fzVAvGeFSFHnnbyWKnl6PvH4Zq6ofYuVRC/3xfQDoj+/DysP4iTM920w1XYujv/EXJD4HvQ79tYtoPOuhqV6bpMBdACQF7kJTo46xceRTZJBhMktCPPLhXYS9o1llBRBaLVY5cyI0GqxsbXke8tgsu1ylSxN99hz6+ASkTkfksRM4ejU3y/bWnSA8KldMew8cOMSdu3fxrJZ8/9Q0ef+A8jCQ8Pw5SUlJJMQn4OSYfnnfhe9yVvmvxeA2x1lUBM6lc2wpMFwIcVwI8YthP5JkbA0bWCW/Ukdd9xFCXBJCzBBCpGlXCiFyAc2B5Da2K3A/1SkPDGkAZYC6QoiTQohDQgjPVOeVEEKcN6RnPdI8UMbdnTPnzhMRGUl8fAKBR47y+HEIZdxLsj8gEIBde/cRHBJitm1WCA9/ipNjQQCcHAvy1BDoPiQsDBcX55TznJ2cCAkNM9v+XdIsU9KNMxcvEREVRXxCAoHHT/I4JJQyJd3Yf+QYALsOBhIcYqwVEvYEF6eXoUudnRwJCQvPtIwA8tFdROlKkDsvWOdAVPYEe0fIlx+iDdccHQF57cy3zUzz/h2syntAnnxgkwNN1Q8QDk4IuwIQqXQFEfkUka9AhvmIgi4It9Lob/5lVlkTHz/m/tz51Dp/ig8vnyfpWTQRhu+va/ev8QzYS7mZv6K1My5r7N9/k7/WB2gLFMDKNicOjRuRo3DmrSiAMu4lOXPuAhGRUYZ74BiPQ0Io4+7OfoPz37VvP8Ehxs94zk5OdP/ycxq2aEudpi3Jkzc3dWq9b5ZuMpa4f7KEXm/+6x0gywPcQog5QB2U1oanEKIk0BRlZeBpIUQtKeU1DN1QJrIYCTwGbFBWJA4Hfkp1vBVwVEr5NFnSRB7JrlYLFEAZS/EENhiuJxgoJqUMF0JUB/yEEBWllNGvlCVlCf2C2TPp3b1bGhH3kiXo2e0ruvfpTy5bW8qWKY1Gq8HnxzH4TPmVuYuW0Kh+XWysjasxPdvswNSThtJb+O/xb2m6uxWn5+ed6T5ouFJPpdzRaDT4jPoenxlzmLtsFY3q1DJZx6avyUzhx/fR7fZFO2gC8nk88v5tMNEVkZ228tFdkratIceoX5EJ8ejv3QRdkpkXbCCHLTaDf+LFytkQb97eU1o7Owo2b8aJGh+QFBVNxSULcO7QjofLVxL060yQkhIjhlFq/Fj+HjQ0jW3cjZvcmz2Hqr5r0cXGEnP1L2SSefWk3ANf0r1vf3LZ5lLuAY0Wn3Gj8Zk6nbkL079/oqKj2R8QyP4dm8mbJy8Dh49iq/+ftPH62CztjLDE/WP6Qt4NJ2Au5jiLq0D75DdSyn5CiIIoe48gpYxBWSW4WQihR9mX5Fp6mUkpgw3/PhdCLAO+f+WUzrzsggKlJVE01fsivNwQ6wGwWSqf/imDfkEpZRiQ3DV1VghxC6UVcuaVa3m5hD4uymRbr+Mnbej4idLrNX32XJydnXAv4cbSebMBuHP3LgHpdH2Yss0KDg72hIY9wcmxIKFhT7C3V544XZyc0rRSQkJDU56AzLF/1zQ7tvqYjq2UH4Hp85fg7FQQ9+LFWDpzMgB37j0g4NhJIzsXJ0ceh758Kg0JDcOpoEOmesnIo3tIOroHAKu2XSHiCURHQr4CSqsiXwF4FmW+rRnoAnaiC9gJgLZTL+TTMKyiIiC/vdK6yG+PjE7nCVajwWbwT+iO7kN/2rhbLj0K1KtL/L17vDAMZIf5/4mdZw1CNm5OOSd41WoqrzLdJx+8Zh3Ba5RB45KjRpAQHGzyPFN0bNuajm1bAzB99jycnR2V+2fubwDcuXuPAEMLMjXHTp6miGth7Aso35+mjRpw/tLlLDkLS3yXs8Q70r1kLuZ0Qx0Acgoh+qRKywUghKgthChg+N8GZQA6wxFGIUQhw18BtEXZBCv5mB3KTKmtqUxOA6WFECUMGp2BbYZjfihjKgghyqC0Vp4IIRwNA+MYWhqlgdtmlNWI8KfKDfYo+DF7DhykZfOmKWl6vZ55i5bSuUM7s22zQqP69fDb7g+A33Z/PmpQT0lvUBf/3XtITEzk/sOHBN27T5VKFc22f9c0wyOUH8dHj0PYc+gILRs3SknT6/XMW7GKzm1bGtlVLleWoAcPuf8omMQXL/DfH0CjOlnYKy25i6mAI1bv1UZ/+hD6SyewqqVsn2NVqzH6i8fNtjWLfPkBEA5OaDzroju2D93Zo2jrKeMA2nrN0Z01/fBh3Xu40jrZaTzYnxHPHz7Erno1rGxzKpdctw6x129gk6oLr2CLj4n9+x+T9tYGB5zDtTAFvT4mdLOf2dpp7oGDAcb3z+JldG7/iZFdYRdnLl6+Qnx8AlJKjp86g3sJN7N1wTLf5SzxHxvgFuYMnhh+4GcA7wNhQCwwH8iB0jIQKI7HHxgupZQmps7uklKOEEIcABwNNheAbw2tE4QQ3VCm3nZ+Rb8FMBNl6uxSKaWPId0GZdykKsp03u+llAeEEO1RuraSAB0wTkq5PcNCptOy6NK9F5GR0Wi1GkYOHUSt92uyYs061qz3BaBJo4YMHdAPIQQhoWF4/+TDot9npmubHkNGeHPq7FkiIiNxsHeg/7e9aNywPoOGjyI4OIRChZyZNWUi+Q39yvMWL2XT1u1oNBpGfT+E+oYfydHjf6Fzh3ZUrliBiMjIdO0tpUlcmp5ApZ76DCIyOhqtVsvI/t9Sq0Y1VmzYzJrNyjNDk/p1GPptT6WOw57gPWk6i36dAMChYyeZ8NtcdDo97Vs2p09X45lEL0abXriq+X4qInc+0CWh27gI+fcFyJ0XTe9RiAKOyIgwdAt8lKmzdvZovhyE7vex6du+gqktym3GzUbkUexe/DEH/dVzkCefMnXWMF03ceY4iH0GBRyw6TWMxCnDsSpbmRw//o7+3q2UPuwX6xehv2Dc4jK1RbnbsKE4tWmNTEoi5spV/h78PeVmTCNPxQqAJOHeA/75fjiJoaHYODtTbsZULnX5CoD3tm3GukABZFISN8eOJ+LwEZP1aWqL8i7dvyEyKkr5bIcMpNb7nqxYs541GzYC0KRRA4b272v4bMPw/mkCi2bPAOC3eYvYuXcfWo2G8mXL4DN2FDY2NmkFDFvtv/Xvci67N+630l/cb3bTwsrjIwv0k6XFLGfx/4J0nIVKNmPCWfzbpOcs/m3UeBZvAUvFockOZ3F+n/nO4r3GFncW6gpuFRUVFUvwPzjAraKioqKS3fzHenVUZ6GioqJiCdSWhYqKiopKprwjs5zMRXUWKioqKpZA/9/qhlIj5amoqKhYguyNlDdQCHFFCHFVCDEoVXp/IcQ/hvQpb3K5astCRUVFxRJk05iFEKIS0Atl09VEYJcQwh9lt4vkXbmfJ4defV1UZ6GioqJiAbJxjVt5lJg9cQBCiEPAJ0ANsnFXbtVZJPMiO3ZWfw2sTQdz+V9FWmBQTxQw3k31bZDj26GZn/QvULdUNsddMBdLTAW1+FK1NyAL90LqTU8NLDTsbQfKlkk+hhjc8Sj7853h5a7cPigxuL+XUp5+3ctVnYWKioqKJchCN1SaTU+Nj10TQkwG9gIxwEWUrY5M7sotX7NJow5wq6ioqFgCvTT/lQlSyiVSympSynrAU+AGqXblllKeAvSA8fa6ZqK2LFRUVFQsQTYuyhNCOEkpQ4UQxYB2QC0U59AICEi9K/fraqjOQkVFRcUSZO8YzybDmMULoJ+UMkIIsRRYKoS4gjJLquvrdkGB6ixUVFRULEM2tiyklEaho6WUicAX2aWhOgsVFRUVS2BuGN93BNVZqKioqFiC/8VdZ4UQziiR8j4AIlD6v6YAu4FFQBWUGc+RKJHuYkxEylsnpZwkhGgETEMZbDkL9JBSJgkhGqCEU71jOH+zlPInIURRYCXggjJgs1BKOctwXT+jrFDUA6FANynlIyFETV5OMxPAj1LKLVmpmGRWrPPF1287Uko6tm1Ft88+5e/rNxk3aRpx8fG4FnJh2k9jyZMnt5FtozYdyZ0rF1ZWVmg0GjavXJyuzsgffyYg8AgO9gXYsVGJdxwZFcXg4aN5+CgY18KFmDllAnb58gGwYMlyNm7dhpWVFd7DhlL3w1pGeWZkbylNU6z03YLv9j+VOm71MV0/bce1G7f4cdpvPE9MRKPRMG7Id1SpUC6N3e179xkybkLK+/uPHjOgx5d0/dR0mNtXEbU/xsqzEQjQnzqAPPonovL7WDXuAI6u6OZ4w0PT0XhFnRZYeTYECfLxPfQb50PSi0w1V+48iO+Bo0gkHRvVpmuLRgCs2hXA6t2H0GisqP9eJX74PG2o0TuPQhgya8nLsoaG07+jV4p9pmX9oClWNRoqZT0TgDy+G6tmnRFl3wNdEvJpKPotiyDBOGCTVdueynmx0eh+H2mWXjIr1qzH12+b8tl+0ppuXTrz9/UbjJswhbi4OFwLF2LaL+NN3j/LV6/F1287QgjKlHJn4rjR5Mhhel3Su/JdzhL/sV1nM506a4iV7QcESilLSimro8TBLgIMBEKklJWllJWAHigDLADxUsqqqV6ThBBWwAqgs+H8u0DXVHKHU53/kyEtCRgqpSyP4qz6CSEqGI5NlVJWkVJWBXYAYw3pV4AahvTmwAIhRJZbUddv3cbXbzu+yxeydfUyAo4cI+jefUb7TGbod9+wfe0KGjeox+JVa9PNY8W8WWxdvSxDRwHQrpUXi+fMSpO2cNkKatX0ZM+2TdSq6cnCZcpiq5u3buO/ew/+G9exeM4sxk+cgs5EkzY9e0tqvsr120H4bv+TDQt/w2/ZfAKOnSTo/kOmzltMv6+/wG/ZPAb0+Iqp85YY2ZYsVhS/ZfPwWzaPTYt/xzZnDhrXq52hXgrORbDybIRuzmh0s4YjylUDBxfk4/vo/pgOQX+nb5uvAFYfNkc3exS6mT+AlRXCI/PY39fvP8L3wFE2+AzDb/IoAs5dISg4lJNXr7P/zCW2ThnFjmlj6N6ysZFticLObJk8ii2TR7Fx4ghsbaxp7OlhXlmdimBVoyG6BePQzRmNKFsV7J2RN6+g+30kujmjIfwxVvVamTTXnz+MbmXWtxW6fvMWvn7b8F2xhK1rVxJw+Khy//w8kaH9+7B9w2oaN6zP4pWrjGxDQkNZuc6XTX8sZceG1eh0Ovx370tX6134LmcZKc1/vQOYs86iEZAopZyfnCClvCulnA0UAh6mSv8neWl5OjgAz6WU1w3v9wLtMxKXUgZLKc8Z/n8GXANcDe9Tx+jMDUhDepyUMsmQnjM5PavcunMXj0oVsM2ZE61Wi2e1quwNCOTOvXt4vlcVgNrv12DPwYDXyT4NntWrYWeX9qllf0AgbVt5AdC2lRf7Dh5KSfdq1hQbGxuKurpSvGgRLl25apRnevaW1HyV23fv4VGhvKGONXhWrcK+wKMIBDGxsQA8i43FqaB9hvkcP3uBooUL4erinOF5yQgnV+T9G/AiEfR65J1riIqeEPYIngRnnoGVBqxtwMpKWYUfHZGpye2Hj/EoXQLbHDZoNRo8y5dm3+mLrNsbSK82TbGxtgbAwS5vhvmcuPwPRZ0dcXV0MK+sjoWR92++LGvQ34gKNZC3rqTE85b3b0K+dOr47j8QH2uWVmpu3QnCo1JFbG2T75/32HvwEHfu3sWz2nsA1H6/JnsOBJi01+l0JDx/TlJSEgkJCTg5pr9E4F34LmcZvd781zuAOc6iInAunWNLgeFCiONCiF+EEKVTHbMVQlxI9eqEMsfXWghRw3BOB6BoKptaQoiLQog/hRAVXxUTQrgB7wEnU6X5CCHuA5/zsmWBEOJ9IcRVlK6wb1M5D7Mp416CM+cvEhEZRXxCAoFHT/A4JJQyJUuyP1AJWr9r30GCQ9LbckXQo/8Q2n3Vg/VbtmVVnvDwpyk3iJNjQZ4+VX6QQsLCcEn1o+js5ERIaJjZ9u+SZukSbpy+eJmIqGjiExI4dOI0waFhjBrwLVPnLqZB+8+ZMmcRQ77pnmE+O/cH4NW4QablS0Y+vo9wKw+58oC1DVZlqyLym/fjS3QE+sM70IyYg2bUfEiIQ964lKlZ6aKFOXPtJhHPYoh/nkjghas8Do8gKDiUs3/fpNPoKXw5fgaXb93NMJ+dx8/g9WF1864VkKEPEG5lwdZQ1tIeCLu0jkFUq4+8cdHsPM2hTCl3zpy/oNw/8QkEHj3O45AQyriXZP+hwwDs2nfA5P3j7ORE9y+60NDrE+o0a0WePHmoU+v9LOlb4v7JEv+xlkWWu2aEEHOAOiitDU8hREmgKdAYOC2EqCWlvIahG8qEfWdghhAiB7AHpZsJFIdU3DDe0QKl66t0Krs8wCZgUOoWhZRyNDBaCDES+A4YZ0g/CVQUQpQHVggh/pRSJrxyLSn7rSyYOZXe3b5Kc63uJdzo+dXndO8/mFy2uShbuhQajQafMSPw+XUWc5csp1HdOthorU3W1drFc3F2LEj40wi+/m4wJYsXw7OaUZVkGVNTpZXewn+Pf0vT3a0YvT7/lB6DR5IrV07KlSqBVqNhrd8ORvT/hmYN6vLngUN4T5rOspmTTeaR+OIFB46eyNShpCHsEfpD29D0GA2JCcjgu+Y/wdnmRlSojm5Kf4iPw+rzQYiqdZAXjmRcVlcXerZuQg+f38mV04ZyxV3RWFmRpNMTHRvHul9+4PKtuwyeuYS9v403Wb+JSUkcOHuZwZ3bZK2sh/3RdBuulPXxvTRlFfVbg16HvHjM/DzNwL2EGz27fkH3vgPIlSsXZcsY7p+xo/GZOoO5i5bSqH5dbKyNf4aioqPZf+gw+7dvIm+evAwcPpqtO3fRpkXzN74uS9w/JvkfnA11lVRdRVLKfkKIgigbVSGljAE2A5uFEHqUTayupZeZlPI4UBdACNEUZbMrXnEAO4UQc4UQBaWUT4QQ1iiOYrWUcnM6Wa8B/DE4i1R5XRNCxAKVkq851bGX+61EhZp03x3btKRjm5YATJ+7AGcnJ9zdirN09nQA7ty9R8DR4yYvyNnwVOJgX4AmDepx6a9rWXIWDg72hIY9wcmxIKFhT7C3LwCAi5MTjx+HpJwXEhpqsomenv27ptmhZXM6tFR+BKYvWIqLkyPTFyxl9MA+ADRvWA/vyTPTtT984jQVypSioBlaqZFnDqI7cxAAq2adkVHhZtmJUpXgaRjEPlPyuXoKUbxMps4CoEOjD+nQSBnfmLF2K84OBbj96DFNPKsihKBKKTeshCDiWQz2+Yy7ow5fuEoFt6IUzJ+1gVZ57hC6c0o3ilXjjsjop0pZqtbBqkxVdMsnZSk/c+nYtjUd27YGYPrv85T7p4QbS+cq4wt37t4j4MhRI7tjJ09TxLUQ9gWUz7Rpo/qcv3g5S87CEt/lLPG/NsANHAByCiH6pErLBSCEqC2EKGD43waogDJonS7Je6obWhbDgfmG9y6GwXQMs5msgHBD2hLgmpRy+it5pe72ag38bUgvkTygLYQoDpQFgswoqxHhhqbno8ch7DkYSMumjVPS9Ho985aupHM746e8uPh4YmLjUv4/evI0pd1LZkm7Uf16+G33B8Bvuz8fNainpDeoi//uPSQmJnL/4UOC7t2nSiWjXrt07d81zfCISAAehYSyN/AoXo0b4FTQgVMXlK6dE2cvULxI4XTt/fcF4PVRg0x1jMht+MG1c0BU9DT7yVpGhiOKlVLGLADhXgkZ9jATK4XwKMXBPHrylL2nL+L1YQ0+quHBiavKMN6dRyG8SEqiQN48Ju39j57Fq3YNk8cyJHVZK9RAXjqOKFUZq7ot0a2eoYxn/AuEP1Wc0qPgx+w5EEDL5k1S0vR6PfOWLKNz+0+M7Aq7uHDx8lXi4xOQUnL81BncS7hlSdsS3+Us8R/rhhLmrP4WQhRCmTr7PhAGxKL8yOcAvkeZnmqF8mQ/XEopTUyd3SWlHCGEmAq0NJw/T0o506DxHdAHpVsqHhgipTwmhKgDHDbkleyKRxlaH5tQHIEexUl9K6V8KIT4EhiBMjNLD/wkpfTLsJDptCy69OpHZHQUWo2WkYO+o1bNGqxY58saX6WB06RhfYb2+wYhBCFhT/D2mcyimVO5//AR/X4YBSgDdS2bNaFP96+MBQxblA8Z4c2ps2eJiIzEwd6B/t/2onHD+gwaPorg4BAKFXJm1pSJ5LdTttuet3gpm7ZuR6PRMOr7IdSvozytjh7/C507tKNyxQpEREama28pTRlj3O/7eb8hREY9Q6vVMOK7b6hV4z3OXrqCz6x56HQ6ctjYMHZofyqVLU3Ik3DGTJ7Bwqm/ABCfkECD9l+wb/0K8pqYfgmgmz7CZLrmmx+VMQu9Dv2OP5C3riAqemLVupvy4xofiwy+i37pRMhbAKv2vdEvV7rCrBp3QFSppQwYPwpCv2kB6NIOi1l16mmk+cW46UTGxKLVaBj+ZTtqVS5HYlIS3vNXcS3oAdZaLcO++IQPKpUl9Gkk3gtXs3BEP6WszxNp2M+bvb+NJ28uW5NlAtBvNp61o+nh/bKsf65G3v4LzaBpoNVCXAygDHLrty+HvPmxatsT/R/TlHJ07IsoYRjfiYlGf2Az8pzxYK92+CyjtC49viUyKgqtVsvIIQOoVdOTFWvWs8Z3EwBNGjZgaP8+hvsnDO+fJ7LoN+WZ8Lf5i9i5Zx9arZbyZcvgM2YkNjY2aQWsNIAFvsu57N6430q3eZbZXkDTbqDFN2M3y1n8vyAdZ/Gv8/8tnoUJZ/Fvk56z+Lcx5SzeBqacxdvAlLP41zE4i7dOdjiLjTPNdxYdBlncWagruFVUVFQsgQUCgb0JqrNQUVFRsQRmxKl4l1CdhYqKiool+I/NhlKdhYqKiool+I+NF6thVVVUVFQsgdSb/8oEIcRAIcQVIcRVIcSgV459L4SQhvVxr43qLFRUVFQsQTbF4BZCVAJ6ATUBD6Bl8ho0w67dTYB7b3q5qrNQUVFRsQR6nfmvjCkPnEi1geohIHml4wxgGK+5mWpq1DGLZCw1X9tSg1yW2snSAnvwaIdNz/ykfwH94zuZn/QvIIoUzfykfwEZ8/Sta4p8jm9dM9vIwj2Yeh87AwsN2xWBEpLBxxCDOx5ly6UzQojWwEMp5cXs2PtKdRYqKioqliALA9xp9rEzPnZNCDEZJeRDDHARZSeM0SibvGYLajeUioqKiiXIxgFuKeUSKWU1KWU94CnKXnglgItCiCCUYHXnhBAur3u5astCRUVFxRJk49RZIYSTlDJUCFEMaAfUSg4/bTgehBI99MnraqjOQkVFRcUSZO+44SbDmMULoJ+UMts3YVOdhYqKioolyMa9oaSUdTM57vamGqqzUFFRUbEE6t5QKioqKiqZ8v9pbyghhDPKoo8PgAggEZgC7AYWAVVQAiNFAs0N8bVfDYq0Tko5KVWes4GvpZR5UqU1AGYC1sATKWV9Q3pzYBagARYn5yOEWI8SFAkgPxBpKh64OaxYux7fLduQKCEiu3XpxN/XbzBu4hTi4uJxLVyIaT//SJ5XAu/cDrrL4FFjU97ff/iQAd/0oluXTplrrlmP75atSCnp+Ekbun3eWdH0mUxcfDyuhVyY5vOTkSbA8lVr8fXbhhCCMqXcmfijNzlymBczwxJlBVi5YQu+23ciJXRs/TFdP23HtRu3+HHqLJ4nJqLRaBg3tD9VKpQzLu/6TWzcvgshoHTJEkwc9T05ctiYUDFR3vUb8d3mr9Rz65Z069yBv2/cZNyUGUp5C7kwbfxo8uQ2rueRv0wm4NgJHArkZ8fqZWbpAazcvhffvYFIJB2b1KNrq6YMnjaPoIePAYiOjSNf7lxsmTHeyHb07KUEnLmIvV0+tv/2s9maAH+cu4Hv5SBFt3IJvqpWmt+OXuXArUcIIXDIlYMJzWrglMc4qFJ0QiJj957jxpMohBD80rQ6VQs7mFfejVvx3bFbqeOWzejasa3y2U6f8/KzHdyXKuXLmrTX6XR06D0IJ0cHFkz6MV2dkT/+TEDgERzsC7Bj4zoAIqOiGDx8NA8fBeNauBAzp0zALp8SMXDBkuVs3LoNKysrvIcNpe6HtYzyzMg+W/j/sjeUIdypHxAopSwppawOdEaZojUQCJFSVpZSVgJ6oAy8AMRLKaumeqV2FDVQftxT6+QH5gKtpZQVgY6GdA0wB/gYJZzrZ0KICgBSyk7J+aPE7k4vbneGXL95C98t2/BduYSta1YQcOQoQffuM/qXiQz9ri/b16+icYP6LP5jtZFtSbfibF2zgq1rVrD5j6XY5sxJk4aZh2VUNLfiu3IpW9f9QcDhIwTdu8fonyYwdEBftm9YTeOGDVi8cpWRbUhoKCvXbWDTqmXs8F2DTq/Hf/fed7asANdv38F3+042LJqN3/L5BBw9SdD9h0ydu4h+X3+B3/L5DOjZlalzFxuXN+wJf2z0Y+OS39n+xyL0ej3++wPM0711B99t/vgumcfWlUsIOHqcoPsPGD1xGkP79GL76qU0rl+HxavWm7Rv59WcxTMmm6WVonn3Ab57A9kw1Ru/GeMJOHORoEchzPi+D1tmjGfLjPE0rVWdxh9UN2nftlFtFo4dkiVNgBtPovC9HMT6Lg3Z8mVjAm4HExTxjO41yuD3VRO2fNmY+iUKMffENZP2EwMuUsfNGf+vm7H5y8aUtDeODW6yvLeD8N2xmw3zp+O35HcCjp8i6MFDps5fRr+uXfBb8jsDun/B1PnpO9uVG7dRsnjmiwzbtfJi8Zy0wZcWLltBrZqe7Nm2iVo1PVm4TAkKdfPWbfx378F/4zoWz5nF+IlT0OmMxw/Ss882/mNhVd9knUUjIFFKOT85QUp5V0o5GygEPEyV/o+U8nlGmRl+/KeiLE1PTRdgs5TyniGvUEN6TeCmlPK2lDIRWAekCYZtcGifAmtfo3zcCrqLR+VK2ObMiVarxbPae+w9eIg7d+/hWa0qALXf92TPgYAM8zl++gxFXV1xLVQoc807QXhUroitrUGzejX2HjjEnbt38az2nqL5QU327D9o0l6n05Hw/DlJSUkkxCfg5GjeCldLlBXgdtB9PCqWN+hq8HyvMvsCjyKEICZOiWH+LCYWp4Kmn2RflldH/PPnOBW0N7+8FSuk0vVg76HD3Ll7H8/3PJTy1qzBnoBAk/ae73lk+Snz9oNgPMqWxDZHDrQaDZ4Vy7Lv5LmU41JKdh09jVfd901rVixL/rymQ8dmxK2nz/AoZI+ttRatlRWeRRzZf/MReXJYp5wTn5SEqTW+Mc9fcObBE9pXcgPARmNFvpzmtdxu372PR4WyL+vYozL7Ao8bf7YOpj+zx6FPOHTiNB1bNstUy7N6Nezs0n4e+wMCadvKC4C2rbzYd/BQSrpXs6bY2NhQ1NWV4kWLcOnKVaM807PPNnQ681/vAG/iLCoC59I5thQYLoQ4LoT4JXlTKwO2QogLqV7JfRXfAduklMGv5FUGKCCECBBCnBVCJAeydgXupzrvgSEtNXVRWjg3slo4gDLuJTlz/gIRkVHEJyQQePQYj0NCKeNekv2HDgOwa98BgkNCM8zHf/c+WjZrYr7mOYNmfAKBR47xOCSEMu7uqTT3m9R0dnKi+5ef07BFW+o0bUmevLmpU8v0D8+7UFaA0iXdOH3hMhFR0cQnJHDo+GmCQ8MYNaAPU+csokG7LkyZs5Ah33Y3Lq9jQbp37kij9l9Qt21n8ubORZ2aNcwsbwnOXLhERJShvMdP8jgkjDIlS7D/8FGlvAcCCA7NuLxZoXQxV85cvU5EdAzxz58TePYyj5+83CLjzF/XccifD7fCztmmCVDaIR9nHjwhMv458S+SCLzzmOBn8QDMPHKFRgt3suPaffp/WNHI9n5ULPa2ORi9+yzt/tjHmD1niXuRZHSeSd0SxTl98crLz/bEGeWz/a4XU+ctpUGHrkyZt5QhvbuZtJ/w+0K+//ZrXnerivDwpzg5KhutOjkW5OlTZTZpSFgYLi4v69jZyYmQ0DCz7bON/0ctizQIIeYIIS4KIU5LKS8AJVFaCvbAaSFEecOpr3ZDrRdCFEbpXpptImstUB3wApoBY4QQZcDkg9CrtfoZGbQqhBC9hRBnhBBnTDUx3Uu40fOrL+jebyA9+w+mbOnSaDQafMaOYo3vJtp98TWxcXHYWKc/9JP44gUHAo/QvHGjdM9Jo1myBD27fUn3vv3p+d0gypYpjUajxWfcaNZs2Ei7Ll2JjTWtGRUdzf6AQPbv2Mzh3TuIj09gq/+f5ulaoKwA7m7F6PXFp/QYPIJeQ0dRrlRJtBor1vptZ8SAbwnYvIaR/b/Fe6Lx/k5R0c/Yf+QY+zasJNBvLfEJCWzbvc9M3eL0/KIz3Qf8QM/Bwylbyl0p7+hhrNm0lXbdehMbF4+N1jrzzMwta9HC9Gz3MT3GT6PXTzMo51YUjeblLeh/+GS6rYo30nXIR0/PMvTYdITem49S1tEOrZVy+wyqU4kDvVvQsnxRVl+4ZWSr00v+Co2kk0dJNn/ZGFtrDYtP/WOerlsxenXpQI+h3vT6YSzlSpVAq9WwdutORnzXi4CNKxjZrxfeU2Ya2R48dgqH/HZUKlvaOOM3RJr48c2OvZNe40L+U87iTQa4rwLtk99IKfsZ9ks/Y3gfgzJWsFkIoUfZ3Mp0pyi8B5QCbho+tFxCiJtSylIoLYYnUspYIFYIEYiyDe8DIHVnZhHgUfIbIYQWZSWj6Q5gXtlv5Vm4yU+kY9tWdGzbCoDpc+bj7OSIu5sbSw39o3fu3iPgyLH0JAg8epyK5cpQMJ2mtmnN1nRs21rRnD0PZ2dH3Eu4sXTubxlqHjt5miKuhbEvUACApo0acP7SZdp4fWym7tsvK0CHlh/ToaVyjdMXLMXFsSDTFyxl9MC+ADRvVA/vyTOM7I6fOU+RQi7YF8gPQJN6dTh/+S9aN2tslm7H1l50bK10M0yft8hQ3mIsnTUVgDv37hNw9ESWypIZHRrXo0NjZTxnxqpNODson1WSTse+E+fYOG1sRuavTfvKJWhfuYSie+QKLq8MZHuVK0qfLcfo/2GFNOnOeW1xzmuLRyHlM21augiLT5vnLAA6eDWjg5fSjTR94QpcHB2YvmgFowd8A0DzhnXwnjrLyO7clb84cOwkh06eITExkZjYeH74ZSpTvX8wW9vBwZ7QsCc4ORYkNOwJ9vZKXbs4OfH4cUjKeSGhoSktCHPssw1Lbeb5mrxJy+IAkFMI0SdVWi4AIURtIUQBw/82KAPQd9PLSErpL6V0kVK6GRaPxBkcBcBWoK4QQiuEyAW8j+J0TgOlhRAlDBqdgW2psm0M/C2lfPAGZST8qdJN8OjxY/YcCKBlsyYpaXq9nnlLltO5/Sfp2vvv3otXFrpl0mgGP2bPwQBaNm+aVnPxMpOahV2cuXj5CvHxCUgpOX7qDO4l3LKu+xbLChAeEWHQDWXvoSN4NW6IU0EHTp2/BMCJsxcoXqSwkV0hZ0cuXv2b+ARDec+ep6RbMfN1nybrhrAn4DAtm3yUkqbX65m37A86f9Iqy+XJUDMyWtEMC2fvibMpLYnjF/+ihKsLLmaOuWRZNy5B0Y2OY9+Nh7QoV5SgiGcpxw/eCjY5cO2YOycueW2581Q598S9UNzNHOAGCI+IVHRDQtl7+Bhejevj5GDPqQvKhMgT5y6a/GyH9u7GoY0rObB+Gb+OHc771apkyVEANKpfD7/t/gD4bffnowaKk27UoC7+u/eQmJjI/YcPCbp3nyqVjLvg0rPPNv6/tCyklFII0RaYIYQYBoQBscBwwB2YZxhgtgL8UWYlgWHMIlVWu6SUIzLQuSaE2AVcAvQoU2SvAAghvkOZpqsBlkopU49SdeY1B7ZT03/YaCKjotBqtYwb/j12+fKxYu161vgqE6yaNKxPe8PTaUhYGN4/T2LRb78CEJ+QwLFTp/lp9PCsaX4/0lhzzXrWbNioaDZqQPs2LV9q/jSBRbNn4FG5Es0+asQnn3dFq9FQvmwZOrVr+06XFWDA6J+JjI5Gq9Eydkh/7PLl5edhg/GZNRedTk8OG2t+GjZI0X0SzphJ01k4zQePiuVp2rAu7br3VcpbphSdWrcwv7yjxhEZFY1Wq2Hc9wOxy5eXFes3smbTVqW8DerS3tDiCQl7gvfEaSyarkzeGzL2Z04Zxpbqte5I/57dUlopGTFwyhwin8Wg1WoY0/sL7AzTkHceOWXUBRX6NALvOctZOGYwAEN/nc+pq/8QGR1Dg55D+a5zm5RWSqa6208QGZ+ItZUV3h+9h11OG8buOcudiBisBBTOl4txH1VTdGPiGbPnLAva1QFgdMOqDPvzFC90eorY5canmXnjQgADxkxQPlutlrGD+mCXNy8//zAAn9kLXn623/cHDJ/tlN9YOMV42nBmDBnhzamzZ4mIjKRes5b0/7YXvb/+ikHDR7HRbxuFCjkza8pEAEq7u/Nx08a0aN8JjUbD2BHD0GiUEAWjx/9C5w7tqFyxQrr22cY74gTMRZjqv/t/STrdUP86Vhba+NdCTWCZEPPWNYUm+8YdsoKl4lnIw/4W0bVqYzwJ4d/GYvEsctm98SCHbuI3Zv/maEYusMCgSlrUFdwqKioqluA/9qCuOgsVFRUVS6A6CxUVFRWVTPmPzYZSnYWKioqKJVBbFioqKioqmfIfcxZqDG4VFRUVCyB1OrNfmSGEGCiEuCKEuCqEGGRImyqE+FsIcUkIscWwKetrozoLFRUVFUuQTYvyhBCVgF4om6t6AC0N+/HtBSpJKasA14GRb3K5ajeUgSH5S1pEd+rGXyyia1W9oUV0fyqdYfTHf4Vxj/9665oAIr/xFhJvRbdhW4voBjU2f0FkdrHvbraHmjaLXs+MNx7MMtnXDVUeOCGljAMQQhwCPpFSTkl1zgmgw5uIqC0LFRUVFUuQhZZF6k1PDa/eqXK6AtQTQjgYtkRqQdp98wC6A+btKpoOastCRUVFxRJkYepsmk1PjY9dE0JMRul2igEuAin7yAshRhveG0cuywJqy0JFRUXFEuj15r8yQUq5REpZTUpZD3gK3AAQQnQFWgKfyzfc20ltWaioqKhYgmycOiuEcJJShgohiqGEZqglhGiOsrFr/eTxjDdBdRYqKioqliB7V3BvEkI4AC+AflLKCCHE70AOYK8hTtAJKeW3ryugOgsVFRUVS5CNLQsppdE0w1QxgbIF1VmoqKioWIL/2AruN3IWQghnYAbwARABJAJTUAISLQKqoMTKjgSaSyljhBA64HKqbNZJKScJIT5CidlthTKi301KeVMIUQ5YBlQDRksppxm0iwIrAReUoEgLpZSzDMc6Aj+izD+uKaU887plrDewLx/0+AopJcFX/mJd9758/JM3FVo2R5eYSPjtO6zt3o+EqCgj25x2dnRaNBuXiuVBStb17MfdE6cz1fzjyEV8T19FSuhYswJf1amacmxp4Dmm7TzG0TE9KJDb1sh2xeELbDz9F0JAGRcHfDp8RI4M4manZuXmHfj+uQ8pJR1bNKFru5YM/uVX7txXotVGx8aSL3du/Bb8amS7fNN2Nv65DyEEpd2KMfGH78hhY2OW7gcD+vDe11+ChJArf7G1Vz/qjRhK2VYtkHo9sWFh+PXsR0zwYyPb1gtmU6ZFM2LDnjCv2odm6SWzYv1GfLfuUOq5jRfdOnfk7xs3GTd5OnHx8bi6uDDtJ2/y5M6dxi44JJRh4yfwJPwpVlZWfNq2JV07mTeFfeXGbfj671HquGVTunZow7Wbt/lx+lyeJ75Ao9EwbtC3VClfJq1maBjDJ87kydMIrITg05bN+KpDa7PLunLbbnx3H1TK2qwBXds0Z/Dk37nzMBiA6Ng48uXOhd9vPmnsnicm8sUIHxJfvECn09O0ticDPm9vSsIk+b7sRt72HUFKEm9c54n3CApOmIK1mxLi1SpvXvTPnvGoQxuzbGViolm6lfp9Q7muXyCl5OnVawT2GYDu+XMAKg/oywc+41npVpbn4U+NbIs0bkStKT4IKw3/rFzFxem/mV3eLPH/xVkYouD5ASuklF0MacWB1sBAIERKWdmQXhalLw0gXkpZ1USW84A2hmlgfQFvoBvKyP4AoO0r5ycBQ6WU54QQeYGzQoi9Usq/UOYdtwMWvG75AOwKF6Ju/2+ZUqkmLxIS+Grdct7r3J5/9h3Ef9SP6HU6Wk4cT+MRQ9gxcpyR/SczJ/H37n2s+PQrNNbWWOfKlanmjcfh+J6+yvp+HbHWaOi9bBv1yrnhVjA/wZHPOH7jPoXymw5rGRIVw6pjF9k+5HNyWmsZvHoXOy/e4JMa5TPVvX7nHr5/7mPD7MlYW2vpNfJn6tesxgzvoSnnTJq/nLy5jcsQ8iScP/x24r94Jjlz5GDQz9PwP3iEds0aZaqbt3Ahavb7hrkeH5CUkECH1Uup9Gk7jk6fzcHxEwCo2a839UcPw/+7IUb2F/5Yy6l5i/hk6fxMtdKU99ZtfLfuwHfpfKy1WnoOGkaDD2sxesJUhvfvQ81qVdm4fSeLV61j0Dc90thqNBpGDOhLxXJliImNo3233tSuWYNSmYSwvX7nLr7+e9gw71eljof9SP0PPJm6YDn9un5Gvferc+jEGaYuWM4fMycYaQ7v052KZdyJiYuj/TdD+LBGVUqZEUb2+t37+O4+yIZfxyu646ZS37MqM4Z/l3LOpCVryJvL+OHDxtqa5T4jyW2bkxdJSXw+/GfqVfegarnMezg0Ts7k+/xLHrZpgXz+HMdpM8n9sRdh3w9KOcf++xHoY56ZbRuzdUumurkKuVDp2174etZBl5DARysWU7LDJ9xYvY7croUp0rABz+7dN2krrKyo/eskdrbpSOzDR7Q9tIe7/ruI/Od6prpZxoxtPN4l3mTqbCMgUUqZcpdKKe9KKWcDhYCHqdL/kVI+zyQ/CeQz/G8HPDLYhkopT/PS2STnGSylPGf4/xlKXG5Xw/trUkrzo8pngJVWg7WtLVYaDda5bIl69Jjrew+gN3zQd0+exs5EDOEcefNSsm5tTi5ZCYDuxQuTrY9XuRUagUdRF2xtrNFqrPAs4cr+q7cBmLzjCEM/rk1GIbN0eknCiySSdHoSXrzAKV/uDM5+ye17D/AoVwbbnDnQajR4VqnIvqOnUo5LKdkVeAyvhnVM6+p0JDxPJEmnI/55Ik4O5seSttJo0drmRGg0WOfKxbPgxyQ+e/kDYpMrd7pPYfeOHCM+IuureG8F3cOjYgVsc+ZEq9XiWa0qew8d5s7d+3i+5wFA7Zo12HMw0MjWqaADFcspT/55cueipFtxQkKfZKp5++59PCqUfVnHHhXZd/g4AkFMrDJZ5VlsrMm6c3Kwp2IZd0UzVy7cixUh5Em4WWW9ff8RHmVLvdStVI59x182tqWU7DpyEq/6tYxshRDkts0JQFKSjqQkHSILMduEVovIkRM0GqxsbdGFhaY5nrv5x8Ts3PFatpnpJn+ntLlsiTO0Sj+Y9Asnx4xP9/vkWKMa0beDeBZ0F/2LF9za5EdxQ2jdbOc/FoP7TZxFReBcOseWAsOFEMeFEL8Y9ilJxlYIcSHVq5MhvSewUwjxAPgSmGTuhQgh3ID3gJNZLkUGRD0KJuDX2YwJusKPD6+TEBXN9b0H0pxT8+sv+HvXXiNbh5JuxIY9ofPSuQw5c5hPF87GxoyWRWkXe84EPSQyNp74xBcE/hNEcOQzDvx1B6d8uSlXOP0tJJzt8vB13ff4aNIK6k9YSp6cOahdJvMnT4DSbsU4ffkvIqKfEZ/wnEOnzhEc9vIH8Mzlv3DInx83E47RuaAD3Tu0ptHn31K3U0/y5s5FnRpVzdJ99iiY4zNnM/jmZYbe/ZuEqGhu7zsIQKPx3gy6eYXKn3VMaWVkF2VKluDMhUtEREURn5BA4LETPA4JpYx7CfYfPgrArv0BBIdm/AP14FEw167fwKNS5q230iWKc/rSVSKiopU6PnmW4LAnjPquJ1MXLKPBp92ZMn8ZQ3p9lbHm4xCu3byNR/myZpW1dPEinL76z8vP9sxFgp+87H45c/UfHPLb4VbYxaS9Tqen7YDR1P6yHx++VwmPsuaNm+pCQ4havoSi+wIodvAo+mfPiD92NOV4zuo10IU/Iene3SzbZkRc8GMu/TaXz/66wOc3r5AYFc3DAwEUa9GMuEfBPL1yNV3b3IUKEfMw5TmX2IePyF2okFm6Web/kbNIgxBijhDiohDitJTyAlASZQzCHjgthEi+m+KllFVTvdYb0gcDLaSURVDGKKabqZsH2AQMklJGZ/GaU5bQX5LGfaG2+fNTqbUXv7hX4cciZbHJnYvqn3+acrzxyO/RJyVxdvUGI1srrRbXah4cm7+E6TXqkhgbS6PhgzO9Jncne3rWr06PJdvovXQ7ZQsVRGtlxYKDZ+jf9P0MbaPiEjjw1232DvuKgFFfE5/4gm3nzWtguRcvQq9ObekxfDy9Rv1MuZJuaA1B7AH8Dx5Jt1UR9SyG/cdPs++PuQSuW0R8QgLb9h0ySzdnfjvKtmzBrLJVme5WHpvcuaj8mVLHB8b9wsxSlbi81peafXqZlZ+5uJcoTs8vP6N7/+/pOWgYZUu7o9Fq8Bk9jDUb/WjXtTexcXHYaNOP3x0bF8eAkeMYNeg7o3ENk5rFi9Krczt6/DCWXsPHUc69BFqNhrVb/2RE354EbFjKyL498Z46O33N+HgGjJ3EyH49yWOiS9CkblFXerX3oseYyfT6cSrlShRDmyr2u3/gcbzqfZCuvUZjhd9vPgQsm8Wl67e5ftd0F86rWOXLR66GH3G/WSPuNaqDsM1F7pYvx1lyt2hJzE7T8cIzs80Im/x2uHk1Z13l6qwuXRlt7lyU/uxT3vt+MGd8MnkGNdVs+rd+rPXS/Nc7wJs4i6sog84ASCn7AR8Bjob3MVLKzVLKvsAqlP1KTCKEcAQ8pJTJLYP1QKajlUIIaxRHsVpKuTmrBZBSLpRS1pBS1qgijAdjyzRuwNOgu8Q+CUeflMTlLdtxq6X8YNf46jMqeDVj1Remf8SiHjwk6sFD7p06C8DFTVspUs3DrOtq71mBTQM68ce37bCzzYlrgXw8fBrNJzPX0XjSCkKiY2j/23rCnsWmsTt+8wGu9vmwz2OLtUZDk4ruXLgbbHZ9dPi4MZvnTWPV9F+wy5uH4q7KE1WSTsfeIydp0aC2Sbvj5y5RxMUJ+/x2WGu1NKnzAef/Ms9JlWzUgMigu8QZ6via33aK1qqZ5pzL6zdS/hPzB3PNpWNrL7asXMTq+b+RP18+ihcpgrtbcZb+No3NKxbi1fQjippoSQG8SEpiwMhxtGrWmKYN65mt2cGrKZsXzmTVrEmGOi6M354DNK2ndAE1b1CbS3+b7h9/kZTEgLGTaNW4Pk3rZW0wv0PTBmye9QurJnljlzc3xQ2tiCSdjr3Hz9CibvrOIpl8eXJTs3I5Dp+9ZJZmzg8+JOnhA/QREZCURNz+PeSs+p5yUKMhd+OmxO4y7SwytM0E1wb1eXb3HglPwpFJSQRt86fMF5+R160Y7Y8F0PnKWXK7Fqbd4f3YOjmlsY199Ig8rq4p73O7Fib2sfHEiuxASmn2613gTZzFASCnEKJPqrRcAEKI2kKIAob/bYAKgHFb8yURgJ0QInkKSBOUMYh0MQywLwGuSSnNaoVklYh79yn+fg2sbZWBv9KN6hNy7R/KNfuIRj8MYknbzryIjzdp+ywklMj7D3EsozTZyzSqT4iZP6DhMUr/9aPIZ+y7eovW1cpyZEwP9o3oyr4RXXHOl4dNAzrhmDft02yh/Hm4eC+E+MQXSCk5ces+JR0LmF3e8AhlTOVRaBh7j55IaUkcP3eJEkVdcXF0MGlXyKkgF69dJz7hOVJKjp+/TMliRczSjLr/ANf3a6A11HGJhvV58vc/2Jd6uQtw2ZbNefIvDDCGP1XGOh49DmFPQCAtm36UkqbX65m37A86m3BSUkpG+0yhpFsxvu7yqdHxDDUjIhXNkDD2Hj6O10f1cHKw59TFKwCcOHeJ4q7GDkpKifeU2bgXL8LXn7bNkiZAeGTyZ/uEvcfOpIxPHL9wlRKuhXApaHqM6WlUNNExykNJwvNEjl+4Ssl0HOir6IIfkaNKVUROZcwj5/u1eHFbGX+z/eBDEm/fRhcSkmXbzIh58AAnz+poDN+pwg3qEbTNn1UlK7CuUnXWVapO7MNHbK77EfGvdDOGnT1PPvcS5C1eDCtra9zbt+We/y6zdLPMf6xl8dqzoaSUUgjRFpghhBgGhAGxKMvL3YF5hh90K8AfpQUAhjGLVFntklKOEEL0QlmFqEdxHt0BhBAuwBmUwW+9IbBHBZRpuV8Cl1PlN0pKuVMI8QkwG6WV4y+EuCClbJbVMt47dZaLm7Yy5Ewg+qQkHl64xPFFyxl++SSaHDZ8u9sPgLsnz7Cx72DyFXKh06LZLGrZEYDNA4fxxR+L0dhYE34niHXd+5mlO3DVn0TGJWBtZYV3m/rY5cqZ7rmh0TGM2XSQBV+3wqOYC00ru9Nh9no0VlaUL+zIp+9XMru8A36aSmT0M7RaDWO/64Vd3jyA0gXV8pUuqJAnTxkzfS4LJ3jjUb4MTevWol3f79FqNJR3L0GnFk3M0nx4+izXNm/jm5MB6JN0BF+4xNnFK2i3chEFy5RG6vVE3rufMhMqTyEXWs//jTVtlB/pdisX41avNrkKOjD41hUCfp7E+eWrzNLuP3IskVHRaLVaxn0/CLt8eVmxfiNrNvoB0KRBXdobBjdDwp7gPWEqi2ZM5uzFy2z9cw9l3EvS5ktlptSQPr2o/2HmT+cDxk1S6lijYezAb7HLm4efv/8On9mL0Ol05LCx4aeh/Qx1HM6Yab+zcNI4zl25xta9BylTsjhtew4EYHDPL6n/QQ2zyjpg4m9EPotRdPt0xS6P8qDhH3iclq8MbIeERzBm9mIW/vgDYU8jGTFzITq9HqnX07zO+zSsad4T/vPLl4jdu5vCG/xAl0Ti39eI9l0HQO6PvYj9M+3AtsbRiYLjfQjp2ytD28wIO3OO237baXdkP/qkJMIvXubaspXpnp/LxZm6v89kd4fPkDodx74fycd+GxBWVvzzx1oi/s6WuTJGSN1/Kwa3eFeaOJZmiMbOIhWhxrP497FUPAsZn6UhtOwjJvNZd/8GQe2+eOuaFoxnkYU5YaZJ7NHU7N8cmyV73ljvTVFXcKuoqKhYgneke8lcVGehoqKiYgH+a706qrNQUVFRsQRqy0JFRUVFJTNk9m5R/q+jOgsVFRUVS/Afa1moYVVVVFRULEB2LsoTQgwUQlwRQlw1LC9ACGEvhNgrhLhh+Gv+oisTqM5CRUVFxRJk06I8IUQloBdQE/AAWhr24xsB7JdSlgb2G96/Nuo6i2Se3P//VRHWOSwiKyPM334k27A1vaX7v43Ia3rF+7+NDLtnEV393be/nkVTo/lb1wQgl90br3uI/7Su2b85thsOp6tniN/TTErZ0/B+DPAc6AE0kFIGCyEKAQFSSvN2nzSB2rJQUVFRsQBSL81+pd701PDqnSqrK0A9IYSDECIXyj58RQFnKWUwKCEdACfjqzAfdYBbRUVFxQJInfmdGVLKhcDCdI5dE0JMBvaiRBm9iBIcLltRWxYqKioqliAb41lIKZdIKatJKeuhRBe9AYQYup8w/DU/epQJVGehoqKiYgmycddZIYST4W8xlJDSa4FtQFfDKV2BrW9yuWo3lIqKiooFyObJRZuEEA4o4af7SSkjhBCTgA1CiB7APaDjmwiozkJFRUXFEmTjojwppdF2zlLKcJSAdNmC6ixUVFRULMB/LZ7FGzkLIYQzMAP4ACVgUSIwBdgNLEIJUCSASKC5lDJGCKEDLqfKZp2UcpIQohEwDbABzgI9pJRJBp0GwEzAGngipaxvSB+IshhFAIuklDMN6VOBVobruQV8LaWMfJ0yrtiwGd9tO5FS0rF1C7p1as+16zcZN3UmzxNfoNFo+PH7AVSpUM4s23dVE2DFOl98/bYrtm1b0e2zT/n7+k3GTZpGXHw8roVcmPbTWPLkMY433ahNR3LnyoWVlRUajYbNKxebrbtyy058/9yv6H78EV3beTHYZwZ3HjwCIDo2jny5c+E3b2oau9v3HzFkwoyU9/cfhzLgy0/p2s7LPF1fP3x37FJ0Wzan66efcO3GLX78dXZKPY8b3I8qFYynpkc/i8F7ykxu3LmLQOAzYjDvVSpvQgVG/vgzAYFHcLAvwI6NSgCfyKgoBg8fzcNHwbgWLsTMKROwy5cPgAVLlrNx6zasrKzwHjaUuh/WMsozI3uTZd3ij+/OfUgkHT9uTNd2LRnsM50795PrOJZ8uXPjN3+ake3yTdvZuGs/AkHpEsWY+H0/ctgYhyE2xR/7juN7+KxSx/Wq81XjD/l92wE2Hj5LAcP3aFC7xtSvXMYs2/R4F+o4y/zH1ri99gC3IQqeHxAopSwppawOdAaKAAOBECllZSllJZTFIS8MpvFSyqqpXpOEEFbACqCz4fy7GAZmhBD5gblAayllRQz9bhmsWgRlClklKWUV4Dow8nXKeP32HXy37cR38e9sXbGQgGMnCLr/gKlzF9Gv+1dsXbGAgT27MnWu8Yy29GzfRU2A67du4+u3Hd/lC9m6ehkBR44RdO8+o30mM/S7b9i+dgWNG9Rj8aq16eaxYt4stq5eliVHcT3oHr5/7mfDbxPwmz+VgJPnCHoYzIzRg/GbNxW/eVNpWvt9mtR+38i2ZNHCKeds+n0ytjlsaFy7pgkVE7q3g/DdsYsNC2bit3QuAcdPEXT/IVPnLaFft8/xWzqHAd2/YOr8JSbtfX6bT933a/DnqkX4LZuDe/Gi6Wq1a+XF4jmz0qQtXLaCWjU92bNtE7VqerJw2QoAbt66jf/uPfhvXMfiObMYP3EKOp3OKM/07E2W9c49fHfuY8PsSfjN/5WAk2cNdTwEv/nT8Js/jaZ1PqBJHeM6DnkSzh9+f7Lx98lsXzQDvV6Pf8DRdLVSc+NhCL6Hz7J+VG+2jOtLwKXrBIWEA/BV41psGdeXLeP6mnQUGdmawtJ1/DpkZZ3Fu8CbzIZqBCRKKecnJ0gp70opZwOFgIep0v+RUj7PIC8H4LmUMjnQ8l4g+ZG4C7BZSnnPkFfy9K/ywAkpZZyhBXII+MRwzp7kVglwAsWBZZlbQffwqFge25w50Wo1eFb1YG/gUYSA2FglLvGz2FicChqv1E3P9l3UBLh15y4elSoYbLV4VqvK3oBA7ty7h+d7VQGo/X4N9hwMMCs/c7l97yEe5UtjmzMHWo0Gzyrl2Xf0VMpxKSW7Ao/j1bB2hvkcv3CZooVccHV2NE/37n08KpRLVVeV2Xf4GEIIYmKVGOjPYuNM1nNMbCxnLl6hg5cSqdfG2pp8hhC0pvCsXg07u7RPpPsDAmnbSmkBtW3lxb6Dh1LSvZo1xcbGhqKurhQvWoRLV64a5Zmevcmy3n+AR/kyL+u4cgX2HT2ZclxKya5Dx1Jirr+KTqcj4XkiSTod8c+f42Rv3hZDt4LD8ChZBNscNopuGTf2nzdvlXdWbS1dx69FNk6dfRu8ibOoCJxL59hSYLgQ4rgQ4pdUT/xgiMGd6tUJeAJYCyGSAwp3QFmBCFAGKCCECBBCnBVCfGVIT2/V4qt0B/58nQKWKenGmYuXiIiKIj4hgcDjJ3kcEsqogX2ZMnch9T/5jMm/L2DItz3Ntn0XNQHKuJfgzPmLREQabI+e4HFIKGVKlmR/4BEAdu07SHC6+Ql69B9Cu696sH7LNrM0AUq7FeX05WtERD8jPuE5h06fJzjs5RPkmSvXcChgh5troQzz2RlwFK8GGTuUNLolinP64hUioqKJT0jg0InTBIeGMar/N0ydt4QG7b9kytzFDOndzcj2/qPH2Oe3Y+TE6XzSox/ek2cSF59gtjZAePhTnBwLAuDkWJCnT5XwoCFhYbi4OKec5+zkREhomNn2JsvqVozTl/9Kv44vp1/HzgUd6N6xNY2+6EPdzr3ImysXdWpUNauMpV2dOXP9LpExccQ/TyTw8nWCnyqhZtccPEXbH+cwevkWomLjs2RrLm+zjl+LbJw6+zbItgFuIcQcoA5Ka8NTCFESaAo0Bk4LIWpJKa9h6IYyYd8ZmCGEyAHs4eUKRC1QHWVU3xY4LoQ4Yc6qRSHEaEPa6nSuuTfQG2DBrxPp/dXnaY67uxWn5+ed6T5oOLlsbSlbyh2NRsPaLdsZ2b8PzRrWY+f+AEZPnMbyWVPNss0MS2gCuJdwo+dXn9O9/2By2eaibOlSaDQafMaMwOfXWcxdspxGdetgo7U2ab928VycHQsS/jSCr78bTMnixfCsVjVz3WJF6PVpG3qM/IVcOXNSrkRxtJqXzzD+BzN3Aokvkjhw4ixDuncxq6wA7m7F6NWlIz2GjCKXrS3l3Eui1WhYu9WfEd/1plmDOvx5IBDvyTNZNmNiGtsknY6/btzEe1AfPCqUw2fWfBat3sDAnl+lo2Y+pqZTKj2+r49Sx23pMeInpY5LFkdrlaqOA46k26qIehbD/mOn2bdyDnnz5GbQz7+ybV8grRvXy1y3kCM9m9ehx4wV5MphQ9kiLmg1VnRuUJM+LRsggN+2HmCK7y58un1ilm128G/UcXZdx7vMm9T+VaBa8hspZT+UH3RHw/sYKeVmKWVfYBXKk3+6SCmPSynrSilrAoEoKxABHgC7pJSxUsonhmMeBhtTqxYBEEJ0BVoCn8t0PhUp5UIpZQ0pZY1XHUUyHVt9zJZl81k9dwb58+WleFFXtvy5h6YNlJlqHzeqz6W//jHb1hwsoQnQsU1LtvyxlNULfye/XV6KFyuKu1txls6ezuaVS/Bq+hFFi5jOz9nwBOZgX4AmDepx6a9rZut2aN6IzXMms+rX8djlzUNxwxNukk7H3qOnaFE//YFNgMOnz1OhVAkKFshvtiZAh5bN2Lzkd1b9PhW7fHkpXsQVv137aFpfcU7NG9bl0jXjenZxLIizY0E8DBMMmjWow1/Xb2ZJ28HBntCwJwCEhj3B3tC14+LkxOPHISnnhYSGpjzdmmOfblk//ojNc6eyavrPxnV85CQt6pt2yMfPX6KIixP2+e2w1mppUud9zqfz3TNF+7rV2TSmD38M64FdbluKOzlQMF8eNFZWWFlZ0bFudS7feWi2bVZ423WcZXR681/vAG/iLA4AOYUQfVKl5QIQQtRO3jtdCGEDVEAZtE6XVCsQcwDDgeSxkK1AXSGE1tDd9D5w7RWb1KsWEUI0N+TRWkoZ9wZlJDxCaXo+ehzCnkNHaNm4EU4FC3Lq/EUATpw9j1s6P8imbN9VTYDwp6lsDwbSsmnjlDS9Xs+8pSvp3K6NkV1cfHxKP39cfDxHT56mtHtJ83UjoxTd0CfsPXoqpSVx/NxlShQtjItjxj8S/lnsgkrRjYhUdENC2Rt4FK/G9XFycODUBWWy3olzFyhuwjk6OthTyMmR2/eUyQPHz17A3a1YlrQb1a+H33Z/APy2+/NRA+VJvVGDuvjv3kNiYiL3Hz4k6N59qlSqaLZ9+mVNruMw9h45mdKSOH7uEiWKuqZbx4UcC3Lx7+vEJzxHSsnx85cpWcz8B5Dw6BhFNzySfeev0aJmZcIin6Uc33f+GqVdTe9vZ8o2K7ztOs4q2RnP4m3w2t1QUkophGiL0nU0DAgDYlF+pN2BeYYZU1aAP7DJYGorhLiQKqtdUsoRwA9CiJaG8+dJKQ8YdK4JIXYBlwA9sFhKecVga7Rq0ZD+O5AD2GtoXp6QUn77OuXsP2o8kdHRaLVaxg3tj12+vPw8fDATZs0lSacjh40NPw0bDEBI2BO8J01n0a8T0rV9VzUB+g/3JjI6Cq1Gy7gfBmOXLy8r1vmyxnczAE0a1qd9qxYvdX0ms2jmVMKfRtDvh1GAMhjaslkT6tUynlmTHgN++pXIZ8/QarSM/a4HdobBYv9DR2n5ihMICX/KmBkLWPiLMsEtPuE5R89dYvzA3kb5Zqo75hcio5S6Gju4L3Z58/LzsAH4/LYAXXI9/zBA0X0SzpjJM1k49WcAvAf24Yefp/DixQuKFi7EhJGD09UZMsKbU2fPEhEZSb1mLen/bS96f/0Vg4aPYqPfNgoVcmbWFKWrq7S7Ox83bUyL9p3QaDSMHTEspStx9Phf6NyhHZUrVkjXPt2y/jyVyOgYtFoNY/v3fFnHAUdp2dBEHU+fx0Kf0XiUL0PTurVo1/cHtBoN5UuVoFOLJmbX8cB564iMjcdaY4V3Fy/sctsyfMkm/r4fjEDgWjA/P37RGoDQyGjGrNjKgoFfpmv7LtdxVpHvRoPBbNR4Fsmo8SzeCmo8i38fNZ7FWyAb4lk8/bCS2b859seuvP1BlVdQV3CrqKioWID/2nO66ixUVFRULMB/rVdHdRYqKioqFkD/jqyfMBfVWaioqKhYgP9Yw0J1FioqKiqWQP8f8xZqpDwVFRUVC5CdW0MJIQYLIa4KIa4IIdYKIXIKIaoKIU4YtlU6I4Qwb5fNdFCdhYqKiooFyK5dZ4UQrsAAoIZh124Nyg7gU4Dxhu2VxhrevzZqN5QBGWW8kdhb0Y3L2uZo2YXIaRyT4m0gnxtvGvdvIyy0zsJSCMesrSbPNtbOeeuS+lzZGF8iC1jV+PiN89Bn76I8LcqC5xcoO2k8AiSQXEF2hrQ3ElBRUVFRectkZeps6k1PDSyUUi405PNQCDENJc52PLBHSrlHCHEf2G04ZgVkvMlaJqjOQkVFRcUCZGV82+AYjCOeAYZ9+NoAJVCikvoKIb5ACQw3WEq5SQjxKbAEZRfw10Ids1BRUVGxAHopzX5lQmPgjpQyTEr5AtiM0oroavgfwBfFebw2qrNQUVFRsQDZOBvqHvCBECKXYfPWj1B25n4E1Dec04hUIRxeB7UbSkVFRcUCZNd2H1LKk0KIjSiRS5OA8yhdVueBWUIILZBA2jGPLKM6CxUVFRULkJ3bfUgpxwHjXkk+ghJlNFtQnYWKioqKBfivxbMwy1kIIZyBGcAHQASQiLLAYzewCKgCCJSR+OZSyhghhA64nCqbdVLKSUKI74BBKAGSHA2hUhFCtAF+RglwlAQMklIeMRwbCPQyaCySUs40pNsD6wE3IAj4NFUApOQIen8BP0opp5lfLS9Z6fcnvrsPIKWkY/NGdG3bgsETZ3HnoRKXITomlnx5cuP3+yQj20bd+pPb1haNxgqNlRWbfptgnqb/fnz3HVE0G9eha0tlAsOqnQdYvSsAjZUV9atX5ocv25tta5bu1l347g5AIunYrCFd2zRn8OTZ3HlgKGtsHPly58Jvtuly6HR6Ogweg5NDARaM+9583R378N13WLnmJvXo2rIxg39dQNCjxwbdePLltmXLr68+OMHh81eYsHQder2eDh/VpVc78+e/r/T1w3fHLkW3ZXO6fvoJ127c4sdfZ/M88QUajYZxg/tRpUJZI9voZzF4T5nJjTt3EQh8RgzmvUrlTeqM/PFnAgKP4GBfgB0b1wEQGRXF4OGjefgoGNfChZg5ZQJ2+ZQp8QuWLGfj1m1YWVnhPWwodT+sZZRnRvaW1k2NqNEI4VEbEMiLR5BnDiAatkOUqgK6JIh8gt5/Bby6/sbeGas2PV++z18QeXg78syBdLVSs3LXIXwPHkdK6NjwA7p+3ACAVbsDWb33MBorDfWrVuCHLq2NbD8aOJ7cOXOisRJoNBo2/jLULM2s8j+366xhwMQPWCGl7GJIKw60BgYCIVLKyob0sihR6wDiDSsHX+UosAMIeCV9P7DNEIGvCrABKCeEqITiKGqiOKldQgh/KeUNYASw3+CERhjeD0+V5wzgz8zKmB7Xg+7ju/sAG2b8grW1ll5jJlHf8z1mjByYcs6kRX+QN3eudPNYOcmbAnbmLxy6fu8hvvuOsGHSSKy1Gnr98hv1q1cmJDyS/acvsvXXMdhYWxMeZbyYLz1bt0LOZpY1gA3TxytlHTuF+jWqMmN4/5dlXbw647Ju20XJooWJiTN/4Z1yzYfZMHkU1lotvX6eRf1qlZkx9JuUcyYv30CeXMZR0nQ6PT8vWsOSsYNxdijAp8N9aOjpQamihTPXvR2E745dbFgwE2utNb1+8KZ+rZpMnbeEft0+p94Hnhw6foqp85fwx2/GC199fptP3fdr8NvP3iS+eEFCwvN0tdq18uKLTh0ZPubHlLSFy1ZQq6Ynvbt3ZeHSFSxctoIfBvbn5q3b+O/eg//GdYSEhfH1t9+x229jSiS3zOzfBd0UChZGeNRGv2IS6HRYdeqPvHUFeecaMsAPpB7R4BNErebIgC1pbZ+GoF/mo/wvBFb9JiGvX0i3jlNz/X4wvgePs+GnIcp9MHkB9d+rqNxDZ6+wdeJwbKy1hEc9SzePFd79KGCIJvhv8R/zFWbNhmoEJEopk2NiI6W8K6WcDRQCHqZK/0dKmf5do5xzXkoZZCI9Rr50tblRVh8ClEcJixonpUwCDgGfGI61AVYY/l8BtE3OzxDy9TZw1YwymuT2/Yd4lC2Nbc4caDUaPCuVZ9+x06mvmV2HT+BV/43WuqTVfPAYjzIlsM1ho2hWKMO+kxdYt/sQvT5pjo21NQAOJhxQerbm6T7Co5x7qrKWY9/xMynHpZTsOnISr3rGT5sAj5+Ec+j0BTo2bZDF8gbjUaYktjkMuhXLsO/U+bS6x87gVcd41t+lm3co5uJIURdHbKy1tKjjyYHTZpb37n08KpTDNmdOtFoNnlUrs+/wMYQQKfHEn8XG4VTQONpdTGwsZy5eoYNXMwBsrK3Jl8EPi2f1ati98nntDwikbSsvANq28mLfwUMp6V7NmmJjY0NRV1eKFy3CpSvGX+H07N8F3RQcXJCP7kDSC5B65L0biDJVIehaSh+MfHQH8hZIPw+A4uUg8glEP834PAO3H4XgUcrt5X1Q3p19py+xbv9RerX+CBtr5RnZwc6yK/uzcersW8EcZ1ERZZTdFEuB4UKI40KIX4QQpVMdszVsYJX86pSZkBDiEyHE3ygxu7sbkq8A9YQQDkKIXEALoKjhmLOUMhjA8NfJkE9ulBbGeDPKly6lixfl9JVrREQ/Iz7hOYfOXCD4SXjK8TNX/sYhvx1uroXSKw89vCfSbsAo1v+53zzNYoU589cNIp7FEP88kcDzl3kc/pSg4BDOXrtBpxET+XLsNC7fDDLb1ryyFuH0lX9SlfVi2rJe/cdQVheT9hMWruL77p9hiHluNqWLuXLmr+uGa35O4LnLPH7y8prP/HUDh/z5cCts3DoKfRqJS0H7lPfO9gUICY80T7dEcU5fvEJEVDTxCQkcOnGa4NAwRvX/hqnzltCg/ZdMmbuYIb27Gdnef/QY+/x2jJw4nU969MN78kzi4hOyVO7w8Kc4ORYEwMmxIE+fKr2nIWFhuLi8LKuzkxMhocZb0aRn/07pPnmEKFoacuYGrTXCvRLkS+sYrKp8CLevZHjNokIN5F+nMzwnNaWLuHDm71tEPItV7oMLf/H4aSRBwaGc/fs2ncZO58ufZ3P5lunws0IIekyaT/vR09hw4JjZulklOzcSfBtkeYBbCDEHqIPS2vAUQpQEmqIsDDkthKglpbxG+t1Q6SKl3AJsEULUQxm/aCylvCaEmAzsBWKAiyhjGhkxHphhGDvJqCwpS+jn/zKa3p3bpTnuXsyVXh1b02P0BHLlzEm5EsXQpmqW+x86hleD9FsVa6b9iLODPeGRUXQfPYGSRQrjWdl0v3aKZpFC9GzbjB4/zSRXzhyUK14UjZWGJJ2e6Jg41k0cweWbQQyevpC9c3zS/DinZ2sO7kVd6dWhJT3GTEqnrMfTbVUcPHUeh/z5qFSqBCcvZS0Os3LNzekxfoZyzW5F0nR9+B85ZbJVAab7fM31Ve5uxejVpSM9howil60t5dxLotVoWLvVnxHf9aZZgzr8eSAQ78kzWTZjYhrbJJ2Ov27cxHtQHzwqlMNn1nwWrd7AwJ5fmV/wdDBdpn8//PK/ohv+GHliN1adB8KL58jQB2k2RBK1Pga9Hnn1VPp5WGkQpTzQB/iZLevu6kLPVh/RY9I8cuWwoVwxVzRWViTp9UTHxrFu/GAu377H4NnL2TtjjFE514wbiFMBO8KjntFj0jxKFHLGs7x7VkufKf+LwY+uAikjqVLKfkKIgsAZw/sYlFWCm4UQepQn/2tvclFSykAhhLsQoqCU8omUcgnKUnWEEBOAB4ZTQ4QQhaSUwUKIQkCoIf19oIMQYgqQH9ALIRKklL+/opOyhF7eOmfyk+vQrCEdmjUEYPrydSlPskk6HXuPncpw0NrZQTnXIb8djWt5cun6rUydBUCHj+rQ4aM6AMxYvQVnhwLcfhhMk/ffQwhBldIlsBKCiOgY7F9pSpuyNZcOTRvQwdCNNH3F+rRlPX6aTTN/Nml37q/rHDh5jkNnLpKY+IKY+Hh+mDaXqd/3NU+3cV06NK5ruObNKdecpNOx7+Q5Nk71Nmnn7FAgTSsk5GkETvb5zdIE6NCyGR1aKl1J0xcux8WxINMXLmP0gG8BaN6wLt5TZhrZuTgWxNmxIB4VygHQrEEdFq3eYLYugIODPaFhT3ByLEho2BPs7ZUyuzg58fhxyMsyhYamPMmbY/+u6cpLx5CXlKdzUa8NPItU/q/0AaJUZfRrZ2R8we6VIOQexKU/vmCKDg0+oEODDwCYsX4Hzvb5uf0ohCaeVZR7yL24cg89i8U+X9ouRKcCdkpZ7fLSuEZlLt+++684i//aALc53VAHgJxCiD6p0nIBCCFqG/YlQQhhA1QA7r7OhQghShkG0xFCVANsgHDD++TupWJAO2CtwWwbypJ2DH+3Akgp60op3aSUbsBMYMKrjsJcwiOjAHgU+oS9x06njE8cP3+ZEkUK42KiTxsgLiEhZaA3LiGBo+cvUaZ4EfM0DYPXj8KesvfkebzqePKRZ1VOXPkHgDuPQniRpKNAPuN+clO2r1XW42delvXClQzLOrRbJw6tmM2BpTP5dVg/3q9SwWxHkfaaw9l74nxKS+L4pWuUcC2Ei4O9SbvKpdy4GxzKg5AwEl8ksfPIaRrW8DBfNyJS0Q0JZW/gUbwa18fJwYFTF5RJfCfOXaB4EVcjO0cHewo5OXL7nvLMcvzsBdzdsrbTa6P69fDb7g+A33Z/PmpQT0lvUBf/3XtITEzk/sOHBN27T5VKFc22f+d0cxkeZvIVQJR9T+lOKlEB8UEz9BvnKuMZGSDKZ60LKpnkwetHTyLYe/oSXh9W46PqlTnxl7KI+U5wqHIP5U27+3JcwnNiDV2KcQnPOXr5H0oXMd3N/Kb8z3VDGWYntQVmCCGGAWFALMqYgDswz/Ajb4Uy1rDJYGorhLiQKqtdUsoRQogBwDDABbgkhNgppeyJ0nr5yrDFbjzQKdWA9yYhhAPKTKt+qabHTgI2CCF6oCx57/hatZABA3xmEBkdg1arYWzfr7EzDGT6Bx6n5SsD2yHhTxkzaxELfxpOeEQU3/0yHQCdTkfLBrWpW6OqWZoDpy4gMiYWrUbDmJ6fYZcnN+0a1cZ77gpaDR6PtVbDxO+6IYQg9Gkk3vP+YOHo/unaml3WCbOIfBaDVqNl7LddU2z9A0/Q8pUuqJDwCMb8tpiF438wO//0yzuPyGeGa+7VJUV355FTRs4u9Gkk3nNXsNB7IFqNBu+eXej580z0ekm7RrUpXcz4xz09Boz5hcioaLRaLWMH98Uub15+HjYAn98WoNPpyGFjw08/DFDK+yScMZNnsnCq0rryHtiHH36ewosXLyhauBATRg5OV2fICG9OnT1LRGQk9Zq1pP+3vej99VcMGj6KjX7bKFTImVlTlK6u0u7ufNy0MS3ad0Kj0TB2xLCUbrnR43+hc4d2VK5YIV37d0E3NVaf9AbbPKDXod+zFp7HYdW0M2i0SvcUyiC33L0G8thh9fGX6H0Nz3Vaa0SJ8uh3rzb3I01h4KxlyndKq2FMtw7Y5c5Fuwbv471wLa2GT8Jaq2Xit12UeygiCu9F61g47BvCo5/Rf8ZSAJJ0elp+WI26Hpn3BrwO74oTMBfxX2sK/Vuk1w31r+uq8Sz+dYSjeS26bNfNa7ol9r+K7rfhmZ+UzYjGbd66JoBVjY/feCDpvGtxs39z3nt4998fuMoEdQW3ioqKigXQ/Q8OcKuoqKioZDP/LVehOgsVFRUVi6A6CxUVFRWVTPmvjRerzkJFRUXFAvy3XIXqLFRUVFQswn9sh3I1rKqKioqKJcjOjQSFEIOFEFeFEFeEEGuFEDkN6f2FEP8Yjhlvn5wF1JaFAeFSwjK64v+Zv46NeuuS+jWZbCnxLyHqeVlEd1n9zyyi2+PxTYvo/lfJrm4oIYQrMACoIKWMF0JsADoLIe6i7MxdRUr5PHknjNdFdRYqKioqFiCbxyy0KLtmvEDZjukR0AeYlBw2QkoZmoF9pvw/e6xVUVFReTfQS/NfQojeQogzqV69k/ORUj4EpqFseRQMREkp9wBlgLpCiJNCiENCCPM3ijOB2rJQUVFRsQAyC22L1Dtkv4phM9c2QAmU0Na+QogvUH7fC6CEw/ZE2UevpHzNObtqy0JFRUXFAsgsvDKhMXBHShkmpXyBEjLiQ5RQDpulwimUCVjG+86bieosVFRUVCxAVrqhMuEe8IEQIpdhB/CPUGIK+aGExUYIUQYl7MOT171etRtKRUVFxQLos2mIW0p5UgixESX8dRJwHqXLSgJLhRBXgESg6+t2QYHqLFRUVFQsQnbOhpJSjgPGmTj0RXZpmOUshBDOwAyUgZIIFC81BdgNLAKqAAJlcKW5Ifa1DricKpt1UspJQojVQA2UQEangG8M/WwIIRqgRLazBp5IKesbFpcEAjkM17vRUDEIIdYDZQ355wcipZRVhRDWwGKgmsFmpZQy4ygt6bBizXp8t2xFSknHT9rQ7fPO/H39BuN8JhMXH49rIRem+fxEHhNBhpavWouv3zaEEJQp5c7EH73JkSOHSZ2RP/5MQOARHOwLsGPjOgAio6IYPHw0Dx8F41q4EDOnTMAuXz4AFixZzsat27CyssJ72FDqfmgcHzsje0tpmmLlhs34bv9TqePWLej6aTuu3bjJj1Nn8TwxEY1Gw7ihA6hiCGOapo7Xb2Lj9j8RQlC6pBsTR/1Ajhw2Geol88fFO/heu4+U0LFCUb7yKMFvJ69z4E4IQoCDbQ4mfFQFp9w509gFP4tn5P6LPIl7jhCCTysU5UsP89bprNx5EN8DR5FIOjaqTdcWjQBYtSuA1bsPodFYUf+9Svzw+Sdp7O48CmHIrCUp7++HhtO/o1eKfWZU7PcNZb/6AqTk6V/XONxnALrnzwGo1L8v7/uMZ5VbWZ4/fWpkW3fOLIo2b0JC2BM2f5BxZDxLfafele9yVviPbQ2V+ZiFoQ/MDwiUUpaUUlYHOgNFgIFAiJSyspSyEtADxQkAxEspq6Z6TTKkrwbKAZUBW6CnQSc/MBdoLaWsyMuod8+BRlJKD6Aq0FwI8QGAlLJTcv4oEfo2G2w6AjmklJWB6sA3Qgi3rFbO9Zu38N2yFd+VS9m67g8CDh8h6N49Rv80gaED+rJ9w2oaN2zA4pWrjGxDQkNZuW4Dm1YtY4fvGnR6Pf6796ar1a6VF4vnzEqTtnDZCmrV9GTPtk3UqunJwmUrALh56zb+u/fgv3Edi+fMYvzEKeh0OqM807O3pOarXL99B9/tf7Jh0Wz8li8g4OgJgu4/YOrcRfT7+kv8li9gQM+uTJ27yMg2JOwJf2z0Y+OSOWz/YxF6vR7//Qcz1EvmRvgzfK/dZ3372mzpVIeAu6EERcbS/b0S+HWuy5ZOdanv5sTc0zeMbLVWgmG1y7OjS33Wtf+QNVfucvNp5jGir99/hO+Bo2zwGYbf5FEEnLtCUHAoJ69eZ/+ZS2ydMood08bQvWVjI9sShZ3ZMnkUWyaPYuPEEdjaWNPY07wQsrkKuVDxm15srd+EzR/UQ1hpKNlecUa5XQvj2qgBMffup19Xq9exu11ns7Qs9Z16F77LWSUbB7jfCuYMcDcCEqWU85MTpJR3pZSzgULAw1Tp/yQvAEkPKeVOw+i8RGlZJIcx64Iycn/PcF6o4a+UUsYYzrE2vNLUn8GhfcrL2NwSyC2E0KI4pEQgyyHpbt0JwqNyRWxtc6LVavGsXo29Bw5x5+5dPKu9B0DtD2qyJ50fKJ1OR8Lz5yQlJZEQn4CTo2O6Wp7Vq2Fnl/apZX9AIG1bKauA27byYt/BQynpXs2aYmNjQ1FXV4oXLcKlK1eN8kzP3pKar3I76B4eFcthmzMnWq0Gz/eqsC/wKEIIYuLiAHgWE4tTOvG/X9axjvjnz9M971VuRcTg4ZwfW2sNWisrPAvbs//OY/LYWKecE/8iCUNY+DQ45s5JBUc7AHLbaClZIA+hsQmZat5++BiP0iWwzWGDVqPBs3xp9p2+yLq9gfRq0xQba0XbwS5vhvmcuPwPRZ0dcXU0PxKf0GrR2OZEaDRoc9kS9/gxAO9P/IXTY8ZnuAPq42PHeR4Rke7x1FjqO/UufJezik5Ks1/vAuY4i4ooAyemWAoMF0IcF0L8IoQoneqYrRDiQqpXp9SGhq6iL4FdhqQyQAEhRIAQ4qwQ4qtU52oM8bxDgb1SypOvXEddlBZO8mPgRpQ44cEoMwWmSSmN29eZUMa9JGfOXSAiMor4+AQCjxzjcUgIZdzd2X/oMAC79u0nOMR4YaSzkxPdv/ychi3aUqdpS/LkzU2dWu9nST88/ClOjspMNyfHgjx9qtywIWFhuLg4p9EKCQ0z2/5d0ixd0o3TFy4TERVNfEICh46fIjg0jFED+jB1zkIatOvClDkLGfJtDyNbZ8eCdO/cgUbtP6du207kzZ2bOjVrZFpGgNL2eTnz6CmRCYnEv9AReDeM4BjlB3/miX9otOIAO248on/N0hnm8zA6jmtPoqninD9zzaKFOXPtJhHPYoh/nkjghas8Do8gKDiUs3/fpNPoKXw5fgaXb93NMJ+dx8/g9WF1s8oJEBf8mCuz59L56gU+u3GFxOhoHh4IoNjHzYgLDuapiR/K7MQS32NL6prL/2LLIg1CiDlCiItCiNNSygtASWAqYA+cFkIkRzd/tRtq/StZzUXp2jpseK9F6TLyApoBYwzTvZBS6gxdTUWAmkKISq/k9RkvWxUANQEdUBhlocpQIURJE2VJWRW5cOlyo7K6lyxBz25f0r1vf3p+N4iyZUqj0WjxGTeaNRs20q5LV2Jj47CxNh76iYqOZn9AIPt3bObw7h3Exyew1f9PU1WaZUw9BZp6As5O/i1Nd7fi9PqiEz0GD6fX0FGUK1USrUbDWr8djBjQh4DNaxjZvw/eE381so2Kfsb+I8fZt+EPAv3WEZ+QwLbd+8zTtc9Dz/fc6bHtFL13nKKsQ160hvIM+qAsB7o2omXpwqy+nP4Pd+yLJAbuPsfI2hXStEjS1XR1oWfrJvTw+Z1eE3+nXHFXNFZWJOn0RMfGse6XH/jh808YPHNJuk/6iUlJHDh7mWYfVDOrnAA2+e0o1qI5GypXZ22ZyljnykWpzz7F44fBnPWZlHkG/xKW+B5bUtfoOrLwehcwx1lcRRkoBkBK2Q9lHq+j4X2MlHKzlLIvsApokVmGQohxBvshqZIfALuklLFSyicog9ppOmWllJFAANA8VV5aoB2Q2hl1MeT1wtCddRRlUD0NUsqFUsr/a++846Mquj/8nCQEQidIRylRVJQiEAFBQxdFERHfF7EhYgOxgAoCr4gFURFUVFABRQWVJkUUQSmi0qTDD0XpLaGGGghJzu+PuQlLsiG7JHcXknn47Ie7c3fud2cz954pZ87UU9V6j3bp7PW73t2uLd+N/4Jxo0dSvGhRKl1WkagqlRnz0ftMGT+WNq1bcWnFihny/bFkGRUrlCeyRAny5QujVbMmrFyz1otC5pQsGcnefcYteu++/URGlgCgbOnSxMbGpX0ubu/etBaQL/kvNM0Ot93ClDEj+OrDoRQrWoRKFSsw9cfZtIppDEDrZjexZsPfGfIt+nMFFcuVJbJEcfKFhdHypsasXPt/Weqlclf1S5n8n8Z8eWdDihUIp1Lxs50U2lSrwJzNsV7znk5O4ZlZK7jtivK0jCrrs2aHZjcwZXAfvnq5J8UKFaRSudKULVmcltG1ERFqXl6ZEBEOHT3mNf/CVeupXvlSLinu+0Rr+SYxHN22nZMHDqBJSWydMZMr7r2HIpUu487f5/OftcspVKE87Rb+QkTpbMWa80ow6lQwdX1F/fh3IeCLsZgLFBCRJzzSCgKISCNnqTkiEg5UB87ZhxaRrpiewz2q6hnSfRomjkmYiBQE6gMbRKSUM/mNiERgViv+5ZGvBfCXqu70SNsONBNDIYwXl2cenzngeIfs3hPL7Hnzua11q7S0lJQURoz6jI533ZkhX/myZVi9dh0JCSdRVRYt/ZOoKpX90m4WcxNTZ8wEYOqMmTRvYjxRmjW5kZk/zSYxMZEdu3axdfsOal57jc/5LzTNA854+O7YvcxZ8DttWjSl9CUlWbpyDQCLl6+kUsUKGfKVK1Oa1es3kHDS+Y2Xr6Rq5cuy1EvTPWGm13YfTeDnzbHcenl5tsYfTzs/b0scVYsXzpBPVfnfvLVULVGYzrUzdFjPrXnYTITv3n+QOctW0+aGejSvV4vF6zcCxuvpdFISJYpk1AWY+fty2jTybagtleM7d1I6ui6hEREAlI+5iW0zZjI+qjoTatRlQo26HN+1m6k3Nidhb7ZizXklGHUqmLq+our760JAfFmjISLlMK6z9YF9mPmAkRh31ucwbrMhwEygt6qqF9fZWaraR0SSMAYl1X1kiqq+4ug8DzyEWZY+SlXfFZGawFgg1NGYkPp5J8/nwGLPCXgRKQx8hjFeAnymqm+fs5DHD3n9ITp1eYz4w4cJCwvjxZ5P07B+NGPHf8v4CZMAaNmsCb16dENEiNu3j/6vDOLT4cMAeH/Ep/ww52fCQkO5+spqvP5SX8LD07l1OiHKe/bpz9LlyzkUH0/JyJL0ePwRWjSN4ZnefdmzJ45y5crw3ltvULyYmVgdMWoMk6fNIDQ0lL7P9SSm8Q0A9Bv4Gh07tKfGNdU5FB+faf5gaaqXEOX3dnuW+CNHCAsNo0+Px2hYrw7LV6/j9fc+Ijk5mfzh4bzUqwfXXlWNuP37+d/goXwyZJD5jUeP5cdfFpjfuFoUr/XumeE3zixE+X3fLSL+5GnyOd5NDStewtOzlrMl/jghCOWLRDAg5lrKFC7A3uMn+d+8tXx8WzTL9xzk/u8WUy2yCKmjF880uJKYSme3yr2FKL9vwFDijx0nLDSU3ve3p2GNq0hMSqL/yK/YsHUn+cLCeOG+O2lw7ZXsPRhP/0/G8Umf7gAknEqkaff+zHl/IEUKRngtE3gPUX5d3xeo2r4dmpTEgTVrWfjks6QkJqad/8/a5UyLacmpgwcpWLYMjT94l9kdzHWajPmYco0bUaBkJAl797Fi0Fts/HJcBo2HY/8NSp2CINTlgsWyPW41JbKsz2ag/cHYwI+TpcMnY5EnyMRYuE4e28/Cm7FwG7ufRWDIU/tZ5ICxmFSijM/PnA6H4oJuLOwKbovFYgkCF1sz3RoLi8ViCQLWWFgsFoslS6yxsFgsFkuWpFxk88XWWFgsFksQyBiN6sLGGguLxWIJAj5sanRBkbf8Ni0Wi+UCIQX1+ZUVIvKsiKwXkXUi8rWztUPquedEREXkvLdUBWssLBaLJSjk1LaqIlIBeAqo52wVEYrZRgIRuRRoiYlqkS3sMFQqwZpsCtZSm2CVN+mcEexd4fdBEwOuCdBgjbvRXDNj2dHA/8YADyd4j2flKhHew6JcDOTwHRiGifR9GhOOabeTPgx4ARNOKVvYnoXFYrEEAX96Fp4Rsp3Xo6nXUdVdwBBM72EPcFhVZ4tIW2CXqq7Oie9rexYWi8USBJL86N2r6ifAJ97OOcFc78BsxxAPTHT2A+oOtMr2F3WwPQuLxWIJAil+vLKgBbBFVfep6mnM9tIPYYzHahHZitkLaIWI+B5PPx22Z2GxWCxBIAddZ7cDDZytHRIw+w1NUdWmqR9wDEY9Z6+g88IaC4vFYgkCvrjE+oKqLhGRSZjtr5OAlWQyZJUdrLGwWCyWIJCTi/JUdQAw4BznK2dXwxoLi8ViCQI+zEVcUPhkLESkDMZftwFwCEgE3gJ+Aj4FamJWDMQDrVX1mJed8r5R1cEiMg6zH/ZpYCnwmKqeFpFimD28L3O+1xBV/UxEruTs/bWrAi85u+i9DDyC2b0PoK+q/uB85xeBhzEhWJ5S1Z98/1nOMHb8t0ycOh1V5e4729K5U0f+2vgPAwa9xYkTJ6hQvhxDXhtI4cKFMuT9fNzXTJw6AxGh2uVRvDGgH/nz5/eq8+LLrzL/198oGVmC7yd9A0D84cM827sfu3bvoUL5crz71iCKFTV7L388+nMmTZtOSEgI/V/oxY03NMxwzXPl917Wb5j43TSnrHfQ+d57+GvjRga8/iYnEhKoUK4cQ14fSOHCGX3bveX1lS8mTWPi9z+hwN1tbubBu+9gwz+beXnoh5xKTCQ0NJQBzz5BzauvPCvfqVOJ3Pd0bxJPnyY5OYVWMY146qF7fdat8FhXyna6B1COb/iLv5/uhZ46RfmHH6J8l85oUhIHf57Llldfz5C3RNMmRL02EAkNJXbc1+wY/qFPmiEt2hFyk9mmPuXXH0n5+TsoVISwx/ohl5RB98eRNPI1OJFuzUKZioQ93i/trZQqS/LUL0x+H2j+THcadX0AVWX32v9j7ENP0PbV/tS8/RaSEhPZv2kLYx/qRsLhszenKlGxAp2/+JiiZcugKSn89snnzH1/hE+aAGO/nczE6TNRlLvbtqHzfzvw1z+bGPDWMKdOlWHIy/0oXCjj/fPi628x//fFlCxRnO/HjTmnzoVw//iLP95QFwJZekOJiABTgV9Vtaqq1sWsDqwIPA3EqWoNZ+XgwxgjAJCgqrU9XoOd9HHAVUANIALo6qR3B/5PVWsBTYB3RCRcVf9OvQZQFzgBeN4hwzw0Ug1Fdec7XgO0Bj4SkVB/f5yN/25i4tTpTBw7mmlff8H8hb+zdfsO+r36Br16PMGMCeNo0TSGUV98lSFv3N69fPHNRCZ/OYbvJ4wjOTmZmT/9nKlW+9vbMOrD985K++SzsTS8PprZ0yfT8PpoPvlsLAD/btrMzJ9mM3PSN4z68D0GvvEWyckZw5Jllj/Tsn43jYlffMa0b75yyrqdfq8MotdT3ZkxYXymZc0sry9s3LyVid//xISRQ5k6ajjzFy1l685dvP3xZ3TvfA9TRw/nqS738vbIzzLkDQ/Px+dDBzFt9Ad8N+p9flu6nFXrfdtqPbxsWSp07cLKm9uwPKYFEhJK6XZtKdboBkq2bsXypi1ZHtOcnSNGZswcEsLlg19jXaf7+fPGppS68w4KVrsiS02pUJmQm24l6bUeJL38OCG16kPp8oTe8l9SNqzkdN+HSNmwktBb/5sxc9xOkgY+YV6vdIfEU6Ss/N2nshYvX46mTz3GG/VieLVGA0JCQ4jueBcb5szjlWvr81qtG4jb+C+tX+yZIW9yUhKTevVjYPVo3mzQnJjuj1AundHOjI2btjBx+kwmjv6IaWNHMf/3xWzdsZN+bwyhV7dHmPHVaFrE3Miocd96zd/+1psZNWyw13MZPhvk++d8yEFvqIDgi+tsMyDRc49rVd2mqsOBcsAuj/S/VfWcy0dV9Qd1wPQsKqaeAoo4xqkwcBAzWeNJc2CTqm7L4jvfgenJnFLVLcC/wPVZFTQ9m7Zspda11xARUYCwsDCi61zHnHkL2LJtG9F1rgOgUf3rmT13vtf8ycnJnDx1iqSkJE6ePEnpUpmHZomuW4dixc5utfwy/1fa3W625mx3ext+nrcgLb3Nza0IDw/n0goVqHRpRdasy7haOLP8mZa1xrVnylr3OubMTVfWBvWZ/cs8n/P6wubtO6lV/SoiChQgLCyU6NrX8vPCRYjAseMnADh6/ASlLymZIa+IUMjZizopKYmkpGREfF8SL6FhhBQoAKGhhBSMIDE2jvIP3s+O4R+izv7Up/cfyJCvSJ3aJGzZyslt29HTp9k3dRolW/vgzl7uUnTTBkg8BSkppPy9lpA6jQi5riEpf8wBIOWPOYRcd8O5v3f169C9e+DAXp/LGhIWRr6ICEJCQ8lXsCDxu2PZMGcuKc5DcsviZZSoWCFDviOxcexYadZ0nTp2jNgNf1O8QnmfNDdt20ata6uf+dteV4s5C35jy/YdRNeuCUCj6LrMnr/Qa/7o62r53JIP9v1zPuRUuI9A4YuxuAYzy+6NMUBvEVkkIq+JiGfzKkJEVnm8zmouiUg+4H5glpP0AXA1Zpn6WuBpVU1vVDsCX6dLe1JE1ojIGGdxCkAFYIfHZ3Y6aX5R7fIo/ly5ikPxh0lIOMmvvy8iNi6OalFV+WWBqeCzfp7LnriMN22Z0qXpcl8nmra5k8Y3307hwoVp3LC+X/oHDhxMMzClS13CwYOHAIjbt4+yZcucpRW3d5/P+b2WNaoqf65Yeaasv/3hlDWKXxb86pT1F69lzSyvL1xRpRLL1qzj0OEjJJw8yYLFf7Jn7376Pvkob4/8jCZ3d+atEaPp+ciDXvMnJyfT7uEeNGp3HzfUq02t6r61ehNjY9kx4mPqr1hCgzUrSD5ylEMLfiUiqirF6ten9o8zqPndJArXrpUhb/6y5Ti1e0/a+1O7YwkvWy5LTd21lZBqNaBQEQjPT0jNaCSyFBQtAYcPmg8dPghFip/zOiHXx5CyNKPRzoz43Xv4echwBm1fz5t7/uHk4SNsmDP3rM/c0OV+1v0455zXKVnpMi69riZblvzpk261qlX4c9UaDh0+TMLJk/z6xxJi9+6lWtXK/LLwDwBmzV3Anr2+Gz1/COT9cz7kxp7FWYjIhyKyWkSWqeoqzBzC20AksExErnY+mn4YKn1f8yPM0FZqs+JmYBVQHqgNfCAiaU0FEQkH2gKegX5GAFHO5/cA76R+3MtXz2CfPZfQfzImYxczqkpluj54H126PUXXHs9yZbXLCQ0N5fWX+jF+wmTa39uZ4ydOEJ4v49TP4SNH+GXBQn6ZMZmFs2aQkHCSaT/MyvC580G9jHX606L2RlTVKnTt/ABduvWg65NPc2W1K0xZB/Rn/IRJtO/0AMePey9rZnl90q10KY/c04GHn/sfj7wwgKuiqhAWGsrX036gT/euzJ/4OS92f4T+b73nNX9oaChTRw9n/sTPWbNhIxs3b/VJN6xYMS5p3Yql0Q1ZUqsuIQUjKH1XeyQslLDixVh1y+1seeU1qn/qZXze60/tQ/Nvzw6Sf5xAWK/BhD07CN2xGZL9fBSEhhFSqyEpf/7qc5aCxYtT845b6V+lBr3LVyO8UEGuv/dM2+2Wvs+RkpTE0kyGgwDyFyrEo5O/ZMIzfTh59KhPulGVK9H1vo50efp5uj7bmyuviDJ1qu8LjJ88lfYPPWbun7B8PpclJ3Dj/jkfUlR9fl0I+DLBvR64K/WNqnZ3Qt3+6bw/hlkxOEVEUoBbgQ3nuqCIDABKAY95JD8EDHaGp/4VkS2YuY2lzvlbgBWqmtZk9TwWkU+B7523O4FLPa5dkTOBtdI4awn9sYNe/yJ3t2vL3e3aAjD0gxGUKV2aqCqVGfOReXht2bad+b9lHDv+Y8kyKlYoR2QJ09lp1SyGlavXcsetrb3JeKVkyUj27ttP6VKXsHfffiIjzbXKli5NbOyZlnvc3r1eh7gyy58ZZ5V1+EeUKZNa1uHnLGtmeX2lQ5tWdGhjhnGGfjqWsqUuYeinY+nXw4S/ad2kMf3ffv+c1yhapDDX167BwqUrqFa1cpaaxW9qzMntOzh9wLTo98/8kaLRdTm1O5b9M38E4OjKVWhKCvlKRqZ9DuDUnj3kL3+mJ5G/fFkSY2N9KmvKb7NI+c00GkLbP4Qe2g9HDkGxSNOrKBYJR+MzzS81otHt/8KRzD+TnqtaNOHAlm0cc4bUVk6ZQdQN9Vk67lsaPNCJGre1Zljz2zPNHxIWxqOTv2LpuAms+m6Gz7oAd99+K3ffbib0h44cRZlSpYiqfBlj3nsbgC3bdzD/j8V+XdNXAn3/+EvShWEDfMaXnsVcoICIPOGRVhBARBqlDv04Lf/qwDnnE0SkK6YXcU+6YabtmDmJVO+rK4HNHufvId0QlIh49v3vBNY5x9OBjiKSX0SqAFdwxuj4xYGD5iGxe08ss+fO57bWLdPSUlJSGDH6MzredWeGfOXLlmX12vUkJJxEVVm09E+iqlT2S7tZzE1MnTETgKkzZtK8yU0mvcmNzPxpNomJiezYtYut23dQ89prfM7vU1nnzee21q3OLuuoMV7LmlleXzlwKN7kjdvLnF8X0aZ5DKVLRrJ0lXGmW7xiNZUqZhwnPxh/mCNHjdfQyVOnWLR8FVUvq5jhc944tWs3RepcR0iECftf4sbGnPjnXw78OIvijRsBEFG1CiH5ws8yFABHV64momoVClx2KZIvH6Xa3cGBn849hJNG6hBTZClC6jQmZck8UlYtJuSGlgCE3NCSlJWLMs0eUr8pKUt8H4ICOLh9J1UaRJMvwszvXNU8hj0b/qb6zS24ufczfNT2v5xOSMg0/wOjPyR2w9/8Msw3jy9PDjhDN7tj45g9fyG3tWyWlpaSksKIz7+i451t/b6uLwT6/vGXi20YSrx1yTJ8yDyUhwH1MW6qx4GRQH7gOUzHPASYCfRWVfXiOjtLVfuISBLGoKT2Zaeo6isiUh74HDNpLphexleOfkHMHERVVU3z7RORLzFDUApsxbjh7nHO9QO6YCbJn1HVH89ZyEx6Fp0efpz4w4cJCwvjxZ5P0fD6aMaO/5bxEycD0LJpE3r1eAIRIW7fPvq/+gafvj8UgPdHfsoPs38mLCyMq6+sxuv/e5Hw8PCzBULMcE3PPv1Zunw5h+LjKRlZkh6PP0KLpjE807sve/bEUa5cGd576w2KFysGwIhRY5g8bQahoaH0fa4nMY3NpGi/ga/RsUN7alxTnUPx8Znm9xaivFOXRz3K+gwN60czdvw3jJ8wyZS1WVN69eh2pqyvvM6nw9/NNK839EjGseF7e7xA/JGjhIWF0qdbVxrWrc3yNet5/YNPSE5OJn94OC89041rr7ycuP0H+N/b7/PJmwP5e9MW+rwxjOSUFDQlhdZNb6T7gxlddhfWbpohDaDS870odcftaHISx9auZ2PP50GVau++Q+Frq5OSeJotA18l/rc/CC9ThmpD32bdvQ8AUKJ5M6JefRkJDSH262/Z8e7wDNdvcFv1DGlhvd9BChdFk5NI/vZjdMMq4zr7RH8ksjR6cC9JI16D40eheCRhD/Yk6b3+JnN4fvK9PY7TfR6AhBNeywTw1JiMLfXbXu5Lvf+2JzkpiR0r1/BV1yd5af1SwvKHc9wxhlsWL2P8E89SrFxZ7h/1AR+06UBUowY8/9tsdq5Zh6aYx9a0vq+w7sfZGTRG7s84oNDpiaeJP3yEsLBQXnyqGw3r1WHst5MZP8VEzG4Z05heTzzi1Kn99B88hE/fMR5QPV96laUrV3Mo/jAlI0vQo2vntF5KGk6I8oDfPwWLZXvcqm++4j73LQadjg/WZgZp+GQs8gSZGAvXCfHbozdnCNLf3ZuxcJvMjIXbeDMWgcCbsQgE3oyF6wRrP4scMBZ9/DAWgy8AY2FXcFssFksQuFBcYn3FGguLxWIJAhfKXISvWGNhsVgsQeBiC/dhjYXFYrEEATsMZbFYLJYsscNQFovFYsmSC2Vltq9YY2GxWCxB4GLrWdh1FjmAiDzqhA6xurlI0+rmbt1glfVixe9AghavPGp1c6Wm1c3dusEq60WJNRYWi8ViyRJrLCwWi8WSJdZY5AzBGvfMS7p5qaxWN/dqXrTYCW6LxWKxZIntWVgsFoslS6yxsFgsFkuWWGNhsVgsliyxxsJisVgsWWKNxXkghvoi0l5E7nSOA7aTlYgUFpE6IlI8AFohIhLiHIc7upEua64Qkf4iEuWmjj+IyLm35c3etYuKyBsi8qWIdEp37iO3dL18j24B0rkste6KSGUR6SAi1wZAN6j37cWOjQ3lJyLSCvgI+AfY5SRXBC4XkW6qmnFz4uxrfqSq3ZzjxsB4YJOj+Ziq/pDTmo5WO+BjIEVEHgf6YvZfryYiT6jqDDd0gRJAcWCeiMQCXwPfqupul/QAEJE6mZ3C7PXuFp9h6tNkoIuI3AV0UtVTQAM3BEWkZ/ok4EURKQCgqkNd0u0DPAacEpEhwHPA78BAERntom7A79vchnWd9RMR2QDcoqpb06VXAX5Q1atd0FyhqnWc43lAL1VdISJVgQmqWi+nNR2tlcAtQASwGohW1b9FpBIw2UVdz/LeCNwDtAc2AF+7Fc9HRJKBBZgHZ3oaqGqES7qrVLW2x/t+wK1AW2BO6m+Rw5pHgR+A9Zwp7zPAuwCqOjCnNR3d9UA9oCCwFaiqqvtEpBCwRFVd6WEE477Nbdiehf+EATu9pO8C8gVAv6iqrgBQ1c0iEuqmmKrGAojIdlX920nbljo05TaquhBYKCI9gJbAf3FvMdUG4DFV/Sf9CRHZ4ZImQH4RCVHVFABVfV1EdgK/AoVd0rwGGAoUAgaq6gkRedAtI+FBsqomiEgikAAcAFDV4y6PCAX7vr3oscbCf8YAy0TkGyD1AXIZ5iE22iXNq0RkDaYFWFlESqjqIeeB7WpF93iIdfFICwXCXZTdmD5BVZOBWc7LLV4m83m8Hi7qzgCaAT+nJqjqWBGJA4a7Iaiq24EOInIHMEdEhrmh44UVIjIeY6R+AcaKyCxM+f/PRV1v9+2lQEfcu29zFXYY6jwQkauBO4AKmAf4TmC6qrpS2Z1hH0/2qGqiiFwC3KSqU1zSjQbWqurJdOmVgcaq+pUbupbA4gwBvQzUV9WbXNYKA+4GFJgEXA90ArYDH6rqcRe1A3rf5jasscgBRKS0qu4NsGZJVT0QSM1AIiJXcebGVmA35sbeEADdCpjx82Me6a1V1bVejeP5dSemtZuEmYj9WlUPu6VpsfiDdZ31ExGJTP8ClopICbdcSkVksNOLQETqichmYImIbBORGDc0Ha2yIjJCRD4UkZIi8rKIrBWRCSJSzkXd3sA3mNbfUmCZc/y1403jlu5TwDTMkNM6Z4gmlUEu6j4NjAQKANEYh4JLgUUi0sQlzWJOvfpLRA6KyAER2eCkFXdD09ENilu0iLT2OC4mIqNEZI2IjBeRMoH8LhcrtmfhJyKSAmxLl1wR06VVVa3qguZaVa3hHM8DXlDVZSJSDRjvolfSLGAmZny5EzAO48Z6B9BCVe84R/bs6G4ErlHV0+nSw4H1qnqFS7prgYaqeswZapsEfKmq74nISlW9zkXd2qqaLCIFMd45TUTkMmCaG7oi8hMwFxjr4cRQFngQ87dtmdOajsYWjIvwf4BAukV7etiNcrQ/xXjZxahqOzf1cwO2Z+E/LwB/A21VtYqqVgF2Osc5bigc8jljvQARqroMQFU3Avld0gQoo6rDVXUwUFxV31TV7ao6HEg/j5KTpADlvaSXw92ti0NTh54cF8smwC0iMhTv7rQ5SerfNz9QxPkO23HPgaGy8/eMTU1Q1VhVfRPjsOEWh1T1OVW9DOgFXIGZ9J4nIoHaua6eqvZX1W2qOgyoHCDdixrrDeUnqjrE8agY5rhTDsCMqbvJh8APIjIYmCUi7wJTgObAKhd1PRsTX5zjXE7zDPCLiPzD2R5nlwNPuqgbKyK1VXUVgNPDuA3jSVPDRd1RGE+dxcBNwJsAIlIKOOiS5jYReQHTs4hz9MoAnTnzm7tKgN2iS4tZiChAURERPTOsYhvNPmCHobKBiNwO9MO00sq6rNUEeAKoxhmf8anAmPTDNTmo+QrwludEr5N+OTBYVTu4oetohGA8ZTw9V5Y5LrRuaVYEkjxb2x7nGqnq7y5qXwNcDaxT1b/c0vHQKwH0wQwppo7ZxwLTgTdV1RUjJSLfqGpHN66dhe6AdEkfOYsBy2Lq+AOB/k4XG9ZYZBMRiQCiVHVdsL9LbsUxTrWADcFycxSRwumNpotaQS+vxZIe2/3KJqqagJnHcBURuUpEeovI+yLynnPseogCR7e5iBROl946szw5oDnPw/vrfkxYiluAb50hi2Dg2kM7WOUVkSgRec6pT++IyOMiUswtPQ/d68Ws4UFEqotITxG51WXNp5yeo+U8sT0LPxGR6emTgKYYzxJUta0Lmr0x8ZG+4UzIgoqY1affOBPQOY7jStodEwajNvC0qk5zzqV5l7iguy41RpCILANaq+oBx1NosarWdEk3fXC9tFNAP1V1yzU64OV1/ra3Y2Jh3YqZ+zqEWevRTVXn57SmozsAYwjDgDlAfWA+0AL4SVVfd0n3MCYI5iaMB9ZEVd3nhlZuxU5w+09FTCtzFGZiWzCB0d5xUfNhvLuSDsUEgnPFWACPAHU9XUlFpLKqvoe73kGnRaSCqu4CjmFucoBTgJuxsAYBb2MWxaXHzV54MMr7CGfcdYdyxl33Y8xaE1fchIEOmIZHfswcSUVVPSIibwNLAFeMBbAZqIsxSv/FRLldjjEcU1T1qEu6uQZrLPynHvA0ZmL7eVVdJSIJqrrARc1UV9L06zsC6krqTLJPEhN+xE1j8SwwW0QmY4zhXGfNx42YcN5usQKYqqrL058Qka4u6garvGFAMuncdUXEzXhjSY6TwgkR2aSqRxzdBGcNk1uoE+NsNua3zofp4dwDDAFKuaidK7DGwk+cCjdMRCY6/8fh/u/4DHnIlVRV54vIDZiFgEWA5ZhWdg+XPYUeInNXVVcWPkLQyhsMd12ARBEpqKonMC19HN1iuNvwOatx4/TSpwPTHScVSxbYOYtsIiJtgEaq2tdlnTzlSmpxn0C76zqa+dVs6pQ+/RKgnKqudUm3mrOI1XKeWGORTQLh5igixVU13o1r+4uIRLrlg5+F7kZVreayRlWgPyZo4WBgGNAQM8H/vKbbOCcHdUMwi+Hac3YgwZFuTTRn8j0C/rcNpJuwiISpapJzXBi4CtgcjPp8MWJdZ/0kSG6O+0XkZxF5WAKw73YqItLf47i6mJhNy0Vkq4jUd1H3qIgccf4/KmZXt6jUdLd0gc8xQQuPAYuBvzB/21mYoTe3GI0ZVhwMzMPE4xoN9HerTolIIzGBA9eL2Yt6DvCniOwQkYZuaDq6wXIT7gzEichGEbkFWIMZelstIve4pZurUFX78uOF6bKnHi8DSjrHBYE1LmmuBW7DBPI7gPFW6YiJE+VmWVd4HM/EbEsJZjjsDxd1h2PCi5TxSNsSgL/tSo/j7Zmdc0F3Tbr3i53/82Na3G5oLsXMOzUE9mP2JwGoA/zuYlkDfv84118LXAJUAY5gFtKCWb3umm5uetmehf+cFpEKznGg3BxPq+r3qnovxnV3HCZq504xu44FgvKq+iOAqi7FhNF2BVXtAbyHCUn+lDNME4jx0hQRqeYsGCsoIvUgbajETZfd0+KE7BaROkAigJqxfbfKnU9V16rqImCfqv7maK7Axb8twbl/wGznul9VtwDHVHUTgDpxsSxZY72h/CcYbo5pnhxqVoxPACY4HiTtXNIEqOosQhSgoocXC7i8nauqLheRFhhvrwWYvR7c5gXMFqcpmN/1RRGpBRQF3IyI+jwwT0ROYn7XjpDmmfS9S5qeDcUX051zc8vcYLkJbxeRNzDeZn+JyDuYYJwtgD0u6uYa7AT3eeA8pDtxdlC/aeqSR4mIPKeqQ9y4dha66TdWWq7GfbYM0EFVPwzQ9ygHXKeqPwRCL532JZiw2q55nTk6ghmS2e+mjodeW+BnD+Ofmh4F3KWqb7moHdD7x9EsiolGoMAHwM0YV+ltwGuqag1GFlhjYbngEJEXUh9WInK3qk70ODdIXXJTzmu6Fos/2DkLPxGRUBF5TERedRZSeZ7rn1m+bGrW9DjOJ2ZbyukiMkhM/CBXEJEQEXlIRL4XkdUislxEvhGXtvr0wDOEdfohEtcCGOZBXa+IiFt7SgTl/vGi2yhQurkJayz852MgBuOVNFxMXJ1U2ruk+bnH8WDMyu13MBORI13SBOO+WYkAunQ6SCbH3t5b3fMR9LKXvPMqiQks6BbBuH/S674fQN1cg53g9p/r1YkCKiIfAB+JyBRMjBm3Hiie120ORKvqaRH5FVjtkiaYIIIPOce/ichiVX3J0V2FcXF1A83k2Nt7q3t+7MOM13vWrdTAmKVd0oTg3D/B1M01WGPhP2meImpWgz4qIi9hQpQXzjRX9igmIndieoL51Yk+q6oqIm4+xE6LSJSqbkrv0umybi1n8Z0AER4L8QR3vaLyku5moLmafb7PQsx2wW4RjPsnmLq5Bmss/OdPEWmtqrNSE1T1FRHZDYxwSXMBkLpPxmIRKaOqcWK2hHTTeyYYLp2oqpv+9lbX8C5QAshgLADXPKEIzv0TTN1cg/WGspyTQLt0OpoFMQsRTzvvr8SMo29V1e+srsUSeOwEt5+IyAsex3enOzcot2im6qphfyB1MbGYKjs6lwOLgKrAkyLi1kZPeUo3mHUqL+nmKoIdb+Rie3F2vKQVmZ272DWDrLvW4/hV4EPnONzznNW9KP+2eUo3N71sz8J/guFemWdcOh08x0abYfZqRlUTcXeDnLykm9fqVLB0cw12gtt/guHmmJdcOgHWiMgQYBdmTclsMPt6uKiZ13TzWp0Klm6uwU5w+4mIJGMiZQpmUVxqbB0BCqhqjgfYC4ZmkHUjMPuclwPGqOpqJ70hcLmqfml1s62Z1+pUUHRzE7Zn4ScaBDfHYGgGUxdoBRxV1cEAIrIEKOWc6211s09eq1NBrMu5Bjtn4SciUlBE8nm8v1JEnnUWzeUazWDqYkKFT/d4nx+IBpoAj1vd7JPX6lQQ63KuwRoL/wmGe2Wecel0CFdVz1XEv6nqATWrjQtZ3Rwhr9WpYOnmGuychZ+IyFpVreEcvwpEqmp3EQnH7PdQIzdoBln3X1W9PJNzm1Q1yupmWzOv1amg6OYmbM/Cf4Lh5piXXDoBlojII+kTReQxzN7RVjf75LU6FSzdXIOd4PafYLg55iWXTjBbb04VkU7ACietLmYsv53VzRHyWp0Klm6uwQ5D+UmQ3BzzjEtnOv1mwDXO2/WqOtdNvbykm9fqVLDrcm7A9iz8JxjulXnGpdMT52EZkAd1HtTNa3UqqHU5N2DnLPwnGO6Vecal0xIw8lqdsnU5m9iehf94dXMEDoiIW26OwdAMpq7FffJanbJ1OZvYnoX/lPB8o6pPerwthTsEQzOYuhb3yWt1ytblbGKNhf8Ew80xL7l0WgJDXqtTti5nE+sN5SciUhqYCpzCi5ujqsblBs1g6lrcJ6/VKVuXs481FudJMNwr84JLpyWw5LU6Zevy+WONhcVisViyxM5ZWCwWiyVLrLGwWCwWS5ZYY2GxWCyWLLHGwmKxWCxZ8v+eZ9W+vITZQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df__*100, annot=True, fmt=\".1f\", cmap=\"Reds_r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
